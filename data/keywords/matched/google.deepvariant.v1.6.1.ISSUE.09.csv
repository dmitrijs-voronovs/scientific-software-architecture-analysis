id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/273:2537,security,model,model,2537,"tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3420,security,model,model,3420,". + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3535,security,model,model,3535,"odel.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3572,security,model,model,3572,"3s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3595,security,model,model,3595,"back (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3623,security,model,model,3623,":. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3935,security,log,logs,3935,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4582,security,model,model,4582,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4636,security,log,log,4636,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:238,testability,Trace,Traceback,238,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:944,testability,hook,hooks,944,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2593,testability,Trace,Traceback,2593,"7, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index mod",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3935,testability,log,logs,3935,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4636,testability,log,log,4636,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:13,usability,input,inputing,13,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:134,usability,close,closed,134,"Follow up of inputing model files; Hello, a following-up thread of a previous issue. I don't know if you get notified of a reply in a closed issue so I am opening a new one. . I have tried your flag but it doesn't work. . Thank you. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 442, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 432, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_QDZzEL/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 388, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 627, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 934, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 648, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1122, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2516,usability,input,input,2516,"hon2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:2564,usability,user,user,2564,"/monitored_session.py"", line 1127, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 805, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 571, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3009,usability,command,command,3009,"ocal/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3192,usability,Command,Command,3192,"python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3399,usability,input,input,3399,"line 1268, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:3456,usability,statu,status,3456,"eError: The passed save_path is not a valid checkpoint: /input/mosquito_model/model.ckpt. real	0m7.387s. user	0m9.233s. sys	0m4.817s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4213,usability,input,input,4213,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4344,usability,input,input,4344,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4376,usability,input,input,4376,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4416,usability,input,input,4416,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/273:4561,usability,input,input,4561,"sl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@20.gz"" --checkpoint ""/input/mosquito_model/model.ckpt""' returned non-zero exit status 1. ```. However, the directory mosquito_model does exist and contains. `model.ckpt-97700.data-00000-of-00001 model.ckpt-97700.index model.ckpt-97700.meta`. The model file was providen to me by your colleague Andrew Carroll. Is there a way to check the files are ""correct""? . EDIT: here is the script . ```. #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}/ARCcestor_mosquito_model"". mkdir -p ""${OUTPUT_DIR}"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.9.0"". N_SHARDS=20. LOG_DIR=""${OUTPUT_DIR}/logs"" . mkdir -p ""${LOG_DIR}"" . #declare -a decade=(ARCcestor D2A1 D2B3 D3A1 D4A3 D5B3 H2A3 H2C3 H4A4 H4C2 H5A3). #for SAMPLE in ""${decade[@]}"". #do. # BAM=${SAMPLE}.sorted.bam. #OUTPUT_VCF=${SAMPLE}.vcf.gz. #OUTPUT_GVCF=${SAMPLE}.g.vcf.gz. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/shasta_final.fa --reads=""/input/ARCcestor.sorted.bam"" --regions=""/input/ARCcestor.bed"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=""${N_SHARDS}"" --customized_model=""/input/mosquito_model/model.ckpt"" ) 2>&1 | tee -a ""${LOG_DIR}/make_examples.log"". #done. ```. _Originally posted by @aderzelle in https://github.com/google/deepvariant/issues/268#issuecomment-586584341_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/273
https://github.com/google/deepvariant/issues/274:335,energy efficiency,current,currently,335,"Thread usage; Hello, follow-up ... I was not able to make it work, also we noticed, even when it's not taking all the threads, when it's running with the numbers of threads given by the shards argument, other processes (so, not DeepVariant) are on S as shown in htop. Is it that DeepVariant co-opt all the threads even when it doesn't currently need them? . Got it. Thanks for the context! If you end up tweaking the config, let me know whether it works for you or not. I'll close this issue now. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/271#issuecomment-586523576_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/274
https://github.com/google/deepvariant/issues/274:327,reliability,doe,doesn,327,"Thread usage; Hello, follow-up ... I was not able to make it work, also we noticed, even when it's not taking all the threads, when it's running with the numbers of threads given by the shards argument, other processes (so, not DeepVariant) are on S as shown in htop. Is it that DeepVariant co-opt all the threads even when it doesn't currently need them? . Got it. Thanks for the context! If you end up tweaking the config, let me know whether it works for you or not. I'll close this issue now. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/271#issuecomment-586523576_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/274
https://github.com/google/deepvariant/issues/274:381,testability,context,context,381,"Thread usage; Hello, follow-up ... I was not able to make it work, also we noticed, even when it's not taking all the threads, when it's running with the numbers of threads given by the shards argument, other processes (so, not DeepVariant) are on S as shown in htop. Is it that DeepVariant co-opt all the threads even when it doesn't currently need them? . Got it. Thanks for the context! If you end up tweaking the config, let me know whether it works for you or not. I'll close this issue now. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/271#issuecomment-586523576_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/274
https://github.com/google/deepvariant/issues/274:475,usability,close,close,475,"Thread usage; Hello, follow-up ... I was not able to make it work, also we noticed, even when it's not taking all the threads, when it's running with the numbers of threads given by the shards argument, other processes (so, not DeepVariant) are on S as shown in htop. Is it that DeepVariant co-opt all the threads even when it doesn't currently need them? . Got it. Thanks for the context! If you end up tweaking the config, let me know whether it works for you or not. I'll close this issue now. _Originally posted by @pichuan in https://github.com/google/deepvariant/issues/271#issuecomment-586523576_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/274
https://github.com/google/deepvariant/issues/275:206,deployability,contain,contained,206,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:27,energy efficiency,model,models,27,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:118,energy efficiency,model,model,118,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:144,energy efficiency,model,model,144,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:600,integrability,wrap,wrapper,600,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:600,interoperability,wrapper,wrapper,600,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:20,modifiability,Pac,PacBio,20,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:125,modifiability,PAC,PACBIO,125,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:220,modifiability,Pac,PacBio-native,220,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:340,modifiability,Pac,PacBio-native,340,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:541,performance,perform,performed,541,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:134,reliability,doe,does,134,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:361,safety,input,input,361,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:472,safety,input,input,472,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:27,security,model,models,27,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:118,security,model,model,118,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:144,security,model,model,144,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:284,security,ident,identical,284,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:667,security,ident,identical,667,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:361,usability,input,input,361,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:472,usability,input,input,472,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/issues/275:541,usability,perform,performed,541,"Information used in PacBio models; Hi,. I have a question about the information used by DeepVariant (v0.9.0) with the model `PACBIO`: does this model rely on/benefit from the additional quality information contained in ""PacBio-native"" BAM files? In other words, are the variant calls identical for a dataset that is processed (i) using the PacBio-native BAM as input, requiring the alignment to be done with pbmm2 to keep said information intact; and (ii), using FASTQ as input (w/o the additional quality information), and the alignment is performed with minimap2 (since pbmm2 is essentially just a wrapper around minimap2, let's assume the resulting alignments are identical)? Thanks for the clarification. Best,. Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/275
https://github.com/google/deepvariant/pull/276:67,deployability,updat,update,67,"Add blog post ""Looking through DeepVariant's eyes""; This is a blog update by the DeepVariant team. Note: we are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/276
https://github.com/google/deepvariant/pull/276:145,performance,time,time,145,"Add blog post ""Looking through DeepVariant's eyes""; This is a blog update by the DeepVariant team. Note: we are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/276
https://github.com/google/deepvariant/pull/276:67,safety,updat,update,67,"Add blog post ""Looking through DeepVariant's eyes""; This is a blog update by the DeepVariant team. Note: we are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/276
https://github.com/google/deepvariant/pull/276:67,security,updat,update,67,"Add blog post ""Looking through DeepVariant's eyes""; This is a blog update by the DeepVariant team. Note: we are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/276
https://github.com/google/deepvariant/pull/276:93,security,team,team,93,"Add blog post ""Looking through DeepVariant's eyes""; This is a blog update by the DeepVariant team. Note: we are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/276
https://github.com/google/deepvariant/issues/277:90,deployability,version,version,90,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:200,energy efficiency,current,currently,200,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:90,integrability,version,version,90,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:181,interoperability,platform,platforms,181,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:90,modifiability,version,version,90,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:80,reliability,Doe,Does,80,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:140,reliability,doe,does,140,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:263,testability,coverag,coverage,263,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/277:210,usability,support,supported,210,"Can I use this caller to run on long read samples; Hi,. We have long read data. Does this version run successfully on long read data? If it does , what are the long read sequencing platforms that are currently supported ? Also do you recommend a certain sequence coverage to get good results from long reads? Thanks,. Archana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/277
https://github.com/google/deepvariant/issues/278:136,integrability,filter,filtering,136,"What does exactly ""PASS"" mean?; Hello, I am curious about the meaning of ""PASS"" actually, how exactly is this evaluated? I noticed that filtering on ""PASS"" I am missing some variants. For examples, some variants with a GQ of 50 have a ""."" in the QUAL column. Example, it's a multi sample experiment. `chromosome_6	9454294	.	G	<*>	0	.	END=9454294	GT:GQ:MIN_DP:PL	0/0:50:296:0,240,2879`. And in another sample . `chromosome_6	9454294	.	G	C,<*>	21.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:22:176:96,79,0:0.448864,0:21,0,99,990,990,990`. What kind of info does DeepVariant use to decide if a variant pass or not? . Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/278
https://github.com/google/deepvariant/issues/278:5,reliability,doe,does,5,"What does exactly ""PASS"" mean?; Hello, I am curious about the meaning of ""PASS"" actually, how exactly is this evaluated? I noticed that filtering on ""PASS"" I am missing some variants. For examples, some variants with a GQ of 50 have a ""."" in the QUAL column. Example, it's a multi sample experiment. `chromosome_6	9454294	.	G	<*>	0	.	END=9454294	GT:GQ:MIN_DP:PL	0/0:50:296:0,240,2879`. And in another sample . `chromosome_6	9454294	.	G	C,<*>	21.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:22:176:96,79,0:0.448864,0:21,0,99,990,990,990`. What kind of info does DeepVariant use to decide if a variant pass or not? . Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/278
https://github.com/google/deepvariant/issues/278:543,reliability,doe,does,543,"What does exactly ""PASS"" mean?; Hello, I am curious about the meaning of ""PASS"" actually, how exactly is this evaluated? I noticed that filtering on ""PASS"" I am missing some variants. For examples, some variants with a GQ of 50 have a ""."" in the QUAL column. Example, it's a multi sample experiment. `chromosome_6	9454294	.	G	<*>	0	.	END=9454294	GT:GQ:MIN_DP:PL	0/0:50:296:0,240,2879`. And in another sample . `chromosome_6	9454294	.	G	C,<*>	21.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:22:176:96,79,0:0.448864,0:21,0,99,990,990,990`. What kind of info does DeepVariant use to decide if a variant pass or not? . Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/278
https://github.com/google/deepvariant/issues/279:42,reliability,doe,does,42,Missing data/low coverage handling; - How does deepVariant behave with low-coverage data which results in a lot of missingness? . - What's the lowest coverage the tool could be used with? Thanks! Yassine,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/279
https://github.com/google/deepvariant/issues/279:17,testability,coverag,coverage,17,Missing data/low coverage handling; - How does deepVariant behave with low-coverage data which results in a lot of missingness? . - What's the lowest coverage the tool could be used with? Thanks! Yassine,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/279
https://github.com/google/deepvariant/issues/279:75,testability,coverag,coverage,75,Missing data/low coverage handling; - How does deepVariant behave with low-coverage data which results in a lot of missingness? . - What's the lowest coverage the tool could be used with? Thanks! Yassine,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/279
https://github.com/google/deepvariant/issues/279:150,testability,coverag,coverage,150,Missing data/low coverage handling; - How does deepVariant behave with low-coverage data which results in a lot of missingness? . - What's the lowest coverage the tool could be used with? Thanks! Yassine,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/279
https://github.com/google/deepvariant/issues/279:163,usability,tool,tool,163,Missing data/low coverage handling; - How does deepVariant behave with low-coverage data which results in a lot of missingness? . - What's the lowest coverage the tool could be used with? Thanks! Yassine,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/279
https://github.com/google/deepvariant/issues/280:1244,safety,compl,completely,1244,"case to my eyes. . Here is the gvcf line. ```. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. That looks all right to me, seems like a ""solid"" candidate. But now, let's look at the bam . ![CT](https://user-images.githubusercontent.com/23341393/75540193-d4db9a80-5a1b-11ea-92a6-ba9da3def9f1.png). the relevant position is the first C starting from the right. As you see, there is not a single T base there. The site seems perfectly homozygous for C:C. . However, a bit on the left, you can see that many of the mapped reads abruptly end at the same position with a T. It's not a variant but something a bit strange seems to happen in that region. So far it's the only such case I have. Do you have any idea of what's going on? Here are the lines from the gVCF before the site. The abrupt T position is at 17434056, so in a block with no candidate. But just right after, for a few bases, DeepVariant threw a few calls that are completely not supported by the mapping. ```. zgrep -w -C8 ""17434065"" H4A4.g.vcf.gz. chromosome_1	17434049	.	T	G,<*>	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:62:36,25,0:0.403226,0:29,0,99,990,990,990. chromosome_1	17434050	.	G	<*>	0	.	END=17434056	GT:GQ:MIN_DP:PL	0/0:50:59:0,186,1859. chromosome_1	17434057	.	G	T,<*>	25.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:59:33,26,0:0.440678,0:25,0,71,990,990,990. chromosome_1	17434058	.	T	<*>	0	.	END=17434058	GT:GQ:MIN_DP:PL	0/0:50:63:0,189,1889. chromosome_1	17434059	.	G	T,<*>	25	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:63:37,26,0:0.412698,0:25,0,77,990,990,990. chromosome_1	17434060	.	A	<*>	0	.	END=17434062	GT:GQ:MIN_DP:PL	0/0:50:64:0,165,1889. chromosome_1	17434063	.	G	C,<*>	26.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:64:38,25,0:0.390625,0:26,0,99,990,990,990. chromosome_1	17434064	.	A	<*>	0	.	END=17434064	GT:GQ:MIN_DP:PL	0/0:50:64:0,192,1919. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. any idea of w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/280
https://github.com/google/deepvariant/issues/280:1244,security,compl,completely,1244,"case to my eyes. . Here is the gvcf line. ```. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. That looks all right to me, seems like a ""solid"" candidate. But now, let's look at the bam . ![CT](https://user-images.githubusercontent.com/23341393/75540193-d4db9a80-5a1b-11ea-92a6-ba9da3def9f1.png). the relevant position is the first C starting from the right. As you see, there is not a single T base there. The site seems perfectly homozygous for C:C. . However, a bit on the left, you can see that many of the mapped reads abruptly end at the same position with a T. It's not a variant but something a bit strange seems to happen in that region. So far it's the only such case I have. Do you have any idea of what's going on? Here are the lines from the gVCF before the site. The abrupt T position is at 17434056, so in a block with no candidate. But just right after, for a few bases, DeepVariant threw a few calls that are completely not supported by the mapping. ```. zgrep -w -C8 ""17434065"" H4A4.g.vcf.gz. chromosome_1	17434049	.	T	G,<*>	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:62:36,25,0:0.403226,0:29,0,99,990,990,990. chromosome_1	17434050	.	G	<*>	0	.	END=17434056	GT:GQ:MIN_DP:PL	0/0:50:59:0,186,1859. chromosome_1	17434057	.	G	T,<*>	25.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:59:33,26,0:0.440678,0:25,0,71,990,990,990. chromosome_1	17434058	.	T	<*>	0	.	END=17434058	GT:GQ:MIN_DP:PL	0/0:50:63:0,189,1889. chromosome_1	17434059	.	G	T,<*>	25	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:63:37,26,0:0.412698,0:25,0,77,990,990,990. chromosome_1	17434060	.	A	<*>	0	.	END=17434062	GT:GQ:MIN_DP:PL	0/0:50:64:0,165,1889. chromosome_1	17434063	.	G	C,<*>	26.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:64:38,25,0:0.390625,0:26,0,99,990,990,990. chromosome_1	17434064	.	A	<*>	0	.	END=17434064	GT:GQ:MIN_DP:PL	0/0:50:64:0,192,1919. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. any idea of w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/280
https://github.com/google/deepvariant/issues/280:2404,testability,plan,plan,2404," look at the bam . ![CT](https://user-images.githubusercontent.com/23341393/75540193-d4db9a80-5a1b-11ea-92a6-ba9da3def9f1.png). the relevant position is the first C starting from the right. As you see, there is not a single T base there. The site seems perfectly homozygous for C:C. . However, a bit on the left, you can see that many of the mapped reads abruptly end at the same position with a T. It's not a variant but something a bit strange seems to happen in that region. So far it's the only such case I have. Do you have any idea of what's going on? Here are the lines from the gVCF before the site. The abrupt T position is at 17434056, so in a block with no candidate. But just right after, for a few bases, DeepVariant threw a few calls that are completely not supported by the mapping. ```. zgrep -w -C8 ""17434065"" H4A4.g.vcf.gz. chromosome_1	17434049	.	T	G,<*>	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:62:36,25,0:0.403226,0:29,0,99,990,990,990. chromosome_1	17434050	.	G	<*>	0	.	END=17434056	GT:GQ:MIN_DP:PL	0/0:50:59:0,186,1859. chromosome_1	17434057	.	G	T,<*>	25.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:59:33,26,0:0.440678,0:25,0,71,990,990,990. chromosome_1	17434058	.	T	<*>	0	.	END=17434058	GT:GQ:MIN_DP:PL	0/0:50:63:0,189,1889. chromosome_1	17434059	.	G	T,<*>	25	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:63:37,26,0:0.412698,0:25,0,77,990,990,990. chromosome_1	17434060	.	A	<*>	0	.	END=17434062	GT:GQ:MIN_DP:PL	0/0:50:64:0,165,1889. chromosome_1	17434063	.	G	C,<*>	26.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:64:38,25,0:0.390625,0:26,0,99,990,990,990. chromosome_1	17434064	.	A	<*>	0	.	END=17434064	GT:GQ:MIN_DP:PL	0/0:50:64:0,192,1919. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. any idea of what's going on there? It's a bit annoying in the sense that I don't know how I could have caught that without eyeballing the alignment. In my experiment I plan to eyeball all my candidates anyway (because there are less than 100 of them).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/280
https://github.com/google/deepvariant/issues/280:520,usability,user,user-images,520,"Strange false positive call ; Hello, (me again sorry), I am eyeballing bam files for evaluation of candidates. Mostly it's fine (I open a lot of issues but I want to stress that most reported variants seem correct). But here is a very, very strange case to my eyes. . Here is the gvcf line. ```. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. That looks all right to me, seems like a ""solid"" candidate. But now, let's look at the bam . ![CT](https://user-images.githubusercontent.com/23341393/75540193-d4db9a80-5a1b-11ea-92a6-ba9da3def9f1.png). the relevant position is the first C starting from the right. As you see, there is not a single T base there. The site seems perfectly homozygous for C:C. . However, a bit on the left, you can see that many of the mapped reads abruptly end at the same position with a T. It's not a variant but something a bit strange seems to happen in that region. So far it's the only such case I have. Do you have any idea of what's going on? Here are the lines from the gVCF before the site. The abrupt T position is at 17434056, so in a block with no candidate. But just right after, for a few bases, DeepVariant threw a few calls that are completely not supported by the mapping. ```. zgrep -w -C8 ""17434065"" H4A4.g.vcf.gz. chromosome_1	17434049	.	T	G,<*>	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:62:36,25,0:0.403226,0:29,0,99,990,990,990. chromosome_1	17434050	.	G	<*>	0	.	END=17434056	GT:GQ:MIN_DP:PL	0/0:50:59:0,186,1859. chromosome_1	17434057	.	G	T,<*>	25.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:59:33,26,0:0.440678,0:25,0,71,990,990,990. chromosome_1	17434058	.	T	<*>	0	.	END=17434058	GT:GQ:MIN_DP:PL	0/0:50:63:0,189,1889. chromosome_1	17434059	.	G	T,<*>	25	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:63:37,26,0:0.412698,0:25,0,77,990,990,990. chromosome_1	17434060	.	A	<*>	0	.	END=17434062	GT:GQ:MIN_DP:PL	0/0:50:64:0,165,1889. chromosome_1	17434063	.	G	C,<*>	26.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:64:38,25,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/280
https://github.com/google/deepvariant/issues/280:1259,usability,support,supported,1259,". . Here is the gvcf line. ```. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. That looks all right to me, seems like a ""solid"" candidate. But now, let's look at the bam . ![CT](https://user-images.githubusercontent.com/23341393/75540193-d4db9a80-5a1b-11ea-92a6-ba9da3def9f1.png). the relevant position is the first C starting from the right. As you see, there is not a single T base there. The site seems perfectly homozygous for C:C. . However, a bit on the left, you can see that many of the mapped reads abruptly end at the same position with a T. It's not a variant but something a bit strange seems to happen in that region. So far it's the only such case I have. Do you have any idea of what's going on? Here are the lines from the gVCF before the site. The abrupt T position is at 17434056, so in a block with no candidate. But just right after, for a few bases, DeepVariant threw a few calls that are completely not supported by the mapping. ```. zgrep -w -C8 ""17434065"" H4A4.g.vcf.gz. chromosome_1	17434049	.	T	G,<*>	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:62:36,25,0:0.403226,0:29,0,99,990,990,990. chromosome_1	17434050	.	G	<*>	0	.	END=17434056	GT:GQ:MIN_DP:PL	0/0:50:59:0,186,1859. chromosome_1	17434057	.	G	T,<*>	25.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:59:33,26,0:0.440678,0:25,0,71,990,990,990. chromosome_1	17434058	.	T	<*>	0	.	END=17434058	GT:GQ:MIN_DP:PL	0/0:50:63:0,189,1889. chromosome_1	17434059	.	G	T,<*>	25	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:63:37,26,0:0.412698,0:25,0,77,990,990,990. chromosome_1	17434060	.	A	<*>	0	.	END=17434062	GT:GQ:MIN_DP:PL	0/0:50:64:0,165,1889. chromosome_1	17434063	.	G	C,<*>	26.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:64:38,25,0:0.390625,0:26,0,99,990,990,990. chromosome_1	17434064	.	A	<*>	0	.	END=17434064	GT:GQ:MIN_DP:PL	0/0:50:64:0,192,1919. chromosome_1	17434065	.	C	T,<*>	29.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:64:38,26,0:0.40625,0:29,0,99,990,990,990. ```. any idea of what's going on ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/280
https://github.com/google/deepvariant/issues/281:612,availability,error,error,612,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:936,deployability,Fail,Failed,936,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:1184,deployability,modul,module,1184,"odel_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:1270,interoperability,platform,platform,1270,"ice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Coul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:1184,modifiability,modul,module,1184,"odel_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:1243,modifiability,pac,packages,1243,"/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:612,performance,error,error,612,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:936,reliability,Fail,Failed,936,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:612,safety,error,error,612,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:1184,safety,modul,module,1184,"odel_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_orig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:1037,testability,Trace,Traceback,1037,"mmand to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:40,usability,command,command,40,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:612,usability,error,error,612,"Could not open BAM file; Hi, I run this command to call variant on my bam file:. ```. sudo docker run \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/home/thanh/ref37/hg19.fa \. --reads=/home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam \. --regions=$/home/thanh/RB1_Project/VBDI-VAR/RB1_padding_100.bed \. --output_vcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.vcf \. --output_gvcf=/home/thanh/Procedure_practice/17D2627041/VCF/17D2627041_De_hg19.g.vcf \. --num_shards=4 . ```. it resulted in this error. ```. ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. I0305 09:55:16.252675 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:2654,usability,command,command,2654,"75 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. ```. However I have checked my path and it's correct. ```. file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam: gzip compressed data, extra field. ```. I can run the example command of DeepVariant without any issue. What have gone wrong in my case, could you please help me on this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/281:2746,usability,help,help,2746,"75 139778511243008 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1399, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 388, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3IsReI/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. ```. However I have checked my path and it's correct. ```. file /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam. /home/thanh/Procedure_practice/17D2627041/qualification/17D2627041_hg19_arr.bam: gzip compressed data, extra field. ```. I can run the example command of DeepVariant without any issue. What have gone wrong in my case, could you please help me on this?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/281
https://github.com/google/deepvariant/issues/284:130,reliability,doe,does,130,"strange mutation; Dear,. We are facing an issue with one of our samples, there is a mutation in both the vcf and gvcf files which does not exist in the bam file. (chr14:50605480 C > - ) which makes a frameshift. If it helps I can send the igv link to Andrew. Kind regards. <img width=""1668"" alt=""Screenshot 2020-03-16 at 11 18 23"" src=""https://user-images.githubusercontent.com/12953535/76746670-299b4700-6778-11ea-9ca1-8773c885d103.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/284
https://github.com/google/deepvariant/issues/284:218,usability,help,helps,218,"strange mutation; Dear,. We are facing an issue with one of our samples, there is a mutation in both the vcf and gvcf files which does not exist in the bam file. (chr14:50605480 C > - ) which makes a frameshift. If it helps I can send the igv link to Andrew. Kind regards. <img width=""1668"" alt=""Screenshot 2020-03-16 at 11 18 23"" src=""https://user-images.githubusercontent.com/12953535/76746670-299b4700-6778-11ea-9ca1-8773c885d103.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/284
https://github.com/google/deepvariant/issues/284:344,usability,user,user-images,344,"strange mutation; Dear,. We are facing an issue with one of our samples, there is a mutation in both the vcf and gvcf files which does not exist in the bam file. (chr14:50605480 C > - ) which makes a frameshift. If it helps I can send the igv link to Andrew. Kind regards. <img width=""1668"" alt=""Screenshot 2020-03-16 at 11 18 23"" src=""https://user-images.githubusercontent.com/12953535/76746670-299b4700-6778-11ea-9ca1-8773c885d103.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/284
https://github.com/google/deepvariant/issues/285:51,deployability,upgrad,upgrade,51,"python3 compatibility; Hi,. Are there any plans to upgrade to python3? Py2 has been deprecated, which makes deepvariant kind of obsolete.. Thanks. M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/285
https://github.com/google/deepvariant/issues/285:8,interoperability,compatib,compatibility,8,"python3 compatibility; Hi,. Are there any plans to upgrade to python3? Py2 has been deprecated, which makes deepvariant kind of obsolete.. Thanks. M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/285
https://github.com/google/deepvariant/issues/285:51,modifiability,upgrad,upgrade,51,"python3 compatibility; Hi,. Are there any plans to upgrade to python3? Py2 has been deprecated, which makes deepvariant kind of obsolete.. Thanks. M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/285
https://github.com/google/deepvariant/issues/285:42,testability,plan,plans,42,"python3 compatibility; Hi,. Are there any plans to upgrade to python3? Py2 has been deprecated, which makes deepvariant kind of obsolete.. Thanks. M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/285
https://github.com/google/deepvariant/issues/287:433,availability,Down,Download,433,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:310,deployability,contain,containers,310,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:454,deployability,contain,container,454,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:498,deployability,build,build,498,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:73,security,privil,privileges,73,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:788,testability,unit,unittest,788,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:168,usability,help,helpful,168,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:184,usability,user,user-base,184,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:372,usability,help,helpful,372,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:400,usability,tool,tool,400,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/287:599,usability,command,command,599,"Add singularity usage to docs; Given that academic HPCs do not have root privileges it is not possible to run docker and one needs to use singularity. I think it would helpful to your user-base if you added a section on singularity to either the `deepvariant-quick-start.md` or `README.md`. . I had never used containers before today so the following would have been very helpful for me getting your tool up-and-running quicker:. ## Download an existing container from Docker Hub. ```. singularity build deepvariant.simg docker://google/deepvariant. ```. ## Run Deep Variant with Singularity in one command. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Respectfully,. Matthew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/287
https://github.com/google/deepvariant/issues/288:1296,availability,checkpoint,checkpoint,1296," -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2978,availability,error,errors,2978,"Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:13,deployability,pipelin,pipeline,13,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:109,deployability,pipelin,pipeline,109,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1369,deployability,modul,module,1369,"nt:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quali",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1585,deployability,depend,depend,1585,"--output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Descri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2509,deployability,observ,observed,2509,"80907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2761,deployability,scale,scaled,2761,"est.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3558,deployability,modul,module,3558,"Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 656, in common_contigs. common = contigs_list[0]. IndexError: list index out of range. ```. so is there any way to make it work? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:282,energy efficiency,gpu,gpus,282,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:382,energy efficiency,gpu,gpu,382,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1313,energy efficiency,model,models,1313,"}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Numbe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1324,energy efficiency,model,model,1324," -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=In",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1992,energy efficiency,model,model,1992,"put/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2761,energy efficiency,scale,scaled,2761,"est.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3064,energy efficiency,gpu,gpus,3064,"Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3170,energy efficiency,gpu,gpu,3170,"Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_opti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:13,integrability,pipelin,pipeline,13,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:109,integrability,pipelin,pipeline,109,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:808,integrability,buffer,buffer,808,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1585,integrability,depend,depend,1585,"--output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Descri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1896,integrability,FILTER,FILTER,1896,"test.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1929,integrability,filter,filters,1929,"8_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1949,integrability,FILTER,FILTER,1949,"b.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2034,integrability,FILTER,FILTER,2034," ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2887,integrability,FILTER,FILTER,2887,".2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2235,interoperability,FORMAT,FORMAT,2235,"tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2297,interoperability,FORMAT,FORMAT,2297,"kpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/std",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2380,interoperability,FORMAT,FORMAT,2380,"t be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2445,interoperability,FORMAT,FORMAT,2445,":. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2546,interoperability,FORMAT,FORMAT,2546,"ithub.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2627,interoperability,FORMAT,FORMAT,2627,"ase file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2706,interoperability,FORMAT,FORMAT,2706,"ostprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2899,interoperability,FORMAT,FORMAT,2899,"=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3644,interoperability,platform,platform,3644,"Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 656, in common_contigs. common = contigs_list[0]. IndexError: list index out of range. ```. so is there any way to make it work? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1369,modifiability,modul,module,1369,"nt:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quali",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1585,modifiability,depend,depend,1585,"--output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Descri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2761,modifiability,scal,scaled,2761,"est.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3558,modifiability,modul,module,3558,"Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 656, in common_contigs. common = contigs_list[0]. IndexError: list index out of range. ```. so is there any way to make it work? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3617,modifiability,pac,packages,3617,"Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 656, in common_contigs. common = contigs_list[0]. IndexError: list index out of range. ```. so is there any way to make it work? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:282,performance,gpu,gpus,282,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:382,performance,gpu,gpu,382,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:774,performance,time,time,774,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:789,performance,parallel,parallel,789,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1112,performance,time,time,1112,"ine, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1682,performance,time,time,1682,"debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2761,performance,scale,scaled,2761,"est.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2967,performance,time,time,2967,"escription=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2978,performance,error,errors,2978,"Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3064,performance,gpu,gpus,3064,"Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3170,performance,gpu,gpu,3170,"Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_opti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1296,reliability,checkpoint,checkpoint,1296," -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:319,safety,input,input,319,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:456,safety,input,input,456,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:505,safety,input,input,505,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:873,safety,input,input,873,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:921,safety,input,input,921,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1369,safety,modul,module,1369,"nt:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quali",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1585,safety,depend,depend,1585,"--output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Descri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1737,safety,input,input,1737," ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Intege",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2978,safety,error,errors,2978,"Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3107,safety,input,input,3107,"ow calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3244,safety,input,input,3244,"T,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3558,safety,modul,module,3558,"Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 656, in common_contigs. common = contigs_list[0]. IndexError: list index out of range. ```. so is there any way to make it work? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1313,security,model,models,1313,"}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Numbe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1324,security,model,model,1324," -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=In",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1992,security,model,model,1992,"put/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:478,testability,unit,unittest,478,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:895,testability,unit,unittest,895,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1585,testability,depend,depend,1585,"--output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Descri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1759,testability,unit,unittest,1759,"and:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-sc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2509,testability,observ,observed,2509,"80907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3266,testability,unit,unittest,3266,"Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3411,testability,Trace,Traceback,3411,"Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 656, in common_contigs. common = contigs_list[0]. IndexError: list index out of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:0,usability,command,command,0,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:22,usability,support,support,22,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:88,usability,support,support,88,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:96,usability,command,command,96,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:319,usability,input,input,319,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:456,usability,input,input,456,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:505,usability,input,input,505,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:759,usability,command,command,759,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:873,usability,input,input,873,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:921,usability,input,input,921,"command line pipeline support?; Hi, I want to know is there any way to make deepvariant support command line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1097,usability,command,command,1097,"nd line pipeline, I'm expecting it could accept read from stdin and pipe result to stdout. I tried explicitly using /dev/stdout to pipe result to stdout, . ```bash. docker run \. --gpus all \. --rm \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/dev/stdout \. --num_shards=4 \. 2> stderr.txt. ```. it could work, but print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1667,usability,command,command,1667,"t print some debug information to stdout and pollute the result. ```. ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Descripti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:1737,usability,input,input,1737," ***** Running the command:*****. time seq 0 3 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --regions ""chr20:10,000,000-10,000,100"" --task {}. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Intege",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2498,usability,Minim,Minimum,2498,"er/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2804,usability,close,closest,2804,"tput/call_variants_output.tfrecord.gz"" --outfile ""/dev/stdout"". ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:2978,usability,error,errors,2978,"Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3107,usability,input,input,3107,"ow calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/288:3244,usability,input,input,3244,"T,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default. ```. I then tried explicitly using /dev/stdin, this time I got errors. ```bash. cat ${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam | \. docker run \. --gpus all \. --rm \. -i \. -v ${INPUT_DIR}:/input \. -v ${OUTPUT_DIR}:/output \. google/deepvariant:latest-gpu \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/dev/stdin \. --regions ""chr20:10,000,000-10,000,100"" \. --output_vcf=/output/output.vcf \. --num_shards=4 . ```. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1461, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1451, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1325, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_O8GZSR/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1243, in processing_regions_from_options. sam_contigs = common_contigs(only_true(*all_sam_contigs)). File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/288
https://github.com/google/deepvariant/issues/289:126,availability,error,error,126,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:61,deployability,updat,update,61,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:94,deployability,updat,update,94,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:105,deployability,pipelin,pipeline,105,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:137,deployability,instal,installing,137,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:105,integrability,pipelin,pipeline,105,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:208,modifiability,pac,packages,208,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:320,modifiability,pac,packages,320,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:126,performance,error,error,126,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:61,safety,updat,update,61,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:94,safety,updat,update,94,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:126,safety,error,error,126,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:61,security,updat,update,61,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:94,security,updat,update,94,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/289:126,usability,error,error,126,CLIF for Ubuntu 18 missing; Hello. . Thanks for long awaited update to Python3. I'm trying to update our pipeline and getting error when installing CLIF. Looks like https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-18.latest.tgz is missing while https://storage.googleapis.com/deepvariant/packages/oss_clif_py3/oss_clif.ubuntu-16.latest.tgz exists. Can you fix this please?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/289
https://github.com/google/deepvariant/issues/290:138,deployability,pipelin,pipeline,138,"no output.visual_report.html?; Hi. . I recently ran deep variant with a collection of WGS samples. It seems to have run through the whole pipeline producing the g.vcf.gz and vcf.gz files, however there was no visual_report.html file? . /nrnb/opt/singularity-3.3.0/bin/singularity run --nv /nrnb/opt/singularity-containers/deepvariant_gpu_0.8.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Do I have to include a specific output tag in order to get the file? Based on the docs, it should automatically be produced? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/290
https://github.com/google/deepvariant/issues/290:311,deployability,contain,containers,311,"no output.visual_report.html?; Hi. . I recently ran deep variant with a collection of WGS samples. It seems to have run through the whole pipeline producing the g.vcf.gz and vcf.gz files, however there was no visual_report.html file? . /nrnb/opt/singularity-3.3.0/bin/singularity run --nv /nrnb/opt/singularity-containers/deepvariant_gpu_0.8.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Do I have to include a specific output tag in order to get the file? Based on the docs, it should automatically be produced? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/290
https://github.com/google/deepvariant/issues/290:614,deployability,automat,automatically,614,"no output.visual_report.html?; Hi. . I recently ran deep variant with a collection of WGS samples. It seems to have run through the whole pipeline producing the g.vcf.gz and vcf.gz files, however there was no visual_report.html file? . /nrnb/opt/singularity-3.3.0/bin/singularity run --nv /nrnb/opt/singularity-containers/deepvariant_gpu_0.8.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Do I have to include a specific output tag in order to get the file? Based on the docs, it should automatically be produced? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/290
https://github.com/google/deepvariant/issues/290:138,integrability,pipelin,pipeline,138,"no output.visual_report.html?; Hi. . I recently ran deep variant with a collection of WGS samples. It seems to have run through the whole pipeline producing the g.vcf.gz and vcf.gz files, however there was no visual_report.html file? . /nrnb/opt/singularity-3.3.0/bin/singularity run --nv /nrnb/opt/singularity-containers/deepvariant_gpu_0.8.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Do I have to include a specific output tag in order to get the file? Based on the docs, it should automatically be produced? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/290
https://github.com/google/deepvariant/issues/290:539,interoperability,specif,specific,539,"no output.visual_report.html?; Hi. . I recently ran deep variant with a collection of WGS samples. It seems to have run through the whole pipeline producing the g.vcf.gz and vcf.gz files, however there was no visual_report.html file? . /nrnb/opt/singularity-3.3.0/bin/singularity run --nv /nrnb/opt/singularity-containers/deepvariant_gpu_0.8.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Do I have to include a specific output tag in order to get the file? Based on the docs, it should automatically be produced? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/290
https://github.com/google/deepvariant/issues/290:614,testability,automat,automatically,614,"no output.visual_report.html?; Hi. . I recently ran deep variant with a collection of WGS samples. It seems to have run through the whole pipeline producing the g.vcf.gz and vcf.gz files, however there was no visual_report.html file? . /nrnb/opt/singularity-3.3.0/bin/singularity run --nv /nrnb/opt/singularity-containers/deepvariant_gpu_0.8.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Do I have to include a specific output tag in order to get the file? Based on the docs, it should automatically be produced? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/290
https://github.com/google/deepvariant/issues/291:287,availability,down,download,287,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:69,energy efficiency,model,model,69,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:524,energy efficiency,reduc,reducing,524,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:145,interoperability,specif,specific,145,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:430,modifiability,paramet,parameters,430,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:455,performance,network,network,455,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:69,security,model,model,69,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:455,security,network,network,455,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:183,testability,simpl,simply,183,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:154,usability,guid,guide,154,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:183,usability,simpl,simply,183,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:356,usability,guid,guide,356,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/291:605,usability,help,help,605,"Training on local machine; Hi,. I am trying to train the DeepVariant model in my local machine (presumably not using docker as well). Is there a specific guide on doing that? or do I simply follow https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md, download the binaries and change all output bucket references in the guide to local directories? . Also, if I want to change the structure and parameters of the neural network for training, where can I impose those changes? (for example reducing the image size from 221x100 to 101x100). . Thank you very much for your help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/291
https://github.com/google/deepvariant/issues/292:0,availability,Error,Error,0,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:248,availability,error,error,248,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:569,availability,error,error,569,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1715,availability,error,error,1715,"gularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2545,availability,error,error,2545,". #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7590,availability,error,error,7590,"ant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8326,availability,down,download,8326,8.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8845,availability,down,download,8845,a. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:192,deployability,version,version,192,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:530,deployability,log,logs,530,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:608,deployability,log,logs,608,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:703,deployability,modul,module,703,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1675,deployability,log,logs,1675,"user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1754,deployability,log,logs,1754,"DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1850,deployability,modul,module,1850,"VARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/use",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3825,deployability,modul,module,3825,"NTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5138,deployability,build,build,5138,"riant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5553,deployability,build,builds,5553,"min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5645,deployability,build,builds-,5645,"iant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(comman",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5719,deployability,build,build,5719,"gs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subproce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5775,deployability,fail,failed,5775,"uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessErro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6325,deployability,modul,module,6325,"5148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8136,deployability,modul,module,8136,"ake_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.201",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8163,deployability,modul,module,8163," --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8186,deployability,modul,module,8186,"w4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. mo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8404,deployability,modul,module,8404,m_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8431,deployability,modul,module,8431, maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8454,deployability,modul,module,8454,_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8522,deployability,releas,releases,8522,es in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8905,deployability,releas,release,8905,"est.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9105,deployability,releas,releases,9105,"`.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9160,deployability,modul,module,9160,"module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9187,deployability,modul,module,9187,"le load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9210,deployability,modul,module,9210,"gzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:11101,deployability,modul,module,11101,"NTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12414,deployability,build,build,12414,"riant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12829,deployability,build,builds,12829,"min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12921,deployability,build,builds-,12921,"iant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12995,deployability,build,build,12995,"gs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subproc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13051,deployability,fail,failed,13051,"uv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13602,deployability,modul,module,13602,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:39,energy efficiency,model,model,39,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:122,energy efficiency,CPU,CPU,122,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:130,energy efficiency,GPU,GPU,130,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:188,energy efficiency,CPU,CPU,188,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:388,energy efficiency,cpu,cpus-per-task,388,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:710,energy efficiency,load,load,710,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:861,energy efficiency,cpu,cpu-,861,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1533,energy efficiency,cpu,cpus-per-task,1533,"ar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1857,energy efficiency,load,load,1857,"T/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8143,energy efficiency,load,load,8143,"amples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8170,energy efficiency,load,load,8170,"f ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8193,energy efficiency,load,load,8193,"f.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8411,energy efficiency,load,load,8411,EM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_ele,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8438,energy efficiency,load,load,8438,g_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annot,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8461,energy efficiency,load,load,8461,dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9167,energy efficiency,load,load,9167," load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9194,energy efficiency,load,load,9194,"d samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9217,energy efficiency,load,load,9217,"_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a publi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:192,integrability,version,version,192,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:259,integrability,Sub,Submission,259,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1393,integrability,Sub,Submission,1393,"ask=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2919,integrability,event,event,2919,"ch/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 30",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2938,integrability,pub,public,2938,"MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6621,integrability,sub,subprocess,6621,"n-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6714,integrability,sub,subprocess,6714,"build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6795,integrability,sub,subprocess,6795,"/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6875,integrability,buffer,buffer,6875,"G/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8509,integrability,pub,pub,8509, more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10195,integrability,event,event,10195," gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 30",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10214,integrability,pub,public,10214,"load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13898,integrability,sub,subprocess,13898,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13991,integrability,sub,subprocess,13991,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:14072,integrability,sub,subprocess,14072,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:14152,integrability,buffer,buffer,14152,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8390,interoperability,format,format,8390,maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_ded,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:192,modifiability,version,version,192,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:703,modifiability,modul,module,703,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1850,modifiability,modul,module,1850,"VARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/use",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3042,modifiability,interm,intermediate,3042,". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3825,modifiability,modul,module,3825,"NTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6325,modifiability,modul,module,6325,"5148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6385,modifiability,pac,packages,6385,"MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6485,modifiability,pac,packages,6485,"Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8136,modifiability,modul,module,8136,"ake_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.201",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8163,modifiability,modul,module,8163," --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8186,modifiability,modul,module,8186,"w4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. mo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8404,modifiability,modul,module,8404,m_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8431,modifiability,modul,module,8431, maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8454,modifiability,modul,module,8454,_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9160,modifiability,modul,module,9160,"module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9187,modifiability,modul,module,9187,"le load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9210,modifiability,modul,module,9210,"gzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10318,modifiability,interm,intermediate,10318,"og_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:11101,modifiability,modul,module,11101,"NTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13602,modifiability,modul,module,13602,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13662,modifiability,pac,packages,13662,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13762,modifiability,pac,packages,13762,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:0,performance,Error,Error,0,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:122,performance,CPU,CPU,122,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:130,performance,GPU,GPU,130,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:188,performance,CPU,CPU,188,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:248,performance,error,error,248,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:388,performance,cpu,cpus-per-task,388,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:435,performance,time,time,435,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:569,performance,error,error,569,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:710,performance,load,load,710,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:861,performance,cpu,cpu-,861,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1533,performance,cpu,cpus-per-task,1533,"ar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1580,performance,time,time,1580,"h/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1715,performance,error,error,1715,"gularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1857,performance,load,load,1857,"T/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2545,performance,error,error,2545,". #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2660,performance,time,time,2660,"/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with Nat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5756,performance,parallel,parallel,5756,"/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6835,performance,time,time,6835,"ef /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6850,performance,parallel,parallel,6850,"ch/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. uc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7590,performance,error,error,7590,"ant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8143,performance,load,load,8143,"amples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8170,performance,load,load,8170,"f ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8193,performance,load,load,8193,"f.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8411,performance,load,load,8411,EM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_ele,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8438,performance,load,load,8438,g_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annot,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8461,performance,load,load,8461,dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9167,performance,load,load,9167," load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9194,performance,load,load,9194,"d samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9217,performance,load,load,9217,"_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a publi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9936,performance,time,time,9936,"e [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with Nat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13032,performance,parallel,parallel,13032,"/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. rais",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:14112,performance,time,time,14112,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:14127,performance,parallel,parallel,14127,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2768,reliability,doe,does,2768,"egans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5775,reliability,fail,failed,5775,"uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessErro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10044,reliability,doe,does,10044,". wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13051,reliability,fail,failed,13051,"uv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:0,safety,Error,Error,0,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:248,safety,error,error,248,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:530,safety,log,logs,530,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:569,safety,error,error,569,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:608,safety,log,logs,608,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:703,safety,modul,module,703,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:805,safety,test,testdata,805,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1675,safety,log,logs,1675,"user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1715,safety,error,error,1715,"gularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1754,safety,log,logs,1754,"DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1850,safety,modul,module,1850,"VARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/use",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2545,safety,error,error,2545,". #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3496,safety,input,inputs,3496,"""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3825,safety,modul,module,3825,"NTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5060,safety,input,input,5060,"v)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5701,safety,input,input,5701,"e_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5738,safety,input,input,5738,"action). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6325,safety,modul,module,6325,"5148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7277,safety,input,input,7277,"riant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7517,safety,input,input,7517," _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7563,safety,input,input,7563,"eepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7590,safety,error,error,7590,"ant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8039,safety,input,input,8039,"h/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8136,safety,modul,module,8136,"ake_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.201",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8163,safety,modul,module,8163," --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8186,safety,modul,module,8186,"w4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. mo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8404,safety,modul,module,8404,m_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8431,safety,modul,module,8431, maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8454,safety,modul,module,8454,_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9160,safety,modul,module,9160,"module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9187,safety,modul,module,9187,"le load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9210,safety,modul,module,9210,"gzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9286,safety,input,input,9286,"388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9775,safety,input,input,9775,"egans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10772,safety,input,inputs,10772,"input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:11101,safety,modul,module,11101,"NTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12336,safety,input,input,12336,"v)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12977,safety,input,input,12977,"e_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13014,safety,input,input,13014,"action). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13602,safety,modul,module,13602,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:39,security,model,model,39,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:530,security,log,logs,530,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:608,security,log,logs,608,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1675,security,log,logs,1675,"user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1754,security,log,logs,1754,"DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8496,security,worm,wormbase,8496,e are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vc,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8513,security,worm,wormbase,8513,input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elega,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:530,testability,log,logs,530,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:608,testability,log,logs,608,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:805,testability,test,testdata,805,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1199,testability,unit,unittest,1199,"my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1675,testability,log,logs,1675,"user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1754,testability,log,logs,1754,"DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3676,testability,Trace,Traceback,3676,"0:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:4916,testability,coverag,coverage,4916,"300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6227,testability,Trace,Traceback,6227,"110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7836,testability,unit,unittest,7836,"seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7868,testability,unit,unittest,7868,"ne-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7904,testability,unit,unittest,7904,"examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/rel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7939,testability,unit,unittest,7939,"atch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7978,testability,unit,unittest,7978,"legans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10952,testability,Trace,Traceback,10952,"5:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12192,testability,coverag,coverage,12192,"300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13504,testability,Trace,Traceback,13504,"10855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:0,usability,Error,Error,0,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:104,usability,guid,guide,104,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:248,usability,error,error,248,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:569,usability,error,error,569,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:677,usability,user,user,677,"Error running DeepVariant on non-human model organism; I've had success following the **Getting started guide** with both CPU and GPU on the example datasets and now I'm trying to run the CPU version on my own data, _C. elegans_, but am getting an error:. ## Submission script for example. ```. #!/bin/bash. #SBATCH --job-name=example_DV. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_example_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celeg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1715,usability,error,error,1715,"gularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/quickstart-testdata"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:1824,usability,user,user,1824,"=""/scratch/moldach/bin/DEEPVARIANT/cpu-1cpu"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. ## Submission script for _C. elegans_. ```. #!/bin/bash. #SBATCH --job-name=Celegans_DeepVar. #SBATCH --nodes=1. #SBATCH --ntasks=1. #SBATCH --cpus-per-task=1. #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2545,usability,error,error,2545,". #SBATCH --mem=1000. #SBATCH --time=0:20:0. #SBATCH --account=def-mtarailo. #SBATCH --output=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.out. #SBATCH --error=/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2719,usability,user,user,2719,"/scratch/moldach/bin/DEEPVARIANT/logs/deepVar_Celegans_%j.err. #SBATCH --mail-type=ALL. #SBATCH --mail-user=moldach@ucalgary.ca. module load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:2850,usability,user,user,2850,"dule load singularity. BIN_VERSION=""0.10.0"". INPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/MADDOG"". OUTPUT_DIR=""/scratch/moldach/bin/DEEPVARIANT/celegans"". mkdir -p ""${OUTPUT_DIR}"". # Pull the image. singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Run DeepVariant. singularity run -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/c_elegans.PRJEB28388.WS274.genomic.fa \. --reads=""${INPUT_DIR}""/maddog_bam_trim_bwaMEM_sort_dedupped.bam \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:3496,usability,input,inputs,3496,"""/output.g.vcf.gz \. --num_shards=1. ```. The error looks like:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T17:40:13-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 17:40:16.049175 47823917316800 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpl3fvinw4. I0331 17:40:24.867229 47384002755264 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 17:40:25.244051 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 17:40:25.256583 47384002755264 make_examples.py:535] Preparing inputs. I0331 17:40:25.453527 47384002755264 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5060,usability,input,input,5060,"v)). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5701,usability,input,input,5701,"e_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:5738,usability,input,input,5738,"action). File ""/tmp/Bazel.runfiles_p8uucuhy/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6131,usability,user,user,6131,"ence build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6643,usability,command,command,6643,"ilds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:6826,usability,Command,Command,6826,"ing --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz --gvcf /tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz --task 0. real	0m9.819s. user	0m2.982s. sys	0m2.851s. I0331 17:40:25.872794 47823917316800 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7246,usability,statu,status,7246," call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.geno",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7277,usability,input,input,7277,"riant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7517,usability,input,input,7517," _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7563,usability,input,input,7563,"eepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:7590,usability,error,error,7590,"ant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:8039,usability,input,input,8039,"h/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpl3fvinw4/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpl3fvinw4/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. This is what my input directory looks like:. ```. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. ```. I noticed there are a few more input files in the sample example `quickstart-input`; is it possible the error is caused by that? . ```. NA12878_S1.chr20.10_10p1mb.bam. NA12878_S1.chr20.10_10p1mb.bam.bai. test_nist.b37_chr20_100kbp_at_10mb.bed. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. ucsc.hg19.chr20.unittest.fasta. ucsc.hg19.chr20.unittest.fasta.fai. ucsc.hg19.chr20.unittest.fasta.gz. ucsc.hg19.chr20.unittest.fasta.gz.fai. ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. ## Trying to fill in the missing input files. I used `bgzip` to convert to gzip and `faidx` to get the `.fai`/`.gzi` files:. ```. module load nixpkgs/16.09. module load gcc/7.3.0. module load samtools/1.9. bgzip c_elegans.PRJEB28388.WS274.genomic.fa. samtools faidx c_elegans.PRJEB28388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9286,usability,input,input,9286,"388.WS274.genomic.fa.gz. ```. Next I download the `.gff3` annotation from and converted it to `.bed` format:. ```. module load nixpkgs/16.09. module load gcc/6.4.0. module load bedops/2.4.35. wget ftp://ftp.wormbase.org/pub/wormbase/releases/WS274/species/c_elegans/PRJEB28388/c_elegans.PRJEB28388.WS274.annotations.gff3.gz. bgzip -d c_elegans.PRJEB28388.WS274.annotations.gff3.gz. gff2bed < c_elegans.PRJEB28388.WS274.annotations.gff3 > c_elegans.PRJEB28388.WS274.annotations.bed. rm c_elegans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9775,usability,input,input,9775,"egans.PRJEB28388.WS274.annotations.gff3. ```. The `.vcf.gz` file I download from [CeNDR](https://www.elegansvariation.org/data/release/latest) (comparable to the [DGV database in humans](http://dgv.tcag.ca/dgv/app/home)) then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:9995,usability,user,user,9995,") then generate its index file `vcf.gz.tbi`:. ```. wget https://storage.googleapis.com/elegansvariation.org/releases/20180527/variation/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10126,usability,user,user,10126,"tion/WI.20180527.impute.vcf.gz. module load nixpkgs/16.09. module load gcc/7.3.0. module load htslib/1.9. tabix -p vcf WI.20180527.impute.vcf.gz. ```. Now my input directory looks like:. ```. maddog_bam_trim_bwaMEM_sort_dedupped.bam. maddog_bam_trim_bwaMEM_sort_dedupped.bam.bai. c_elegans.PRJEB28388.WS274.annotations.bed. WI.20180527.impute.vcf.gz. WI.20180527.impute.vcf.gz.tbi. c_elegans.PRJEB28388.WS274.genomic.fa. c_elegans.PRJEB28388.WS274.genomic.fa.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz. c_elegans.PRJEB28388.WS274.genomic.fa.gz.fai. c_elegans.PRJEB28388.WS274.genomic.fa.gz.gzi. ```. Now that I think I have all the appropriate input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:10772,usability,input,inputs,10772,"input files in my `INPUT_DIR` I will try to run the code again:. ```. [31mFATAL: [0m Image file already exists: ""deepvariant_0.10.0.sif"" - will not overwrite. time=""2020-03-31T18:35:24-07:00"" level=warning msg=""\""/run/user/3019658\"" directory set by $XDG_RUNTIME_DIR does not exist. Either create the directory or unset $XDG_RUNTIME_DIR.: stat /run/user/3019658: no such file or directory: Trying to pull image in the event that it is a public image."". I0331 18:35:27.010462 47712747653824 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpmglc7_7t. I0331 18:35:39.745799 47929040407232 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0331 18:35:39.846203 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. I0331 18:35:39.857604 47929040407232 make_examples.py:535] Preparing inputs. I0331 18:35:39.897673 47929040407232 genomics_reader.py:223] Reading /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12336,usability,input,input,12336,"v)). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1279, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 647, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:12977,usability,input,input,12977,"e_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13014,usability,input,input,13014,"action). File ""/tmp/Bazel.runfiles_0muv5ovo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 725, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 102092263 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13408,usability,user,user,13408,"nce build. Contig matches were: . ""chrV_pilon"" is 21243235 bp and IS MISSING, . ""chrX_pilon"" is 18110855 bp and IS MISSING, . ""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:13920,usability,command,command,13920,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:14103,usability,Command,Command,14103,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/292:14523,usability,statu,status,14523,"""chrIV_pilon"" is 17759200 bp and IS MISSING, . ""chrII_pilon"" is 15525148 bp and IS MISSING, . ""chrI_pilon"" is 15331301 bp and IS MISSING, . ""chrIII_pilon"" is 14108536 bp and IS MISSING, . ""chrM_pilon"" is 13988 bp and IS MISSING. Here is a useful article about different human genome reference builds:. https://gatkforums.broadinstitute.org/gatk/discussion/11010/human-genome-reference-builds-grch38-hg38-b37-hg19. Please make sure the --ref input matches the build used for the input in --reads. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa --reads /scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam --examples /tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz --gvcf /tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz --task 0. real	0m13.428s. user	0m3.470s. sys	0m3.116s. I0331 18:35:40.443594 47712747653824 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/c_elegans.PRJEB28388.WS274.genomic.fa"" --reads ""/scratch/moldach/bin/DEEPVARIANT/MADDOG/maddog_bam_trim_bwaMEM_sort_dedupped.bam"" --examples ""/tmp/tmpmglc7_7t/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/tmpmglc7_7t/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/292
https://github.com/google/deepvariant/issues/293:0,modifiability,Pac,PacBio,0,"PacBio short insert reads; Hi,. Will DeepVariant perform well with PacBio CCS smaller insert reads? (i.e. < 5 kb). Thanks,. Gilad",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/293
https://github.com/google/deepvariant/issues/293:67,modifiability,Pac,PacBio,67,"PacBio short insert reads; Hi,. Will DeepVariant perform well with PacBio CCS smaller insert reads? (i.e. < 5 kb). Thanks,. Gilad",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/293
https://github.com/google/deepvariant/issues/293:49,performance,perform,perform,49,"PacBio short insert reads; Hi,. Will DeepVariant perform well with PacBio CCS smaller insert reads? (i.e. < 5 kb). Thanks,. Gilad",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/293
https://github.com/google/deepvariant/issues/293:49,usability,perform,perform,49,"PacBio short insert reads; Hi,. Will DeepVariant perform well with PacBio CCS smaller insert reads? (i.e. < 5 kb). Thanks,. Gilad",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/293
https://github.com/google/deepvariant/issues/294:13,modifiability,Pac,PacBio,13,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/294:115,modifiability,Pac,PacBio,115,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/294:57,performance,perform,perform,57,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/294:4,testability,coverag,coverage,4,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/294:77,testability,coverag,coverage,77,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/294:167,testability,coverag,coverage,167,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/294:57,usability,perform,perform,57,"Low coverage PacBio calling; Hi,. Will DeepVariant still perform on very low coverage (1x, 2x, 3x) highly accurate PacBio CCS reads? Or would GATK be better for lower coverage libraries? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/294
https://github.com/google/deepvariant/issues/295:24,modifiability,Pac,PacBio,24,"Best alignment tool for PacBio data; Hi,. What is the recommended aligner for Pacbio data before running DeepVariant? bwa? pbmm2? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/295
https://github.com/google/deepvariant/issues/295:78,modifiability,Pac,Pacbio,78,"Best alignment tool for PacBio data; Hi,. What is the recommended aligner for Pacbio data before running DeepVariant? bwa? pbmm2? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/295
https://github.com/google/deepvariant/issues/295:15,usability,tool,tool,15,"Best alignment tool for PacBio data; Hi,. What is the recommended aligner for Pacbio data before running DeepVariant? bwa? pbmm2? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/295
https://github.com/google/deepvariant/issues/296:116,availability,error,error,116,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:135,availability,Error,Error,135,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:230,availability,Error,Error,230,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:44,deployability,version,version,44,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:75,energy efficiency,gpu,gpu,75,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:44,integrability,version,version,44,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:181,integrability,buffer,buffer,181,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:44,modifiability,version,version,44,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:75,performance,gpu,gpu,75,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:116,performance,error,error,116,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:125,performance,parallel,parallel,125,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:135,performance,Error,Error,135,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:209,performance,disk,disk,209,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:220,performance,parallel,parallel,220,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:230,performance,Error,Error,230,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:474,performance,disk,disk,474,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:116,safety,error,error,116,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:135,safety,Error,Error,135,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:230,safety,Error,Error,230,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:116,usability,error,error,116,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:135,usability,Error,Error,135,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:230,usability,Error,Error,230,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:304,usability,close,close,304,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/296:620,usability,help,help,620,TMPDIR cleanup; Hi. I started using the new version of deepvariant (0:10:0-gpu) and have been getting the following error: . parallel: Error: Output is incomplete. Cannot append to buffer file in /tmp. Is the disk full? parallel: Error: Change $TMPDIR with --tmpdir or use --compress. Warning: unable to close filehandle properly: No space left on device during global destruction. It seems like running deepvariant leaves behind temporary files that are taking up a lot of disk space and I was wondering if there is a post run cleaning you recommend to remove these sort of items or some flags to do it? Thanks for the help!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/296
https://github.com/google/deepvariant/issues/297:111,usability,user,user,111,"Naming evidence bam folders; Hello,. not a bug, just a suggestion that might be useful. At the moment when the user request the evidence bams, folders are named. Chrom_1:2000-3000 . It seems the "":"" colon is creating problems when one wants to copy the directory somewhere else, on an external drive for example. Of course, it's not that difficult to work around, you can make an archive, or rename all the directories. . But you might think of a new way to name the folder. . Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/297
https://github.com/google/deepvariant/issues/298:94,deployability,pipelin,pipeline,94,"Deepvariant for Structural Variants; Hi, . Would it be possible to use Deepvariant's training pipeline to create a model that is able to call larger variants (SVs), or is there something that would fundamentally limit the use of Deepvariant's algorithm for this case? . Thanks a lot in advance for any comments!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/298
https://github.com/google/deepvariant/issues/298:115,energy efficiency,model,model,115,"Deepvariant for Structural Variants; Hi, . Would it be possible to use Deepvariant's training pipeline to create a model that is able to call larger variants (SVs), or is there something that would fundamentally limit the use of Deepvariant's algorithm for this case? . Thanks a lot in advance for any comments!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/298
https://github.com/google/deepvariant/issues/298:94,integrability,pipelin,pipeline,94,"Deepvariant for Structural Variants; Hi, . Would it be possible to use Deepvariant's training pipeline to create a model that is able to call larger variants (SVs), or is there something that would fundamentally limit the use of Deepvariant's algorithm for this case? . Thanks a lot in advance for any comments!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/298
https://github.com/google/deepvariant/issues/298:115,security,model,model,115,"Deepvariant for Structural Variants; Hi, . Would it be possible to use Deepvariant's training pipeline to create a model that is able to call larger variants (SVs), or is there something that would fundamentally limit the use of Deepvariant's algorithm for this case? . Thanks a lot in advance for any comments!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/298
https://github.com/google/deepvariant/issues/300:824,energy efficiency,gpu,gpu,824,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:343,integrability,filter,filtering,343,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:522,integrability,filter,filter,522,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:1120,interoperability,standard,standard,1120,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:824,performance,gpu,gpu,824,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:562,reliability,doe,does,562,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:391,usability,user,user-images,391,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:704,usability,command,command,704,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:986,usability,USER,USER,986,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:1196,usability,document,documentation,1196,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/300:1297,usability,help,help,1297,"DeepVariant calling 10-fold more variants than GATK; Hi. I have been using deepvariant to call germline and somatic variants from WGS samples. For calling germline variants, I have been running GATK 3.8 side by side. By just looking at the number of variants, deepvariant calls 10x more variants for chromosome 1 than GATK (see attached) when filtering for PASS. ![deepvariantvgatk](https://user-images.githubusercontent.com/45370974/79917221-13784a80-83f8-11ea-93c3-8ccc972aeb62.png). I have tried to see if setting a GQ filter would improve the overlap and it does not. I am wondering if this is an issue because I am trying to call germline variants from normal bams (not tumor bams). I also have the command that I used to run deepvariant below. Is there a flag I may be missing? singularity run --nv deepvariant_0.10.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref --reads=$bam --regions $chr --output_vcf=$x.$chr.vcf.gz --intermediate_results_dir /tmp/$USER/$SLURM_JOB_ID/$SLURM_ARRAY_TASK_ID --output_gvcf=$x.$chr.g.vcf.gz --num_shards=3. Also as a follow-up question, what is the gold standard way to call germline vs somatic variants? I can't seem to find the documentation on how to include the matched normal for somatic variant calling. Thanks again for the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/300
https://github.com/google/deepvariant/issues/301:520,deployability,build,build,520,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:578,deployability,depend,dependencies,578,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:288,energy efficiency,core,core,288,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:333,energy efficiency,CPU,CPU,333,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:496,energy efficiency,optim,optimzation,496,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:648,energy efficiency,optim,optimized,648,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:578,integrability,depend,dependencies,578,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:293,interoperability,platform,platform,293,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:578,modifiability,depend,dependencies,578,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:333,performance,CPU,CPU,333,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:648,performance,optimiz,optimized,648,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:578,safety,depend,dependencies,578,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:578,testability,depend,dependencies,578,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/301:337,usability,support,supports,337,"AVX2 or AVX512 enable deepvariant binaries; I'm using google/deepvariant-0.10.0 through docker on AVX-512 instruction capable Intel skylake processor. But the docker image ""google/deepvariant-0.10.0"" binaries are not built for AVX-512. Here are the warnings for the same:. ` I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA `. Where can I get deepvariant or tensorflow binaries with AVX-512 optimzation? I tried to build deepvariant from source, but couldn't due to lot of dependencies. . Please let me know if there is any way to get AVX-512 optimized binaries for deepvariant/tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/301
https://github.com/google/deepvariant/issues/302:362,interoperability,heterogen,heterogeneity,362,"What does "" . /0"" or "" . /1"" stand for?; Hi,. I used DeepVariant+GLnexus to detect the mutations. In the GT area of the VCF file, there were descriptions such as "" . /0"" , "" . /1"" or "" . /2"". I've never seen a pattern like "" . /0"" or "" . /1"" when using gatk's haplotypecaller. Basically, I recognized "" . "" as a missing value. What do the missing values and the heterogeneity of ALT mean? Does this mean that it is different from the heterozygous mutation of ""REF/ALT"", which is different from "" 0/0"" or "" 0/1""?? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/302
https://github.com/google/deepvariant/issues/302:5,reliability,doe,does,5,"What does "" . /0"" or "" . /1"" stand for?; Hi,. I used DeepVariant+GLnexus to detect the mutations. In the GT area of the VCF file, there were descriptions such as "" . /0"" , "" . /1"" or "" . /2"". I've never seen a pattern like "" . /0"" or "" . /1"" when using gatk's haplotypecaller. Basically, I recognized "" . "" as a missing value. What do the missing values and the heterogeneity of ALT mean? Does this mean that it is different from the heterozygous mutation of ""REF/ALT"", which is different from "" 0/0"" or "" 0/1""?? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/302
https://github.com/google/deepvariant/issues/302:389,reliability,Doe,Does,389,"What does "" . /0"" or "" . /1"" stand for?; Hi,. I used DeepVariant+GLnexus to detect the mutations. In the GT area of the VCF file, there were descriptions such as "" . /0"" , "" . /1"" or "" . /2"". I've never seen a pattern like "" . /0"" or "" . /1"" when using gatk's haplotypecaller. Basically, I recognized "" . "" as a missing value. What do the missing values and the heterogeneity of ALT mean? Does this mean that it is different from the heterozygous mutation of ""REF/ALT"", which is different from "" 0/0"" or "" 0/1""?? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/302
https://github.com/google/deepvariant/issues/302:76,safety,detect,detect,76,"What does "" . /0"" or "" . /1"" stand for?; Hi,. I used DeepVariant+GLnexus to detect the mutations. In the GT area of the VCF file, there were descriptions such as "" . /0"" , "" . /1"" or "" . /2"". I've never seen a pattern like "" . /0"" or "" . /1"" when using gatk's haplotypecaller. Basically, I recognized "" . "" as a missing value. What do the missing values and the heterogeneity of ALT mean? Does this mean that it is different from the heterozygous mutation of ""REF/ALT"", which is different from "" 0/0"" or "" 0/1""?? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/302
https://github.com/google/deepvariant/issues/302:76,security,detect,detect,76,"What does "" . /0"" or "" . /1"" stand for?; Hi,. I used DeepVariant+GLnexus to detect the mutations. In the GT area of the VCF file, there were descriptions such as "" . /0"" , "" . /1"" or "" . /2"". I've never seen a pattern like "" . /0"" or "" . /1"" when using gatk's haplotypecaller. Basically, I recognized "" . "" as a missing value. What do the missing values and the heterogeneity of ALT mean? Does this mean that it is different from the heterozygous mutation of ""REF/ALT"", which is different from "" 0/0"" or "" 0/1""?? Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/302
https://github.com/google/deepvariant/issues/303:106,energy efficiency,model,model,106,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1348,integrability,filter,filtering,1348,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1453,integrability,filter,filter,1453,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:133,performance,perform,performed,133,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:826,reliability,diagno,diagnostic,826,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:106,security,model,model,106,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1104,security,ident,identical,1104,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:826,testability,diagno,diagnostic,826,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:872,testability,understand,understanding,872,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1057,testability,coverag,coverage,1057,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1139,testability,simpl,simply,1139,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1160,testability,coverag,coverage,1160,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1195,testability,coverag,coverage,1195,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:133,usability,perform,performed,133,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:557,usability,clear,clear,557,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:937,usability,user,user-images,937,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/303:1139,usability,simpl,simply,1139,"High density SNPs call in some but not all samples; Hello, . I used DeepVariant with the mosquito trained model, on 11 samples, then performed joint calling with GLnexus. In the following track, in the first sample it calls 2 SNP G/A and T/C (corresponding to the 2 last blue box) in the D2A1 sample. However, in the D5B3 sample the sites are called as 0/0. There is no ""RefCall"" either so I think it means it did not even generate candidates. . Point to note: I have no idea if there are, or not, SNPs at those 2 loci. But from the alignment, it is not at clear to me why in one case it thought there were SNPs, and in the other case it thought not. . For the same sites, GATK joint caller decided the site was 0/0 for all samples (again, I don't know which one is the true genotype there). The bam I am showing here are the diagnostic bams emitted by DeepVariant, so my understanding is that I see what it saw. ![igv_snapshot](https://user-images.githubusercontent.com/23341393/80101296-7e995c80-8571-11ea-8e3d-37e306442888.png). As you might notice, the coverage depth across my samples is not always identical. So I wonder if it's not simply a question of coverage (though my lowest average coverage value is 30, which is ok I think). . Would you have any clue of what might be happening? . Thank a lot. EDIT: I can get rid of those regions by filtering on QUAL on the GLnexus pVCF, however. But I am still curious, as I might want to keep them and filter them otherwise (not easy to reach a spot where you get read of FP without removing all the TP).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/303
https://github.com/google/deepvariant/issues/304:426,availability,checkpoint,checkpoint,426,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:752,availability,operat,operations,752,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:804,availability,operat,operations,804,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1042,availability,servic,service,1042,"issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1050,availability,servic,service,1050,"t upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1070,availability,servic,service,1070," step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1193,availability,servic,service,1193,"pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1201,availability,servic,service,1201,"from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2317,availability,Cluster,ClusterSpec,2317,"time/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3609,availability,slo,sloppy,3609,"tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4663,availability,operat,operator,4663,"ntal_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 1398722",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5230,availability,Restor,Restoring,5230,"s will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5584,availability,Restor,Restoring,5584,"d in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6640,availability,checkpoint,checkpoint,6640,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:92,deployability,fail,failed,92,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1042,deployability,servic,service,1042,"issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1050,deployability,servic,service,1050,"t upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1070,deployability,servic,service,1070," step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1193,deployability,servic,service,1193,"pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1201,deployability,servic,service,1201,"from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1258,deployability,Version,Version,1258,". time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2317,deployability,Cluster,ClusterSpec,2317,"time/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2973,deployability,version,version,2973,"t_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2999,deployability,updat,updating,2999,"_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3439,deployability,version,version,3439,"luation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3465,deployability,updat,updating,3465,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4050,deployability,version,version,4050,"o layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4076,deployability,updat,updating,4076,"01495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4603,deployability,version,version,4603,"f sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4629,deployability,updat,updating,4629,"red, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4931,deployability,version,version,4931,"ap_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4957,deployability,updat,updating,4957,"low.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 33",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5968,deployability,modul,module,5968,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:443,energy efficiency,model,models,443,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:454,energy efficiency,model,model,454,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:592,energy efficiency,core,core,592,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:658,energy efficiency,optim,optimized,658,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:711,energy efficiency,CPU,CPU,711,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:913,energy efficiency,core,core,913,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:958,energy efficiency,CPU,CPU,958,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:962,energy efficiency,Frequenc,Frequency,962,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1308,energy efficiency,core,core,1308,"ile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.serv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1508,energy efficiency,model,modeling,1508,"riants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1538,energy efficiency,model,model,1538,"IME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1606,energy efficiency,estimat,estimator,1606,"eature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1651,energy efficiency,model,model,1651," is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1724,energy efficiency,estimat,estimator,1724,"n performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4223,energy efficiency,optim,optimizations,4223,"iles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4325,energy efficiency,estimat,estimator,4325," (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4498,energy efficiency,model,modeling,4498,"leave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5050,energy efficiency,estimat,estimator,5050,"on. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5261,energy efficiency,model,models,5261," fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5272,energy efficiency,model,model,5272,"ementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5497,energy efficiency,model,modeling,5497,"eling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5615,energy efficiency,model,models,5615,"ctions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5626,energy efficiency,model,model,5626,"updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6657,energy efficiency,model,models,6657,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6668,energy efficiency,model,model,6668,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1042,integrability,servic,service,1042,"issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1050,integrability,servic,service,1050,"t upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1070,integrability,servic,service,1070," step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1193,integrability,servic,service,1193,"pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1201,integrability,servic,service,1201,"from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1258,integrability,Version,Version,1258,". time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2973,integrability,version,version,2973,"t_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3439,integrability,version,version,3439,"luation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3994,integrability,batch,batching,3994," updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` me",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4050,integrability,version,version,4050,"o layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4172,integrability,batch,batch,4172,"39872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4603,integrability,version,version,4603,"f sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4931,integrability,version,version,4931,"ap_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5724,integrability,batch,batches,5724,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6264,integrability,sub,subprocess,6264,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6357,integrability,sub,subprocess,6357,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6438,integrability,sub,subprocess,6438,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:597,interoperability,platform,platform,597,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:918,interoperability,platform,platform,918,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1114,interoperability,platform,platform,1114,"w to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1042,modifiability,servic,service,1042,"issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1050,modifiability,servic,service,1050,"t upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1070,modifiability,servic,service,1070," step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1193,modifiability,servic,service,1193,"pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1201,modifiability,servic,service,1201,"from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1258,modifiability,Version,Version,1258,". time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1556,modifiability,paramet,parameters,1556," 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 13987",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2755,modifiability,pac,packages,2755,"model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2973,modifiability,version,version,2973,"t_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3056,modifiability,layer,layers,3056,"'_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3439,modifiability,version,version,3439,"luation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4050,modifiability,version,version,4050,"o layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4603,modifiability,version,version,4603,"f sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4784,modifiability,pac,packages,4784,"0.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4801,modifiability,layer,layers,4801,"77903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4808,modifiability,layer,layers,4808,"4 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4824,modifiability,Layer,Layer,4824,":323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4931,modifiability,version,version,4931,"ap_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4980,modifiability,layer,layer,4980,"mental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5240,modifiability,paramet,parameters,5240,"e care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5594,modifiability,paramet,parameters,5594,"ure version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5968,modifiability,modul,module,5968,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6028,modifiability,pac,packages,6028,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6128,modifiability,pac,packages,6128,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:264,performance,time,time,264,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:658,performance,optimiz,optimized,658,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:711,performance,CPU,CPU,711,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:731,performance,perform,performance,731,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:958,performance,CPU,CPU,958,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1408,performance,Tune,Tune,1408,"frecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1457,performance,perform,performance,1457,"t"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3994,performance,batch,batching,3994," updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` me",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4172,performance,batch,batch,4172,"39872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4223,performance,optimiz,optimizations,4223,"iles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5724,performance,batch,batches,5724,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6478,performance,time,time,6478,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:92,reliability,fail,failed,92,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:426,reliability,checkpoint,checkpoint,426,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3609,reliability,slo,sloppy,3609,"tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5230,reliability,Restor,Restoring,5230,"s will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5584,reliability,Restor,Restoring,5584,"d in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6640,reliability,checkpoint,checkpoint,6640,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2999,safety,updat,updating,2999,"_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3465,safety,updat,updating,3465,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4076,safety,updat,updating,4076,"01495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4629,safety,updat,updating,4629,"red, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4957,safety,updat,updating,4957,"low.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 33",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5968,safety,modul,module,5968,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:443,security,model,models,443,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:454,security,model,model,454,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1508,security,model,modeling,1508,"riants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1538,security,model,model,1538,"IME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1651,security,model,model,1651," is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:2999,security,updat,updating,2999,"_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:3465,security,updat,updating,3465,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0424 15:59:50.451262 139872277903104 call_variants.py:384] Writing calls to /tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz. W0424 15:59:50.467876 139872277903104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0424 15:59:50.501495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4076,security,updat,updating,4076,"01495 139872277903104 data_providers.py:369] self.input_read_threads=8. W0424 15:59:50.501965 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4498,security,model,modeling,4498,"leave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4629,security,updat,updating,4629,"red, use `tf.data.Options.experimental_determinstic`. I0424 15:59:50.681574 139872277903104 data_providers.py:376] self.input_map_threads=48. W0424 15:59:50.681832 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:4957,security,updat,updating,4957,"low.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 33",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5261,security,model,models,5261," fused implementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5272,security,model,model,5272,"ementation. I0424 15:59:51.794167 139872277903104 estimator.py:1147] Calling model_fn. W0424 15:59:51.800228 139872277903104 deprecation.py:323] From /tmp/Bazel.runfiles_sszxydhb/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5497,security,model,modeling,5497,"eling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5615,security,model,models,5615,"ctions for updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5626,security,model,model,5626,"updating:. Deprecated in favor of operator or tf.math.divide. W0424 15:59:51.806498 139872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6657,security,model,models,6657,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6668,security,model,model,6668,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5870,testability,Trace,Traceback,5870,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5,usability,Statu,Status,5,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:249,usability,command,command,249,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:731,usability,perform,performance,731,"Exit Status 247; Not sure what is causing the issue but upon reaching this step DeepVariant failed. Any thoughts on how to fix? I tired to run it in a python2.7 environment and still it somehow is pulling from python 3.6 it seems. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:1457,usability,perform,performance,1457,"t"". I0424 15:59:50.266534 139872277903104 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-04-24 15:59:50.321136: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations: AVX2 FMA. To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags. 2020-04-24 15:59:50.376605: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz. 2020-04-24 15:59:50.378224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56a1fd0 executing computations on platform Host. Devices:. 2020-04-24 15:59:50.378283: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-04-24 15:59:50.380979: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I0424 15:59:50.447775 139872277903104 modeling.py:563] Initializing model with random parameters. W0424 15:59:50.449538 139872277903104 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3bl4tsmc. I0424 15:59:50.450443 139872277903104 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3bl4tsmc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3659263518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:5771,usability,user,user,5771,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6286,usability,command,command,6286,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6469,usability,Command,Command,6469,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/304:6704,usability,statu,status,6704,"9872277903104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0424 16:00:02.682547 139872277903104 estimator.py:1149] Done calling model_fn. I0424 16:00:06.021238 139872277903104 monitored_session.py:240] Graph was finalized. I0424 16:00:06.037272 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:10.817819 139872277903104 session_manager.py:500] Running local_init_op. I0424 16:00:11.060626 139872277903104 session_manager.py:502] Done running local_init_op. I0424 16:00:12.403780 139872277903104 modeling.py:413] Reloading EMA... I0424 16:00:12.405867 139872277903104 saver.py:1284] Restoring parameters from /opt/models/wes/model.ckpt. I0424 16:00:48.634510 139872277903104 call_variants.py:402] Processed 1 examples in 1 batches [5816.472 sec per 100]. real	4m2.970s. user	5m54.674s. sys	1m14.107s. I0424 16:03:48.557898 140277446174464 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp9_28zx5u/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp9_28zx5u/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/304
https://github.com/google/deepvariant/issues/305:394,availability,error,error,394,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:901,availability,error,errors,901,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:936,availability,failur,failure,936,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:936,deployability,fail,failure,936,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:394,performance,error,error,394,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:901,performance,error,errors,901,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:936,performance,failur,failure,936,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:936,reliability,fail,failure,936,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:959,reliability,doe,does,959,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:394,safety,error,error,394,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:457,safety,input,input,457,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:588,safety,input,input,588,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:633,safety,input,input,633,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:901,safety,error,errors,901,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:394,usability,error,error,394,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:457,usability,input,input,457,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:588,usability,input,input,588,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:633,usability,input,input,633,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:901,usability,error,errors,901,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:915,usability,Command,Command,915,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/305:1024,usability,command,command,1024,"call mutation from multiple regions and multiple chromosomes; Hi, I am trying to call some targeted mutations from multiple targeted regions and chromosomes by Deepvariant. I followed the manual of make_examples.py to separate the multiple regions by space(https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L116), but it showed an error like the following:. sudo docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/Homo_sapiens_assembly19.fasta --reads=/input/proper.bam . --regions=""3:178936057-178936106 3:178952054-178952106"" . --output_vcf=/output/outputch3.vcf.gz --output_gvcf=/output/outputchr3.g.vcf.gz . --num_shards=1 --make_examples_extra_args vsc_min_fraction_snps=0.004. E0416 22:33:24.439428 140413429749504 errors.py:61] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_xs3AuO/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '3:178952054-178952106']"". I wonder whether this issue is due to the chromosome index of my sample is 1-22 without chr and how to run it with multiple regions and multiple chromosomes. Another issue is that when I changed the region to the bed file which includes all targeted regions, the variants called are all false-positive and none true variants included. . Furthermore, my sample is from deep sequencing on targeted regions. I have followed issue #62 to change the pileup_image_hight and downsample_fraction options, but the results are not improved. Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/305
https://github.com/google/deepvariant/issues/306:274,deployability,continu,continuous,274,"Pileup images for insersions; Hi, I'm trying to visualize the pileup images generated by DeepVariant. The images for SNP sites and deletions seem to be straightforward, but I found those for insertions are rather confusing. The reference lines for insertion sites are still continuous, and at the point where the insertion happens, the bases on the sequenced reads are set to 0. Here's part of an example of a homozygous ""A->AATAAAAT"" variant, the top 5 lines are the reference lines. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. The problem is these images are not presenting detailed infomation for the inserted sequence, and on sites where multiple insertions happen, the ""supports variant"" channel might become the only useful infomation to distinguish them. Also, on the ""base quality"" channel, the qualities for these 0-bases are not zeros, how are these values determined? I'm wondering if other structures of pileup images on these sites can achieve better performance, like adding 0s on the reference lines?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/306
https://github.com/google/deepvariant/issues/306:1272,performance,perform,performance,1272,"Pileup images for insersions; Hi, I'm trying to visualize the pileup images generated by DeepVariant. The images for SNP sites and deletions seem to be straightforward, but I found those for insertions are rather confusing. The reference lines for insertion sites are still continuous, and at the point where the insertion happens, the bases on the sequenced reads are set to 0. Here's part of an example of a homozygous ""A->AATAAAAT"" variant, the top 5 lines are the reference lines. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. The problem is these images are not presenting detailed infomation for the inserted sequence, and on sites where multiple insertions happen, the ""supports variant"" channel might become the only useful infomation to distinguish them. Also, on the ""base quality"" channel, the qualities for these 0-bases are not zeros, how are these values determined? I'm wondering if other structures of pileup images on these sites can achieve better performance, like adding 0s on the reference lines?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/306
https://github.com/google/deepvariant/issues/306:48,usability,visual,visualize,48,"Pileup images for insersions; Hi, I'm trying to visualize the pileup images generated by DeepVariant. The images for SNP sites and deletions seem to be straightforward, but I found those for insertions are rather confusing. The reference lines for insertion sites are still continuous, and at the point where the insertion happens, the bases on the sequenced reads are set to 0. Here's part of an example of a homozygous ""A->AATAAAAT"" variant, the top 5 lines are the reference lines. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. The problem is these images are not presenting detailed infomation for the inserted sequence, and on sites where multiple insertions happen, the ""supports variant"" channel might become the only useful infomation to distinguish them. Also, on the ""base quality"" channel, the qualities for these 0-bases are not zeros, how are these values determined? I'm wondering if other structures of pileup images on these sites can achieve better performance, like adding 0s on the reference lines?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/306
https://github.com/google/deepvariant/issues/306:983,usability,support,supports,983,"Pileup images for insersions; Hi, I'm trying to visualize the pileup images generated by DeepVariant. The images for SNP sites and deletions seem to be straightforward, but I found those for insertions are rather confusing. The reference lines for insertion sites are still continuous, and at the point where the insertion happens, the bases on the sequenced reads are set to 0. Here's part of an example of a homozygous ""A->AATAAAAT"" variant, the top 5 lines are the reference lines. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. The problem is these images are not presenting detailed infomation for the inserted sequence, and on sites where multiple insertions happen, the ""supports variant"" channel might become the only useful infomation to distinguish them. Also, on the ""base quality"" channel, the qualities for these 0-bases are not zeros, how are these values determined? I'm wondering if other structures of pileup images on these sites can achieve better performance, like adding 0s on the reference lines?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/306
https://github.com/google/deepvariant/issues/306:1272,usability,perform,performance,1272,"Pileup images for insersions; Hi, I'm trying to visualize the pileup images generated by DeepVariant. The images for SNP sites and deletions seem to be straightforward, but I found those for insertions are rather confusing. The reference lines for insertion sites are still continuous, and at the point where the insertion happens, the bases on the sequenced reads are set to 0. Here's part of an example of a homozygous ""A->AATAAAAT"" variant, the top 5 lines are the reference lines. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 250 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. 250 | 30 | 180 | 0 | 250 | 100 | 250. The problem is these images are not presenting detailed infomation for the inserted sequence, and on sites where multiple insertions happen, the ""supports variant"" channel might become the only useful infomation to distinguish them. Also, on the ""base quality"" channel, the qualities for these 0-bases are not zeros, how are these values determined? I'm wondering if other structures of pileup images on these sites can achieve better performance, like adding 0s on the reference lines?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/306
https://github.com/google/deepvariant/issues/307:13,availability,error,errors,13,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:362,availability,error,error,362,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:833,availability,error,error,833,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:178,deployability,fail,fail,178,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:215,deployability,fail,failing,215,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1095,deployability,Fail,Failed,1095," a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1321,deployability,modul,module,1321,"d and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2347,deployability,fail,failed,2347,"""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2590,deployability,fail,failed,2590,"g0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2833,deployability,fail,failed,2833,"es_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3268,deployability,modul,module,3268,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:25,energy efficiency,current,currently,25,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2277,energy efficiency,load,load,2277,"variant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. ap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3564,integrability,sub,subprocess,3564,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3657,integrability,sub,subprocess,3657,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3738,integrability,sub,subprocess,3738,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3819,integrability,buffer,buffer,3819,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1321,modifiability,modul,module,1321,"d and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3268,modifiability,modul,module,3268,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3328,modifiability,pac,packages,3328,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3428,modifiability,pac,packages,3428,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:13,performance,error,errors,13,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:362,performance,error,error,362,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:833,performance,error,error,833,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2277,performance,load,load,2277,"variant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. ap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2328,performance,parallel,parallel,2328,"p.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-pack",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2571,performance,parallel,parallel,2571,"Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2814,performance,parallel,parallel,2814,"58, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3778,performance,time,time,3778,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3794,performance,parallel,parallel,3794,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:178,reliability,fail,fail,178,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:215,reliability,fail,failing,215,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:264,reliability,doe,doesn,264,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1095,reliability,Fail,Failed,1095," a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2347,reliability,fail,failed,2347,"""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2590,reliability,fail,failed,2590,"g0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2833,reliability,fail,failed,2833,"es_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:13,safety,error,errors,13,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:362,safety,error,error,362,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:504,safety,input,input,504,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:670,safety,input,input,670,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:697,safety,input,input,697,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:833,safety,error,error,833,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:945,safety,input,input,945,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1067,safety,input,inputs,1067,"0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1123,safety,input,input,1123,"g else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1321,safety,modul,module,1321,"d and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2310,safety,input,input,2310,"10, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2413,safety,input,input,2413,"300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2439,safety,input,input,2439,"n, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2656,safety,input,input,2656,""", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/su",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2682,safety,input,input,2682,"e_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2899,safety,input,input,2899,"e ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2925,safety,input,input,2925,"g0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3268,safety,modul,module,3268,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3884,safety,input,input,3884,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3912,safety,input,input,3912,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1172,testability,Trace,Traceback,1172," fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3170,testability,Trace,Traceback,3170,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:5,usability,support,support,5,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:13,usability,error,errors,13,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:362,usability,error,error,362,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:433,usability,command,command,433,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:504,usability,input,input,504,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:670,usability,input,input,670,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:697,usability,input,input,697,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:833,usability,error,error,833,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:945,usability,input,input,945,"Cram support errors; I'm currently attempting to run Deepvariant 0.10.0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1067,usability,input,inputs,1067,"0 utilizing a cram file with a reference file. Everything else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:1123,usability,input,input,1123,"g else appears to be properly coded but it seems to fail upon reading the fa file. After failing it tries to fallback to an fai file that doesn't exist. I've tried it both compressed and uncompressed and it still seems to give the same error. Any ideas on what I should do here? . For reference Here is the command i'm running from Docker. sudo docker run \. -v ""${DATA_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/input/${REF}"" \. --reads=""/input/${BAM}"" \. --output_vcf=/output/${OUTPUT_VCF} \. --output_gvcf=/output/${OUTPUT_GVCF} \. --num_shards=$(nproc). . and here is the error i'm seeing right before crashing:. I0509 06:55:24.592304 140264323651328 genomics_reader.py:223] Reading /input/2009617.cram with NativeSamReader. I0509 06:55:24.597789 140264323651328 make_examples.py:535] Task 2/16: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fa.gz.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2310,usability,input,input,2310,"10, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2413,usability,input,input,2413,"300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2439,usability,input,input,2439,"n, args). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2656,usability,input,input,2656,""", line 1500, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/su",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2682,usability,input,input,2682,"e_examples_runner(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1358, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2899,usability,input,input,2899,"e ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:2925,usability,input,input,2925,"g0cod/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1264, in processing_regions_from_options. options.reference_filename).header.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3072,usability,user,user,3072,"ader.contigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3586,usability,command,command,3586,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3769,usability,Command,Command,3769,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3884,usability,input,input,3884,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:3912,usability,input,input,3912,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/307:4073,usability,statu,status,4073,"tigs. File ""/tmp/Bazel.runfiles_2jmg0cod/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__. fasta_path, fai_path, options). ValueError: Not found: could not load fasta and/or fai for fasta /input/hg19.fa.gz. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/hg19.fa.gz --reads /input/2009617.cram --examples /tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz --gvcf /tmp/tmpr2hdz82_/gvcf.tfrecord. @16.gz --task 7. real 0m5.299s. user 0m12.412s. sys 0m3.014s. I0509 06:55:25.059437 140033813915392 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 15 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg19.fa.gz"" --reads ""/input/2009617.cram"" --. examples ""/tmp/tmpr2hdz82_/make_examples.tfrecord@16.gz"" --gvcf ""/tmp/tmpr2hdz82_/gvcf.tfrecord@16.gz"" --task {}' returned non-zero exit status 1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/307
https://github.com/google/deepvariant/issues/308:12,energy efficiency,model,model,12,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:352,energy efficiency,model,model,352,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:574,energy efficiency,cloud,cloud,574,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:671,energy efficiency,adapt,adapted,671,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:671,integrability,adapt,adapted,671,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:580,interoperability,platform,platform,580,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:671,interoperability,adapt,adapted,671,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:671,modifiability,adapt,adapted,671,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:12,security,model,model,12,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:149,security,modif,modify,149,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:352,security,model,model,352,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:512,security,modif,modify,512,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/308:603,usability,guid,guideline,603,"train a new model for deep sequencing with the Linux system; Hi all,. I have read the discussion about deep sequencing on issue #62. I have tried to modify three options, downsample_fraction, pileup_image_height, and vsc_min_fraction_snps for our deep sequencing data but it didn't work and output many false-positive calls. Here I want to train a new model for deep sequencing data with rare somatic mutation(MAF~1%) and there is some confusion. 1) There is a maximum threshold for pileup_height of 362, can I modify it? 2) There is only one training tutorial with Google cloud platform, is there any guideline for training with the Linux system? 3) Can Deepvariant be adapted to a somatic mutation caller? Thanks a lot! Best regards,. Weiwei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/308
https://github.com/google/deepvariant/issues/309:152,availability,error,errors,152,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:186,deployability,Fail,Failed,186,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:302,deployability,log,log,302,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:425,modifiability,variab,variables,425,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:700,modifiability,Pac,PacBio,700,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:815,modifiability,PAC,PACBIO,815,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:847,modifiability,Pac,PacBio,847,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:152,performance,error,errors,152,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:186,reliability,Fail,Failed,186,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:0,safety,Input,Input,0,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:152,safety,error,errors,152,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:302,safety,log,log,302,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:302,security,log,log,302,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:302,testability,log,log,302,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:0,usability,Input,Input,0,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:152,usability,error,errors,152,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:375,usability,command,command,375,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:443,usability,command,command,443,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/309:1086,usability,help,help,1086,"Input file not found and argument n_shards not found; Hi. I am trying to apply variant calling on CCS reads of 16 samples. I am getting the following 2 errors:. 1. `[E::hts_open_format] Failed to open file /scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams/ARUM_R--ARUM_R_vsMelonv4.MD.bam`. 2. `/var/log/slurm/log_slurmd//job2563083/slurm_script: lnea 45: --num_shards=4: command not found. `. Below I present the defined variables and the command. `INPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/alignedBams""`. `OUTPUT_DIR=""/scratch/041-Melon-Reseq/Pacbio_targeted/DeepVariant""`. `NCPUS=4`. `BIN_VERSION=""0.10.0""`. singularity run. -B /usr/lib/locale/:/usr/lib/locale/ \. 	-B /home/kalexiou/PacBio/ \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=PACBIO \. 	--ref=/home/kalexiou/PacBio/Melon_v4.0_PacBio.fasta \. 	--reads=""${INPUT_DIR}""/${base} \. 	--regions ""chr05:24760000-27020000"" \. 	--output_vcf=""${OUTPUT_DIR}""/${name}.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/${name}.g.vcf.gz \ . 	--num_shards=""${NCPUS}"". Any help will be appreciated! Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/309
https://github.com/google/deepvariant/issues/310:45,availability,error,error,45,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:108,availability,avail,available,108,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:0,deployability,Fail,Failed,0,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:587,deployability,Fail,Failed,587,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:125,interoperability,specif,specified,125,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:45,performance,error,error,45,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:0,reliability,Fail,Failed,0,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:108,reliability,availab,available,108,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:587,reliability,Fail,Failed,587,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:45,safety,error,error,45,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:108,safety,avail,available,108,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:196,safety,input,input,196,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:346,safety,input,input,346,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:372,safety,input,input,372,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:378,safety,input,input,378,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:559,safety,input,inputs,559,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:615,safety,input,input,615,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:108,security,availab,available,108,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:45,usability,error,error,45,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:196,usability,input,input,196,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:346,usability,input,input,346,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:372,usability,input,input,372,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:378,usability,input,input,378,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:559,usability,input,inputs,559,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/310:615,usability,input,input,615,"Failed to open FASTA index; Hello,. I get an error about a missing index file for the used fasta. But it is available in the specified folder. BIN_VERSION=""0.10.0"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/hg19.fasta --reads=/input/input.bam --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=15. I0529 12:24:27.041167 139828907894528 make_examples.py:535] Task 5/15: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/hg19.fasta.fai: No such file or directory. Do you have any idea why this happens?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/310
https://github.com/google/deepvariant/issues/311:29,availability,consist,consistency,29,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1079,availability,consist,consistency,1079,"es (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1787,availability,consist,consistency,1787,"ts. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:2720,availability,consist,consistency,2720,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:139,deployability,pipelin,pipeline,139,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:367,deployability,contain,containing,367,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1151,deployability,contain,contained,1151,"dance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1859,deployability,contain,contained,1859,".25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:2792,deployability,contain,contained,2792,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:139,integrability,pipelin,pipeline,139,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:424,integrability,sub,substanial,424,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:3157,performance,time,time,3157,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:229,reliability,pra,practices,229,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:29,usability,consist,consistency,29,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:171,usability,document,documentation,171,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:507,usability,user,username,507,"High number of Indeterminate consistency in merged VCF; I recently took four cram files (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 21143",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1079,usability,consist,consistency,1079,"es (one family) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1091,usability,statu,status,1091,"amily) and put them through the deep variant pipeline in accordance with the documentation. I then followed the instructions for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1215,usability,user,username,1215,"for ""Best practices for multi-sample variant calling with DeepVariant (WES trio demonstration)"" and tried two sets of of ""trios"" and one comparison containing all four. Each of them however came up with a substanial amount of mendelian constraints which I'll list below:. Checking: /home/username/deepvariant-run/output/RBAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2115432]. 12 non-pass records were skipped. Concordance 2115432: F:127216/127862 (99.49%) M:121292/121882 (99.52%) F+M:79650/80917 (98.43%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both paren",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1787,usability,consist,consistency,1787,"ts. Check for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1799,usability,statu,status,1799," for incorrect pedigree or sample mislabelling. 4249/338863 (1.25%) records did not conform to expected call ploidy. 228759/338863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:1923,usability,user,username,1923,"38863 (67.51%) records were variant in at least 1 family member and checked for Mendelian constraints. 147067/228759 (64.29%) records had indeterminate consistency status due to incomplete calls. 1838/228759 (0.80%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:2720,usability,consist,consistency,2720,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:2732,usability,statu,status,2732,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:2929,usability,tool,tools,2929,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:3051,usability,tool,tools,3051,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/311:3092,usability,close,close,3092,"an constraints. Checking: /home/username/deepvariant-run/output/RBNs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617]. 18 non-pass records were skipped. Concordance 2009617: F:124581/125097 (99.59%) M:120027/120545 (99.57%) F+M:79289/80523 (98.47%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 3705/295693 (1.25%) records did not conform to expected call ploidy. 184648/295693 (62.45%) records were variant in at least 1 family member and checked for Mendelian constraints. 103541/184648 (56.07%) records had indeterminate consistency status due to incomplete calls. 1603/184648 (0.87%) records contained a violation of Mendelian constraints. Checking: /home/username/deepvariant-run/output/RBNAs.cohort.vcf.gz. Family: [2114337 + 2114302] -> [2009617, 2115432]. 24 non-pass records were skipped. Concordance 2009617: F:125675/126263 (99.53%) M:121023/121623 (99.51%) F+M:79766/81139 (98.31%). Sample 2009617 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. Concordance 2115432: F:128175/128895 (99.44%) M:122173/122833 (99.46%) F+M:80026/81440 (98.26%). Sample 2115432 has less than 99.0 concordance with both parents. Check for incorrect pedigree or sample mislabelling. 4510/361421 (1.25%) records did not conform to expected call ploidy. 286909/361421 (79.38%) records were variant in at least 1 family member and checked for Mendelian constraints. 197595/286909 (68.87%) records had indeterminate consistency status due to incomplete calls. 3231/286909 (1.13%) records contained a violation of Mendelian constraints. I'm not sure if the issue is within the deepvariant scan or perhaps the merge within RTG tools. If you have seen this problem before i'm open to any suggestions. Additionally if this issue is more so on the RTG tools side if things please feel free to close this out and I'll open the issue there. Thank you for your time and have a great day.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/311
https://github.com/google/deepvariant/issues/312:782,availability,down,downsampling,782,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:862,availability,down,downsampling,862,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1502,availability,down,downsampling,1502,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:713,energy efficiency,optim,optimistically,713,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1961,energy efficiency,model,model,1961,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:223,interoperability,specif,specifically,223,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:185,performance,perform,performance,185,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1365,reliability,doe,does,1365,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:942,safety,valid,validation,942,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1335,safety,valid,validation,1335,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:942,security,validat,validation,942,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1335,security,validat,validation,1335,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1961,security,model,model,1961,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:185,usability,perform,performance,185,"Advice for retraining on multiple samples; Hello, after some quite impressive results applying HiSeq-trained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1463,usability,effectiv,effectively,1463,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1827,usability,support,support,1827,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/312:1995,usability,tool,tool,1995,"rained DeepVariant on MGISEQ-2000 data, I've been working on achieving even better performance by retraining DeepVariant specifically for the MGISEQ-2000. To do this I've been broadly following the sketch at https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-training-case-study.md. I now have unshuffled tfrecords for six reference samples, and have some questions about next steps. Because it might be relevant to the questions, my data are structured as follows:. * 6 samples (4xHG001/NA12878, 2xHG005/NA24631), each with:. * 25 tfrecord shards (00000-00024) of chr1, for tuning (perhaps over-optimistically) . * 247 tfrecord shards (00000-00246) of chr2-19, no downsampling, for training. * 247 tfrecord shards (00000-00246) of chr2-19, 50% downsampling, for training. * 17 tfrecord shards (00000-00016) of chr20-22, for validation. My questions are:. 1. Is it necessary to shuffle the training data? I ask as it's proving to be a bit laborious to set up, and so I'm hoping that I can get around it. Given I have so many shards, if I just shuffle the order of the chr2-19 shards when I supply them to the training loop, will this be almost as good as shuffling the whole dataset? 2. Is it necessary to shuffle the validation data? The tutorial does this, but I'm not sure why. 3. How can I supply multiple datasets to the training loop (here effectively 12 datasets: 6 samples x 2 downsampling settings)? In the tutorial, `model_train` is supplied a wildcard path of `validation_set.with_label.shuffled-?????-of-?????.tfrecord.gz`, which seems like it would only work for a single sample, and I'm not sure how this will work with multiple samples. 4. Have there been any changes to the code base to better support warmstarting, or is the advice at https://github.com/google/deepvariant/issues/185 still the best approach to fine-tuning the model? DeepVariant is a fantastic tool and I'm very much looking forward to seeing what it can do with these data, so many thanks in advance.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/312
https://github.com/google/deepvariant/issues/313:29,availability,fault,fault,29,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:200,availability,fault,fault,200,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:206,availability,error,error,206,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:447,deployability,log,logs,447,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:557,deployability,log,logs,557,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:562,deployability,log,log,562,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:574,deployability,log,logs,574,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:761,deployability,log,log,761,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:838,deployability,log,log,838,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:29,energy efficiency,fault,fault,29,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:200,energy efficiency,fault,fault,200,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:312,energy efficiency,MODEL,MODEL,312,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:324,energy efficiency,model,models,324,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:338,energy efficiency,model,model,338,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:872,interoperability,share,share,872,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:143,modifiability,Pac,Pacbio,143,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:331,modifiability,pac,pacbio,331,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:29,performance,fault,fault,29,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:200,performance,fault,fault,200,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:206,performance,error,error,206,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:462,performance,time,time,462,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:494,performance,parallel,parallel,494,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:29,reliability,fault,fault,29,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:200,reliability,fault,fault,200,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:29,safety,fault,fault,29,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:200,safety,fault,fault,200,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:206,safety,error,error,206,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:434,safety,input,input,434,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:447,safety,log,logs,447,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:557,safety,log,logs,557,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:562,safety,log,log,562,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:574,safety,log,logs,574,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:761,safety,log,log,761,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:838,safety,log,log,838,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:312,security,MODEL,MODEL,312,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:324,security,model,models,324,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:338,security,model,model,338,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:447,security,log,logs,447,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:557,security,log,logs,557,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:562,security,log,log,562,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:574,security,log,logs,574,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:761,security,log,log,761,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:838,security,log,log,838,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:447,testability,log,logs,447,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:557,testability,log,logs,557,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:562,testability,log,log,562,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:574,testability,log,logs,574,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:761,testability,log,log,761,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:838,testability,log,log,838,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:206,usability,error,error,206,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/313:434,usability,input,input,434,"Troubleshooting segmentation fault ; Dear deepvariant developers,. I'm using deepvariant (0.10.0) to call variants in HG002 human genome using Pacbio hifi sequencing data. However, I am getting a seg-fault error in the process. . ```. REF=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna. BAM=output.primary.bam. MODEL=""/opt/models/pacbio/model.ckpt"". N_SHARDS=24. CALL_VARIANTS_OUTPUT=""output/call_variants_output.tfrecord.gz"". mkdir input output logs. /usr/bin/time seq 0 $((N_SHARDS-1)) \. | parallel -P ${SLURM_CPUS_PER_TASK} --eta --halt 2 \. --joblog ""logs/log"" --res ""logs"" \. make_examples --mode calling \. --ref ""${REF}"" \. --reads ""${wd}/${BAM}"" \. --examples output/examples.tfrecord@${N_SHARDS}.gz\. --task {} \. || exit 1. ```. Here is the [output log file](https://github.com/google/deepvariant/files/4714025/slurm-58983130.log). Please let me know if I can share more details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/313
https://github.com/google/deepvariant/issues/314:36,availability,error,error,36,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:273,availability,error,error,273,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:219,deployability,log,logdir,219,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:228,deployability,log,log,228,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:781,deployability,modul,module,781,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1242,deployability,fail,failed,1242,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1543,deployability,instal,installed,1543,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1569,deployability,instal,install,1569,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1624,deployability,instal,install,1624,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1670,deployability,instal,installed,1670,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:661,interoperability,share,share,661,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:824,interoperability,share,share,824,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:983,interoperability,share,share,983,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1318,interoperability,share,share,1318,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:781,modifiability,modul,module,781,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:36,performance,error,error,36,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:273,performance,error,error,273,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1223,performance,parallel,parallel,1223,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1242,reliability,fail,failed,1242,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:36,safety,error,error,36,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:219,safety,log,logdir,219,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:228,safety,log,log,228,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:273,safety,error,error,273,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:781,safety,modul,module,781,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:219,security,log,logdir,219,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:228,security,log,log,228,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:219,testability,log,logdir,219,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:228,testability,log,log,228,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:368,testability,Trace,Traceback,368,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:36,usability,error,error,36,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:118,usability,command,command,118,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:273,usability,error,error,273,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/314:1583,usability,command,command,1583,"Conda: dv_make_example.py execution error. ; Hi, . I had trouble running Deepvariant using conda. I ran the following command. ```. dv_make_examples.py --sample {MY_SAMPLE} --ref {MY_FASTA}.fasta --reads {MY_BAM}.bam --logdir ./log/ --examples examples/. ```. and I got an error like this:. ```. ETA: 0s Left: 1 AVG: 0.00s local:1/0/100%/0.0s sh: 1: unzip: not found. Traceback (most recent call last):. File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/opt/conda/envs/deepvariant/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 252, in <module>. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 187, in Main. File ""/opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip/__main__.py"", line 138, in GetRepositoriesImports. FileNotFoundError: [Errno 2] No such file or directory: '/tmp/Bazel.runfiles_qwsw52c7/runfiles'. parallel: This job failed:. /opt/conda/envs/deepvariant/bin/python /opt/conda/envs/deepvariant/share/deepvariant-0.10.0-3/binaries/DeepVariant/0.10.0/DeepVariant-0.10.0/make_examples.zip --mode calling --ref E.coli_K12_MG1655.fa --reads SRR1770413.bam --examples examples//SRR1770413.tfrecord@1.gz --task 0. ```. When I installed unzip by `conda install`, the command worked fine. When using conda to install deepvariant, should it not have to be installed together? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/314
https://github.com/google/deepvariant/issues/315:933,deployability,modul,module,933,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:470,integrability,buffer,buffer,470,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1229,integrability,sub,subprocess,1229,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1322,integrability,sub,subprocess,1322,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1403,integrability,sub,subprocess,1403,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1478,integrability,buffer,buffer,1478,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:31,modifiability,concern,concern,31,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:933,modifiability,modul,module,933,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:993,modifiability,pac,packages,993,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1093,modifiability,pac,packages,1093,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:435,performance,time,time,435,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:451,performance,parallel,parallel,451,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1443,performance,time,time,1443,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1459,performance,parallel,parallel,1459,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:535,safety,input,input,535,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:573,safety,input,input,573,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:933,safety,modul,module,933,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1543,safety,input,input,1543,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1581,safety,input,input,1581,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:31,testability,concern,concern,31,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:835,testability,Trace,Traceback,835,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:5,usability,statu,status,5,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:334,usability,guidanc,guidance,334,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:420,usability,command,command,420,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:535,usability,input,input,535,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:573,usability,input,input,573,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:804,usability,user,user,804,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1251,usability,command,command,1251,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1434,usability,Command,Command,1434,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1543,usability,input,input,1543,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1581,usability,input,input,1581,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/315:1820,usability,statu,status,1820,"exit status 55; To whom it may concern,. I have created an openstack instance to run deepvariant 0.9.0 as detailed below. I had no problem running deepvariant in another openstack instance, but I cannot figure out why it will not work in the instance that I newly created. I was wondering if deepvariant developers could provide some guidance towards running deepvariant again. Regards,. Sangjin. ```. ***** Running the command:*****. time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}. real 0m1.608s. user 0m25.676s. sys 0m23.860s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 54 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ilAriAges1.fasta.bgz"" --reads ""/input/ilAriAges1.m64097_191226_203354.minimap2_asm20.primary_alignments.sorted.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@55.gz"" --norealign_reads --vsc_min_fraction_indels ""0.12"" --task {}' returned non-zero exit status 55. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/315
https://github.com/google/deepvariant/issues/316:396,deployability,log,logdir,396,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:278,energy efficiency,core,cores,278,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:440,energy efficiency,core,cores,440,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:569,energy efficiency,model,model,569,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:576,energy efficiency,model,model,576,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:152,modifiability,pac,package,152,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:396,safety,log,logdir,396,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:396,security,log,logdir,396,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:569,security,model,model,569,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:576,security,model,model,576,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:396,testability,log,logdir,396,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:36,usability,command,command,36,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:131,usability,command,command,131,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/316:741,usability,command,command,741,"conda: where is the run_deepvariant command; Hi, @chapmanb. Sorry for asking so many questions. I looked for the `run_deepvariant` command in the conda package, but the I couldn't find it. So to generate the vcf file, I created the following code. ```. dv_make_examples.py \. --cores {threads} \. --ref {ref} \. --reads {bam} \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --logdir {log_dir} . dv_call_variants.py \. --cores {threads} \. --outfile {output_dir}/{samplename}.tmp \. --sample {samplename} \. --examples {output_dir}/{samplename} \. --model {model} . dv_postprocess_variants.py \. --ref {ref} \. --infile {output_dir}/{samplename}.tmp \. --outfile {vcf}. ```. Or is there a way to run the `run_deepvariant` command that I am just not aware of? I'd like to generate a gvcf file if possible.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/316
https://github.com/google/deepvariant/issues/317:244,availability,error,errors,244,"Is it possible that the GAIB high-confidence VCFs have erroneous sites?; Hi. I tried to investigate the ADs and VAFs of sites with label '0' in the training data. In most cases, hom-ref sites have very low ADs, which is generated by sequencing errors. However, about 3% of the total examples (about 20000) have AD values greater than 10, yet still labeled as hom-ref. For example, in the BAM I'm studying, the following site. 4:39708091-39708091 C->CT DP:AD:VAF 46:28,15:0.326087. is found, and labeled as hom-ref. Most of these sites (about 98% of which) are short-tandem-repeats (STR), the reference bases are . CTTTTTTTTTTTTTTTTTCCCAGATGGAAT. at the mentioned site. It seems the GIAB high-confidence VCFs have missed quite a few STR sites (which are within the high-confidence regions). My question is, would these mislabeled sites pollute the training set of DeepVariant, and lead to a higher FN rate? Could this be fixed by, for example, adding an STR/non-STR channel?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/317
https://github.com/google/deepvariant/issues/317:244,performance,error,errors,244,"Is it possible that the GAIB high-confidence VCFs have erroneous sites?; Hi. I tried to investigate the ADs and VAFs of sites with label '0' in the training data. In most cases, hom-ref sites have very low ADs, which is generated by sequencing errors. However, about 3% of the total examples (about 20000) have AD values greater than 10, yet still labeled as hom-ref. For example, in the BAM I'm studying, the following site. 4:39708091-39708091 C->CT DP:AD:VAF 46:28,15:0.326087. is found, and labeled as hom-ref. Most of these sites (about 98% of which) are short-tandem-repeats (STR), the reference bases are . CTTTTTTTTTTTTTTTTTCCCAGATGGAAT. at the mentioned site. It seems the GIAB high-confidence VCFs have missed quite a few STR sites (which are within the high-confidence regions). My question is, would these mislabeled sites pollute the training set of DeepVariant, and lead to a higher FN rate? Could this be fixed by, for example, adding an STR/non-STR channel?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/317
https://github.com/google/deepvariant/issues/317:244,safety,error,errors,244,"Is it possible that the GAIB high-confidence VCFs have erroneous sites?; Hi. I tried to investigate the ADs and VAFs of sites with label '0' in the training data. In most cases, hom-ref sites have very low ADs, which is generated by sequencing errors. However, about 3% of the total examples (about 20000) have AD values greater than 10, yet still labeled as hom-ref. For example, in the BAM I'm studying, the following site. 4:39708091-39708091 C->CT DP:AD:VAF 46:28,15:0.326087. is found, and labeled as hom-ref. Most of these sites (about 98% of which) are short-tandem-repeats (STR), the reference bases are . CTTTTTTTTTTTTTTTTTCCCAGATGGAAT. at the mentioned site. It seems the GIAB high-confidence VCFs have missed quite a few STR sites (which are within the high-confidence regions). My question is, would these mislabeled sites pollute the training set of DeepVariant, and lead to a higher FN rate? Could this be fixed by, for example, adding an STR/non-STR channel?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/317
https://github.com/google/deepvariant/issues/317:244,usability,error,errors,244,"Is it possible that the GAIB high-confidence VCFs have erroneous sites?; Hi. I tried to investigate the ADs and VAFs of sites with label '0' in the training data. In most cases, hom-ref sites have very low ADs, which is generated by sequencing errors. However, about 3% of the total examples (about 20000) have AD values greater than 10, yet still labeled as hom-ref. For example, in the BAM I'm studying, the following site. 4:39708091-39708091 C->CT DP:AD:VAF 46:28,15:0.326087. is found, and labeled as hom-ref. Most of these sites (about 98% of which) are short-tandem-repeats (STR), the reference bases are . CTTTTTTTTTTTTTTTTTCCCAGATGGAAT. at the mentioned site. It seems the GIAB high-confidence VCFs have missed quite a few STR sites (which are within the high-confidence regions). My question is, would these mislabeled sites pollute the training set of DeepVariant, and lead to a higher FN rate? Could this be fixed by, for example, adding an STR/non-STR channel?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/317
https://github.com/google/deepvariant/issues/318:955,availability,avail,available,955,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:915,deployability,observ,observed,915,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:344,integrability,FILTER,FILTER,344,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:441,integrability,filter,filter,441,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:507,integrability,FILTER,FILTER,507,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:968,integrability,filter,filter,968,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:109,interoperability,format,format,109,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:299,interoperability,format,format,299,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:523,interoperability,FORMAT,FORMAT,523,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:312,reliability,doe,does,312,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:955,reliability,availab,available,955,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:1084,reliability,doe,does,1084,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:955,safety,avail,available,955,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:955,security,availab,available,955,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/318:915,testability,observ,observed,915,"Can we generate .VCF file with information for all position including homozygous references and not in block format; I have a few queries about your output:-. 1) Can we generate VCF file with each position information? 2) Is it possible to convert g.VCF to VCF since commonly used software used VCF format? What does QUAL ""0"" mean in VCF? Some FILTER column with QUAL 0 is marked as ""RefCall"" while some as ""."" Can you please explain how is filter decided in VCF? 3). #CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | DRR015476. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 1 | . | A | <*> | 0 | . | END=587 | GT:GQ:MIN_DP:PL | 0/0:1:0:0,0,0. -- | -- | -- | -- | -- | -- | -- | -- | -- | --. 6 | 588 | . | A | <*> | 0 | . | END=588 | GT:GQ:MIN_DP:PL | ./.:0:1:29,3,0. Both the row has QUAL value ""0"". Then why is first row has given homozygous call and the second row with now call? 4) I have observed that there are **three options available in filter column**. RefCall:- Which would mean Homozygous reference . PASS:- Can be homozygous/Heterozygous. . :- what does this mean?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/318
https://github.com/google/deepvariant/issues/319:893,deployability,log,log,893,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1115,deployability,log,log,1115,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:515,modifiability,paramet,parameters,515,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1214,modifiability,paramet,parameter,1214,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1275,modifiability,variab,variables,1275,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1779,modifiability,paramet,parameters,1779,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:822,performance,time,time,822,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:854,performance,parallel,parallel,854,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:893,safety,log,log,893,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1115,safety,log,log,1115,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:893,security,log,log,893,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1115,security,log,log,1115,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:893,testability,log,log,893,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:1115,testability,log,log,1115,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:45,usability,command,command,45,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:478,usability,command,command,478,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:535,usability,command,command,535,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:657,usability,support,support,657,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/319:740,usability,support,support,740,"Run post process variants ; i have used this command to run deep variant and generate VCF file. sudo docker run -v `pwd`:`pwd` -w `pwd` google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=${base_path}/${ref_file_name}.fasta --reads=${base_path}/base_recalib/$i\_vqsr.bam --output_vcf=deep_variant_results/$i\.vcf.gz --output_gvcf=deep_variant_results/$i\.g.vcf.gz. I want to run post-process variants but cannot get it from the above command. 1) Is there some way to add parameters to above command? 2) I found two links related to it:-. a) [https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-gvcf-support.md). GVCF_TFRECORDS=""${OUTPUT_DIR}/HG002.gvcf.tfrecord@${N_SHARDS}.gz"". ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --gvcf ""${GVCF_TFRECORDS}"" \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. There is no make_examples.zip in the bin directory and what should be supplied to this parameter --examples. Can you please give more details about variables? b) [https://github.com/google/deepvariant/issues/103](https://github.com/google/deepvariant/issues/103). sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. This is another way and parameters are also different. how to define the infile here?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/319
https://github.com/google/deepvariant/issues/320:1004,deployability,resourc,resources,1004,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:607,energy efficiency,model,model,607,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:713,energy efficiency,model,model,713,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:814,energy efficiency,model,model,814,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:961,energy efficiency,model,model,961,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:1004,energy efficiency,resourc,resources,1004,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:1104,energy efficiency,model,model,1104,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:1080,integrability,pub,publish,1080,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:397,interoperability,specif,specific,397,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:990,performance,computational resourc,computational resources,990,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:1004,safety,resourc,resources,1004,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:64,security,Team,Team,64,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:607,security,model,model,607,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:713,security,model,model,713,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:814,security,model,model,814,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:961,security,model,model,961,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:1104,security,model,model,1104,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:745,testability,understand,understand,745,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:775,testability,understand,understand,775,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:1004,testability,resourc,resources,1004,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:224,usability,help,help,224,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/320:900,usability,efficien,efficiency,900,"Questions about Details of Applying DeepVariant; Hi DeepVariant Team,. I am exploring the potentiality of applying deepvariant in our project. And I have several questions that cannot be found in your paper. May I have your help? 1. Is your method also applicable to low-depth sequencing data or mainly applicable to high-depth sequencing data? 2. How could you organize your training data? To be specific, do you consider one variant of one chromosome of one individual as one tensor for training (one training case), and put all this kind of variants together as your training set to generate one trained model without considering if they are in the same chromosome or from one individual, rather than training model for each chromosome? Do I understand it correctly? If I understand it correctly -- one trained model for training variants across different chromosomes and individuals, what is the efficiency? Or how long will it take to generate one trained model and under what kind of computational resources, as well as how many variants are in your training set? 3. Do you publish any pre-trained model so that we can directly apply to our data to impute our variants? I am not sure if it is proper to ask this kind of question here, so please feel free to delete it if here is not for this kind of question. Thank you very much. Best regards,. Min-Zhi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/320
https://github.com/google/deepvariant/issues/321:5,availability,Error,Errors,5,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:175,availability,error,errors,175,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:588,availability,checkpoint,checkpoint,588,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1066,availability,servic,service,1066,"ently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/str",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1074,availability,servic,service,1074,"aying a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_exec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1094,availability,servic,service,1094,"ith the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1217,availability,servic,service,1217," sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1225,availability,servic,service,1225," the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3202,availability,Cluster,ClusterSpec,3202,"/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4494,availability,slo,sloppy,4494,"tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5548,availability,operat,operator,5548,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:117,deployability,version,version,117,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1066,deployability,servic,service,1066,"ently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/str",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1074,deployability,servic,service,1074,"aying a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_exec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1094,deployability,servic,service,1094,"ith the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1217,deployability,servic,service,1217," sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1225,deployability,servic,service,1225," the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1282,deployability,Version,Version,1282,"king devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO ver",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1515,deployability,fail,failed,1515,"cord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2003,deployability,version,version,2003," Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2129,deployability,version,version,2129,"s on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_ser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2246,deployability,version,version,2246,"cutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_ty",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2283,deployability,version,version,2283,"on. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_globa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2340,deployability,configurat,configuration,2340,"/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': ''",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3202,deployability,Cluster,ClusterSpec,3202,"/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3858,deployability,version,version,3858,"t_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3884,deployability,updat,updating,3884,"_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4324,deployability,version,version,4324,"luation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4350,deployability,updat,updating,4350,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4935,deployability,version,version,4935,"o layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4961,deployability,updat,updating,4961,"30541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5488,deployability,version,version,5488,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5514,deployability,updat,updating,5514,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5816,deployability,version,version,5816,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5842,deployability,updat,updating,5842,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6217,deployability,version,version,6217,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6264,deployability,instal,installed,6264,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6288,deployability,version,version,6288,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:66,energy efficiency,current,currently,66,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:106,energy efficiency,GPU,GPU,106,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:234,energy efficiency,GPU,GPU,234,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:605,energy efficiency,model,models,605,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:616,energy efficiency,model,model,616,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:754,energy efficiency,core,core,754,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:799,energy efficiency,CPU,CPU,799,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:937,energy efficiency,core,core,937,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:982,energy efficiency,CPU,CPU,982,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:986,energy efficiency,Frequenc,Frequency,986,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2393,energy efficiency,model,modeling,2393,"pened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2423,energy efficiency,model,model,2423,".so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2491,energy efficiency,estimat,estimator,2491,"uda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2536,energy efficiency,model,model,2536,"UDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2609,energy efficiency,estimat,estimator,2609,"uda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5108,energy efficiency,optim,optimizations,5108,"iles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and execu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5210,energy efficiency,estimat,estimator,5210," (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5383,energy efficiency,model,modeling,5383,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5935,energy efficiency,estimat,estimator,5935,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6152,energy efficiency,gpu,gpus,6152,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:117,integrability,version,version,117,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1066,integrability,servic,service,1066,"ently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/str",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1074,integrability,servic,service,1074,"aying a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_exec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1094,integrability,servic,service,1094,"ith the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1217,integrability,servic,service,1217," sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1225,integrability,servic,service,1225," the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1282,integrability,Version,Version,1282,"king devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO ver",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2003,integrability,version,version,2003," Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2129,integrability,version,version,2129,"s on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_ser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2246,integrability,version,version,2246,"cutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_ty",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2283,integrability,version,version,2283,"on. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_globa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2340,integrability,configur,configuration,2340,"/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': ''",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3858,integrability,version,version,3858,"t_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4324,integrability,version,version,4324,"luation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4879,integrability,batch,batching,4879," updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` me",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4935,integrability,version,version,4935,"o layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5057,integrability,batch,batch,5057,"40322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5488,integrability,version,version,5488,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5816,integrability,version,version,5816,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6217,integrability,version,version,6217,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6288,integrability,version,version,6288,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:759,interoperability,platform,platform,759,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:942,interoperability,platform,platform,942,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1138,interoperability,platform,platform,1138,"10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1348,interoperability,platform,platform,1348,"g went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuratio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:117,modifiability,version,version,117,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1066,modifiability,servic,service,1066,"ently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/str",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1074,modifiability,servic,service,1074,"aying a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_exec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1094,modifiability,servic,service,1094,"ith the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1217,modifiability,servic,service,1217," sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1225,modifiability,servic,service,1225," the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1282,modifiability,Version,Version,1282,"king devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO ver",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2003,modifiability,version,version,2003," Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2129,modifiability,version,version,2129,"s on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_ser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2246,modifiability,version,version,2246,"cutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_ty",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2283,modifiability,version,version,2283,"on. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_globa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2340,modifiability,configur,configuration,2340,"/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': ''",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2441,modifiability,paramet,parameters,2441,":18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 14032",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3640,modifiability,pac,packages,3640,"model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3858,modifiability,version,version,3858,"t_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3941,modifiability,layer,layers,3941,"'_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4324,modifiability,version,version,4324,"luation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4935,modifiability,version,version,4935,"o layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5488,modifiability,version,version,5488,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5669,modifiability,pac,packages,5669,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5686,modifiability,layer,layers,5686,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5693,modifiability,layer,layers,5693,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5709,modifiability,Layer,Layer,5709,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5816,modifiability,version,version,5816,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5865,modifiability,layer,layer,5865,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6217,modifiability,version,version,6217,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6288,modifiability,version,version,6288,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5,performance,Error,Errors,5,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:106,performance,GPU,GPU,106,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:175,performance,error,errors,175,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:234,performance,GPU,GPU,234,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:425,performance,time,time,425,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:799,performance,CPU,CPU,799,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:982,performance,CPU,CPU,982,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4879,performance,batch,batching,4879," updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` me",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5057,performance,batch,batch,5057,"40322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5108,performance,optimiz,optimizations,5108,"iles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and execu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6152,performance,gpu,gpus,6152,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:588,reliability,checkpoint,checkpoint,588,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1515,reliability,fail,failed,1515,"cord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1741,reliability,diagno,diagnostic,1741,"sorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoint",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2264,reliability,doe,does,2264,": Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4494,reliability,slo,sloppy,4494,"tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5,safety,Error,Errors,5,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:175,safety,error,errors,175,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3884,safety,updat,updating,3884,"_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4350,safety,updat,updating,4350,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4961,safety,updat,updating,4961,"30541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5514,safety,updat,updating,5514,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5842,safety,updat,updating,5842,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:52,security,team,team,52,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:605,security,model,models,605,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:616,security,model,model,616,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2340,security,configur,configuration,2340,"/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': ''",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2393,security,model,modeling,2393,"pened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2423,security,model,model,2423,".so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:2536,security,model,model,2536,"UDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:3884,security,updat,updating,3884,"_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f0f102630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4350,security,updat,updating,4350,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0703 17:18:45.714398 140322304501504 call_variants.py:384] Writing calls to /tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz. W0703 17:18:45.719665 140322304501504 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. I0703 17:18:45.730541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:4961,security,updat,updating,4961,"30541 140322304501504 data_providers.py:369] self.input_read_threads=8. W0703 17:18:45.730644 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:374: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5383,security,model,modeling,5383,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5514,security,updat,updating,5514,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5842,security,updat,updating,5842,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:1741,testability,diagno,diagnostic,1741,"sorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 410.129.0. 2020-07-03 17:18:45.680416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0. 2020-07-03 17:18:45.680422: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.113.0 does not match DSO version 410.129.0 -- cannot find working devices in this configuration. I0703 17:18:45.713418 140322304501504 modeling.py:563] Initializing model with random parameters. W0703 17:18:45.713950 140322304501504 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp7amyb_ws. I0703 17:18:45.714213 140322304501504 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp7amyb_ws', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoint",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:5,usability,Error,Errors,5,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:175,usability,error,errors,175,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:410,usability,command,command,410,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:803,usability,support,supports,803,"CUDA Errors in call_variants step; Dear deepvariant team,. we are currently playing a bit around with the GPU docker version of deepvariant 0.10.0. I've noticed the following errors in the ""call_variants"" step and I'm not sure if the GPU is used correctly in this step (""cannot find working devices"" ???) or if this is just a warning because the calling went through without any abort:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmp7l6e69ft/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmp7l6e69ft/make_examples.tfrecord@25.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0703 17:18:45.593843 140322304501504 call_variants.py:316] Set KMP_BLOCKTIME to 0. 2020-07-03 17:18:45.625121: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-07-03 17:18:45.661204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz. 2020-07-03 17:18:45.667182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f919f0 executing computations on platform Host. Devices:. 2020-07-03 17:18:45.667206: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-07-03 17:18:45.674475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-07-03 17:18:45.680312: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. 2020-07-03 17:18:45.680339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 7c1895dbad7c. 2020-07-03 17:18:45.680346: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 7c1895dbad7c. 2020-07-03 17:18:45.680397: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda report",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/321:6335,usability,help,help,6335,"pdating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. I0703 17:18:45.810746 140322304501504 data_providers.py:376] self.input_map_threads=48. W0703 17:18:45.810852 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0703 17:18:46.328745 140322304501504 estimator.py:1147] Calling model_fn. W0703 17:18:46.330687 140322304501504 deprecation.py:323] From /tmp/Bazel.runfiles_m65fk12g/runfiles/com_google_deepvariant/deepvariant/modeling.py:885: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. W0703 17:18:46.333346 140322304501504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0703 17:18:50.712157 140322304501504 estimator.py:1149] Done calling model_fn. I0703 17:18:51.788142 140322304501504 monitored_session.py:240] Graph was finalized. ```. We are on Docker 19.03.11 on Debian 10 and executed deepvariant with ```docker run --gpus all ....``` (proposed way of using nvidia docker for Docker version >19.03 in the nvidia docker docs). Our installed Nvidia driver version is 418.113. Thanks in advance for your help,. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/321
https://github.com/google/deepvariant/issues/322:693,availability,error,error,693,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:721,availability,error,error,721,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:378,energy efficiency,gpu,gpu,378,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:378,performance,gpu,gpu,378,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:693,performance,error,error,693,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:721,performance,error,error,721,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:283,safety,input,input,283,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:498,safety,input,input,498,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:693,safety,error,error,693,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:721,safety,error,error,721,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:1083,safety,input,input,1083,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:1303,safety,input,input,1303,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:123,usability,command,command,123,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:283,usability,input,input,283,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:498,usability,input,input,498,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:693,usability,error,error,693,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:721,usability,error,error,721,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:798,usability,help,helpshort,798,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:813,usability,help,helpfull,813,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:829,usability,help,help,829,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:1083,usability,input,input,1083,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/322:1303,usability,input,input,1303,"singularity can not find the paths; Dear,. I tried to use the singularity to run the DeepVariant docker with the following command:. BIN_VERSION=""0.10.0"". OUTPUT_DIR=$fpath. INPUT_DIR=$fpath. REF=$refpath ;. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ -B ${INPUT_DIR}:/input -B ${OUTPUT_DIR}:/output -B ${REF}:/ref \. 		docker://google/deepvariant:""${BIN_VERSION}-gpu"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \ . 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=150 ;. unfortunately, it's not working and give me the following error:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. line 82: --ref=/ref/human_g1k_v37.fasta: No such file or directory. FYI: Same Structure fro the Docker itself is working. 	BIN_VERSION=""0.10.0"". 		OUTPUT_DIR=$fpath. 		INPUT_DIR=$fpath. 		REF=$refpath ;. 		sudo docker run -v ${INPUT_DIR}:/input -v ${OUTPUT_DIR}:/output -v ${REF}:/ref \. 		gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. 		/opt/deepvariant/bin/run_deepvariant \. 		--model_type=WES \. 		--ref=/ref/human_g1k_v37.fasta \. 		--reads=/input/""${fname}.bam"" \. 		--output_vcf=/output/""${fname}.vcf.gz"" \. 		--output_gvcf=/output/""${fname}.g.vcf.gz"" \. 		--num_shards=45 ;. 	. Kind regards . Amin.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/322
https://github.com/google/deepvariant/issues/323:338,testability,coverag,coverage,338,"Why are mitochondrial chromosomes excluded?; https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/exclude_contigs.py#L43. I just noticed that mitochondrial chromosomes are blacklisted along with alt contigs. I just wondered what the reasoning was behind this. Is this because of the much higher coverage, the different ploidy expectations, or something else I'm not thinking of. Also, is it possible to override the blacklist?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/323
https://github.com/google/deepvariant/issues/324:47,performance,perform,perform,47,"VQSR and truth sets; Hello,. There is a way to perform some kind of VQSR or use truth sets for calling on Deepvariant? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/324
https://github.com/google/deepvariant/issues/324:47,usability,perform,perform,47,"VQSR and truth sets; Hello,. There is a way to perform some kind of VQSR or use truth sets for calling on Deepvariant? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/324
https://github.com/google/deepvariant/issues/325:73,availability,error,error,73,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:415,availability,error,error,415,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:19,deployability,fail,failed,19,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:190,deployability,instal,installation,190,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1039,deployability,fail,failed,1039,"test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 1396",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1356,deployability,fail,failed,1356,"4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1673,deployability,fail,failed,1673," seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcess",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2182,deployability,modul,module,2182,"am --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:225,integrability,REPOSITOR,REPOSITORY,225,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:713,integrability,buffer,buffer,713,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2478,integrability,sub,subprocess,2478,"1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --outp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2571,integrability,sub,subprocess,2571,"psowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2652,integrability,sub,subprocess,2652,"allel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2733,integrability,buffer,buffer,2733,"f /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:225,interoperability,REPOSITOR,REPOSITORY,225,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:517,modifiability,interm,intermediate,517,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:565,modifiability,Interm,Intermediate,565,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2182,modifiability,modul,module,2182,"am --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2242,modifiability,pac,packages,2242,"-gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2342,modifiability,pac,packages,2342," This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unitt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:0,performance,parallel,parallel,0,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:73,performance,error,error,73,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:415,performance,error,error,415,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:672,performance,time,time,672,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:688,performance,parallel,parallel,688,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1020,performance,parallel,parallel,1020,"d reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1337,performance,parallel,parallel,1337,"eepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1654,performance,parallel,parallel,1654,"ommand:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subpro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2692,performance,time,time,2692,"iant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2708,performance,parallel,parallel,2708,"ples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3545,performance,content,content,3545,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:19,reliability,fail,failed,19,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1039,reliability,fail,failed,1039,"test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 1396",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1356,reliability,fail,failed,1356,"4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1673,reliability,fail,failed,1673," seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcess",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:42,safety,test,test,42,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:73,safety,error,error,73,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:103,safety,test,test,103,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:415,safety,error,error,415,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:778,safety,input,input,778,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:826,safety,input,input,826,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1105,safety,input,input,1105,"example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1151,safety,input,input,1151,"re I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1422,safety,input,input,1422,"`. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1468,safety,input,input,1468,"eepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1739,safety,input,input,1739,"ake_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1785,safety,input,input,1785,".hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2182,safety,modul,module,2182,"am --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2798,safety,input,input,2798,".chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2846,safety,input,input,2846,"/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3174,safety,test,testdata,3174,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3186,safety,input,input,3186,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3319,safety,input,input,3319,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3365,safety,input,input,3365,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3559,safety,test,testdata,3559,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3603,safety,test,testdata,3603,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:42,testability,test,test,42,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:103,testability,test,test,103,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:800,testability,unit,unittest,800,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1127,testability,unit,unittest,1127," Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1444,testability,unit,unittest,1444,"1 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
