id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/563:937,integrability,buffer,buffer,937,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1973,interoperability,platform,platform,1973,"s --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:3188,interoperability,standard,standard,3188,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:362,modifiability,version,version,362,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1877,modifiability,modul,module,1877,"3v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all pr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1946,modifiability,pac,packages,1946,"eepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:149,performance,error,error,149,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:909,performance,parallel,parallel,909,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1260,performance,time,time,1260,"nnels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:209,reliability,checkpoint,checkpoint,209,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:242,reliability,checkpoint,checkpoint,242,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1423,reliability,checkpoint,checkpoint,1423,"s being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2613,reliability,checkpoint,checkpoint,2613,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2678,reliability,checkpoint,checkpoint,2678,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2711,reliability,checkpoint,checkpoint,2711,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2983,reliability,doe,does,2983,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:149,safety,error,error,149,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1646,safety,input,input,1646,"=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1689,safety,input,input,1689,"HM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint sho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1877,safety,modul,module,1877,"3v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all pr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:3027,safety,input,input,3027,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:3201,safety,input,input,3201,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:99,security,model,model,99,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:650,security,model,model,650,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1435,security,model,model,1435,"lled on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2897,security,model,models,2897,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1729,testability,Trace,Traceback,1729,"_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2781,testability,context,context,2781,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:149,usability,error,error,149,"Optionally drop channel 18; **Describe the issue:**. I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:. ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**. - Operating system: Linux Ubuntu 20.04. - DeepVariant version: 1.4. - Installation method: Docker. Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**. /opt/deepvariant/bin/run_deepvariant \. --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \. --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \. --customized_model=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1646,usability,input,input,1646,"=model.ckpt-364300 \. --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1689,usability,input,input,1689,"HM13v2.chrY.deepvariant.vcf.gz \. --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \. --model_type WGS \. --make_examples_extra_args phase_reads=true,channels=blank \. --regions CHM13v2.chrY \. --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint sho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:3027,usability,input,input,3027,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:3201,usability,input,input,3201,"e_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca"". I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**. DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***. An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/564:9,availability,Error,Error,9,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:197,availability,error,error,197,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:391,availability,Operat,Operating,391,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1275,availability,Error,Error,1275,"d at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1540,availability,checkpoint,checkpoint,1540," docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with def",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2316,availability,operat,operations,2316,"ning the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_exp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2362,availability,operat,operations,2362,"bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_sess",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:3472,availability,Cluster,ClusterSpec,3472,"mmon_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4312,availability,Cluster,ClusterSpec,4312,"experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6190,availability,Restor,Restoring,6190,".apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6296,availability,Restor,Restoring,6296,": UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6726,availability,Restor,Restoring,6726,"m/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6832,availability,Restor,Restoring,6832," Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13089,availability,Error,Errors,13089,"ssion.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13130,availability,operat,operation,13130,"sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13154,availability,operat,operations,13154,"). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = ne",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13320,availability,Operat,Operation,13320,"e ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16916,availability,Operat,Operation,16916,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17176,availability,ERROR,ERROR,17176,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:296,deployability,fail,failed,296,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:432,deployability,version,version,432,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:449,deployability,Instal,Installation,449,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:3472,deployability,Cluster,ClusterSpec,3472,"mmon_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4312,deployability,Cluster,ClusterSpec,4312,"experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4901,deployability,version,version,4901," '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5127,deployability,version,version,5127,"ental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 moni",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5376,deployability,version,version,5376,"in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5602,deployability,version,version,5602,"/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5829,deployability,version,version,5829,"arning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9922,deployability,fail,failed,9922,"51 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10214,deployability,modul,module,10214,"14848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12932,deployability,fail,failed,12932,"onitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13501,deployability,modul,module,13501,"lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14776,deployability,stack,stack,14776,", in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14942,deployability,modul,module,14942,", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17183,deployability,fail,failed,17183,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17200,deployability,contain,container,17200,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17409,deployability,unload,unloaded,17409,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1557,energy efficiency,model,models,1557,"e/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1568,energy efficiency,model,model,1568,"nt:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1955,energy efficiency,model,models,1955,"nt \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_rand",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1966,energy efficiency,model,model,1966,"el_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2129,energy efficiency,core,core,2129,"termediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_check",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2195,energy efficiency,optim,optimized,2195,"ards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2275,energy efficiency,CPU,CPU,2275,"ror trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2471,energy efficiency,core,core,2471," ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2678,energy efficiency,model,model,2678,"riants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2768,energy efficiency,estimat,estimator,2768,"z.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2813,energy efficiency,model,model,2813,"s: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:3704,energy efficiency,estimat,estimator,3704,"81.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 477",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4721,energy efficiency,estimat,estimator,4721,"g config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6011,energy efficiency,estimat,estimator,6011,"ackages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6221,energy efficiency,model,models,6221,"aining). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6232,energy efficiency,model,model,6232,"sr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6327,energy efficiency,model,models,6327,"is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6338,energy efficiency,model,model,6338,"ed and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6676,energy efficiency,model,modeling,6676,"uts). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6757,energy efficiency,model,models,6757,"Warning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 477379842148",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6768,energy efficiency,model,model,6768,"ayer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_var",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6863,energy efficiency,model,models,6863,"method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.4748",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6874,energy efficiency,model,model,6874,"ead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10965,energy efficiency,predict,prediction,10965,"ext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10983,energy efficiency,predict,predictions,10983,"dling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _Wr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11070,energy efficiency,estimat,estimator,11070," last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/trai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11080,energy efficiency,estimat,estimator,11080,"ile ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11108,energy efficiency,predict,predict,11108,"/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11148,energy efficiency,predict,predictions,11148,"le_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **k",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13062,energy efficiency,estimat,estimator,13062,"hon/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_googl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13297,energy efficiency,estimat,estimator,13297,"dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14144,energy efficiency,predict,prediction,14144,"urce operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14162,energy efficiency,predict,predictions,14162,"nected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.om",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14259,energy efficiency,estimat,estimator,14259,"ages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, arg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14269,energy efficiency,estimat,estimator,14269,"rflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14297,energy efficiency,predict,predict,14297,"mator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14452,energy efficiency,estimat,estimator,14452,"eepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14462,energy efficiency,estimat,estimator,14462,"/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14672,energy efficiency,estimat,estimator,14672,">>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15693,energy efficiency,predict,prediction,15693,"0, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15711,energy efficiency,predict,predictions,15711,"n_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _appl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15798,energy efficiency,estimat,estimator,15798,"tNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15808,energy efficiency,estimat,estimator,15808,"ile ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15836,energy efficiency,predict,predict,15836,"/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15977,energy efficiency,estimat,estimator,15977,"usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15987,energy efficiency,estimat,estimator,15987,"lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16183,energy efficiency,estimat,estimator,16183,"fgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: faile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:432,integrability,version,version,432,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4901,integrability,version,version,4901," '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5127,integrability,version,version,5127,"ental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 moni",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5376,integrability,version,version,5376,"in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5602,integrability,version,version,5602,"/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5829,integrability,version,version,5829,"arning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6971,integrability,batch,batches,6971,0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7092,integrability,batch,batches,7092,20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7213,integrability,batch,batches,7213,opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7334,integrability,batch,batches,7334,model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7455,integrability,batch,batches,7455,ocal_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7576,integrability,batch,batches,7576,ne running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I082,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7697,integrability,batch,batches,7697,g EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I08,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7818,integrability,batch,batches,7818,.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7939,integrability,batch,batches,7939,] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8060,integrability,batch,batches,8060,cessed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8181,integrability,batch,batches,8181,ssed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100].,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8303,integrability,batch,batches,8303,sed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100].,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8425,integrability,batch,batches,8425,"ed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8547,integrability,batch,batches,8547,"d 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8669,integrability,batch,batches,8669," 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8791,integrability,batch,batches,8791,"350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8913,integrability,batch,batches,8913,"00001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9035,integrability,batch,batches,9035,"0001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception oc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9157,integrability,batch,batches,9157,"001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9279,integrability,batch,batches,9279,"01 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12793,integrability,messag,message,12793,".py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2134,interoperability,platform,platform,2134,"ate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10310,interoperability,platform,platform,10310,"ack (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/loca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12793,interoperability,messag,message,12793,".py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15038,interoperability,platform,platform,15038,"gek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:432,modifiability,version,version,432,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4788,modifiability,pac,packages,4788,"f_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4805,modifiability,layer,layers,4805,"None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4812,modifiability,layer,layers,4812,"_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be remove",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4842,modifiability,layer,layer,4842,"ave_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4901,modifiability,version,version,4901," '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4922,modifiability,layer,layer,4922,", '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4964,modifiability,layer,layer,4964,"heckpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling mod",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5015,modifiability,pac,packages,5015,"eps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimato",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5032,modifiability,layer,layers,5032,"in_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5039,modifiability,layer,layers,5039,"ribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5068,modifiability,layer,layer,5068,"None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Gr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5127,modifiability,version,version,5127,"ental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 moni",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5148,modifiability,layer,layer,5148,"one, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5190,modifiability,layer,layer,5190,": None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Res",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5263,modifiability,pac,packages,5263,"f': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5280,modifiability,layer,layers,5280,"ice': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5287,modifiability,layer,layers,5287,"one, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5317,modifiability,layer,layer,5317,"pec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters fro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5376,modifiability,version,version,5376,"in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5397,modifiability,layer,layer,5397,"ster': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5439,modifiability,layer,layer,5439,"chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5490,modifiability,pac,packages,5490,"plicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5507,modifiability,layer,layers,5507,"26 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5514,modifiability,layer,layers,5514,"4:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5543,modifiability,layer,layer,5543,"ll_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 4773798",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5602,modifiability,version,version,5602,"/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5623,modifiability,layer,layer,5623,"nts_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Relo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5665,modifiability,layer,layer,5665,"lling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 4773798",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5716,modifiability,pac,packages,5716," estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5733,modifiability,layer,layers,5733,"73] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5740,modifiability,layer,layers,5740,"ling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring paramet",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5770,modifiability,layer,layer,5770,"python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5829,modifiability,version,version,5829,"arning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5850,modifiability,layer,layer,5850,"` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5892,modifiability,layer,layer,5892,"uture version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6200,modifiability,paramet,parameters,6200,"uts, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6306,modifiability,paramet,parameters,6306,"ing: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6736,modifiability,paramet,parameters,6736,"ayers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6842,modifiability,paramet,parameters,6842,"e `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9380,modifiability,pac,packages,9380,"y:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9505,modifiability,pac,packages,9505,"62] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9676,modifiability,pac,packages,9676,"251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10214,modifiability,modul,module,10214,"14848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10283,modifiability,pac,packages,10283,"[0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11033,modifiability,pac,packages,11033,"occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11198,modifiability,pac,packages,11198,"ne 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11335,modifiability,pac,packages,11335," run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11473,modifiability,pac,packages,11473,"absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11744,modifiability,pac,packages,11744,"ariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11898,modifiability,pac,packages,11898,"ant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12044,modifiability,pac,packages,12044,"flow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_est",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12198,modifiability,pac,packages,12198,"ages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12358,modifiability,pac,packages,12358,"training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call la",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12523,modifiability,pac,packages,12523,"py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12694,modifiability,pac,packages,12694,"se value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12833,modifiability,paramet,parameter,12833,"s.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13025,modifiability,pac,packages,13025,"python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13260,modifiability,pac,packages,13260,"esult = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13501,modifiability,modul,module,13501,"lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14222,modifiability,pac,packages,14222," at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14415,modifiability,pac,packages,14415,"k2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.117398",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14635,modifiability,pac,packages,14635,"0, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14942,modifiability,modul,module,14942,", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15011,modifiability,pac,packages,15011,"981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15761,modifiability,pac,packages,15761,". Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15940,modifiability,pac,packages,15940,"dule>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16146,modifiability,pac,packages,16146,"tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16304,modifiability,pac,packages,16304,"les_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-285",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16464,modifiability,pac,packages,16464,"le_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your sy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16642,modifiability,pac,packages,16642,"call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16829,modifiability,pac,packages,16829,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16964,modifiability,pac,packages,16964,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9,performance,Error,Error,9,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:197,performance,error,error,197,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1275,performance,Error,Error,1275,"d at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1345,performance,time,time,1345,"iption of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2195,performance,optimiz,optimized,2195,"ards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2229,performance,Network,Network,2229,"tput_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2275,performance,CPU,CPU,2275,"ror trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2295,performance,perform,performance-critical,2295,"- . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2571,performance,Tune,Tune,2571,".ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2620,performance,perform,performance,2620,"test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6971,performance,batch,batches,6971,0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7092,performance,batch,batches,7092,20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7213,performance,batch,batches,7213,opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7334,performance,batch,batches,7334,model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7455,performance,batch,batches,7455,ocal_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7576,performance,batch,batches,7576,ne running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I082,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7697,performance,batch,batches,7697,g EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I08,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7818,performance,batch,batches,7818,.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:7939,performance,batch,batches,7939,] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8060,performance,batch,batches,8060,cessed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8181,performance,batch,batches,8181,ssed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100].,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8303,performance,batch,batches,8303,sed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100].,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8425,performance,batch,batches,8425,"ed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8547,performance,batch,batches,8547,"d 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8669,performance,batch,batches,8669," 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8791,performance,batch,batches,8791,"350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984214848 call_variants.py:462] Processed 400001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:8913,performance,batch,batches,8913,"00001 examples in 782 batches [0.252 sec per 100]. I0826 21:03:18.836436 47737984214848 call_variants.py:462] Processed 450001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9035,performance,batch,batches,9035,"0001 examples in 879 batches [0.251 sec per 100]. I0826 21:05:24.652524 47737984214848 call_variants.py:462] Processed 500001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception oc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9157,performance,batch,batches,9157,"001 examples in 977 batches [0.251 sec per 100]. I0826 21:07:30.681700 47737984214848 call_variants.py:462] Processed 550001 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9279,performance,batch,batches,9279,"01 examples in 1075 batches [0.251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13089,performance,Error,Errors,13089,"ssion.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17176,performance,ERROR,ERROR,17176,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:296,reliability,fail,failed,296,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1540,reliability,checkpoint,checkpoint,1540," docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with def",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6190,reliability,Restor,Restoring,6190,".apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 10000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6296,reliability,Restor,Restoring,6296,": UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6726,reliability,Restor,Restoring,6726,"m/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6832,reliability,Restor,Restoring,6832," Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9922,reliability,fail,failed,9922,"51 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12932,reliability,fail,failed,12932,"onitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17183,reliability,fail,failed,17183,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17427,reliability,Doe,Does,17427,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9,safety,Error,Error,9,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:197,safety,error,error,197,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1275,safety,Error,Error,1275,"d at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1803,safety,input,input,1803,"lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary fol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1846,safety,input,input,1846,"isk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.om",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2005,safety,input,input,2005,"enome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2048,safety,input,input,2048,"n_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4976,safety,input,inputs,4976,"ery_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5202,safety,input,inputs,5202,"ssion_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring param",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5451,safety,input,inputs,5451,", '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Runn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5677,safety,input,inputs,5677,"fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5904,safety,input,inputs,5904,"n. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10008,safety,except,exception,10008,"0001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10027,safety,except,exception,10027,"61 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10214,safety,modul,module,10214,"14848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10965,safety,predict,prediction,10965,"ext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10983,safety,predict,predictions,10983,"dling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _Wr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11108,safety,predict,predict,11108,"/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11148,safety,predict,predictions,11148,"le_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **k",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13089,safety,Error,Errors,13089,"ssion.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13124,safety,input,input,13124,"n self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13141,safety,Input,Input,13141,"*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13501,safety,modul,module,13501,"lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14144,safety,predict,prediction,14144,"urce operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14162,safety,predict,predictions,14162,"nected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.om",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14297,safety,predict,predict,14297,"mator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14942,safety,modul,module,14942,", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15693,safety,predict,prediction,15693,"0, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15711,safety,predict,predictions,15711,"n_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _appl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15836,safety,predict,predict,15836,"/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16771,safety,input,inputs,16771,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17176,safety,ERROR,ERROR,17176,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17368,safety,permiss,permission,17368,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17448,safety,test,test,17448,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17484,safety,test,test,17484,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17675,safety,Input,Input,17675,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17696,safety,valid,valid,17696,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1557,security,model,models,1557,"e/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1568,security,model,model,1568,"nt:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1955,security,model,models,1955,"nt \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_rand",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1966,security,model,model,1966,"el_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2229,security,Network,Network,2229,"tput_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2678,security,model,model,2678,"riants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2813,security,model,model,2813,"s: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6221,security,model,models,6221,"aining). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6232,security,model,model,6232,"sr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6327,security,model,models,6327,"is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6338,security,model,model,6338,"ed and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6676,security,model,modeling,6676,"uts). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6757,security,model,models,6757,"Warning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 477379842148",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6768,security,model,model,6768,"ayer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_var",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6863,security,model,models,6863,"method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.4748",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:6874,security,model,model,6874,"ead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590 47737984214848 call_variants.py:462] Processed 1 examples in 1 batches [849.953 sec per 100]. I0826 20:46:44.255733 47737984214848 call_variants.py:462] Processed 50001 examples in 98 batches [0.271 sec per 100]. I0826 20:48:48.666643 47737984214848 call_variants.py:462] Processed 100001 examples in 196 batches [0.260 sec per 100]. I0826 20:50:53.094218 47737984214848 call_variants.py:462] Processed 150001 examples in 293 batches [0.256 sec per 100]. I0826 20:52:58.984037 47737984214848 call_variants.py:462] Processed 200001 examples in 391 batches [0.255 sec per 100]. I0826 20:55:03.618282 47737984214848 call_variants.py:462] Processed 250001 examples in 489 batches [0.254 sec per 100]. I0826 20:57:06.583475 47737984214848 call_variants.py:462] Processed 300001 examples in 586 batches [0.253 sec per 100]. I0826 20:59:10.820679 47737984214848 call_variants.py:462] Processed 350001 examples in 684 batches [0.252 sec per 100]. I0826 21:01:15.474886 47737984",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9414,security,session,session,9414,"n 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9539,security,session,session,9539,"270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9710,security,session,session,9710,"36908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12232,security,session,session,12232,"nitored_session.py"", line 786, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12392,security,session,session,12392,"ne 1315, in run. return self._sess.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run. raise six.reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.om",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12557,security,session,session,12557,"reraise(*original_exc_info). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12728,security,session,session,12728,"hon3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run. outputs = _WrappedSession.run(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:620,testability,instrument,instrument,620,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1281,testability,trace,trace,1281,"9179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9308,testability,Trace,Traceback,9308,".251 sec per 100]. I0826 21:09:35.367410 47737984214848 call_variants.py:462] Processed 600001 examples in 1172 batches [0.251 sec per 100]. I0826 21:11:41.218489 47737984214848 call_variants.py:462] Processed 650001 examples in 1270 batches [0.251 sec per 100]. I0826 21:13:47.358545 47737984214848 call_variants.py:462] Processed 700001 examples in 1368 batches [0.251 sec per 100]. I0826 21:15:52.436908 47737984214848 call_variants.py:462] Processed 750001 examples in 1465 batches [0.251 sec per 100]. I0826 21:17:58.339728 47737984214848 call_variants.py:462] Processed 800001 examples in 1563 batches [0.251 sec per 100]. I0826 21:20:07.519950 47737984214848 call_variants.py:462] Processed 850001 examples in 1661 batches [0.252 sec per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/pla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10048,testability,Trace,Traceback,10048," per 100]. I0826 21:22:14.806241 47737984214848 call_variants.py:462] Processed 900001 examples in 1758 batches [0.252 sec per 100]. I0826 21:24:23.524628 47737984214848 call_variants.py:462] Processed 950001 examples in 1856 batches [0.252 sec per 100]. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14535,testability,hook,hooks,14535,">>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14782,testability,trace,trace,14782,"run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> prediction = next(predictions). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. >>> features, input_hooks = self._get_features_from_input_fn(. >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. >>> result, _, hooks = estimator_util.parse_input_fn_result(result). >>> . >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. >>> result = iterator.get_next(). >>> . Original stack trace for 'IteratorGetNext':. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_esti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16056,testability,hook,hooks,16056,"e 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stac",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17448,testability,test,test,17448,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17484,testability,test,test,17484,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17663,testability,context,context,17663,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:9,usability,Error,Error,9,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:197,usability,error,error,197,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:324,usability,clear,clear,324,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:740,usability,Command,Command,740,"DataLoss Error with Tensorflow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1275,usability,Error,Error,1275,"d at 19179998357' failed with EOF reached. (A clear and concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1330,usability,command,command,1330,"concise description of what the issue is.). **Setup**. - Operating system:CentOS7 . - DeepVariant version:1.4.0. - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}"". - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - `singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1803,usability,input,input,1803,"lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary fol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1846,usability,input,input,1846,"isk1/yangyxt/test_tmp"" \. --workdir /paedyl01/disk1/yangyxt \. ${image} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.om",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2005,usability,input,input,2005,"enome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2048,usability,input,input,2048,"n_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads} && \. ls -lh ${output_vcf} && \. ls -lh ${output_gvcf}`. - Error trace: (if applicable). - . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2295,usability,perform,performance-critical,2295,"- . - `***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2620,usability,perform,performance,2620,"test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance. WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt. INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4828,usability,User,UserWarning,4828,"': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future versi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4976,usability,input,inputs,4976,"ery_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5054,usability,User,UserWarning,5054,"evice_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5202,usability,input,inputs,5202,"ssion_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring param",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5303,usability,User,UserWarning,5303,"': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring par",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5451,usability,input,inputs,5451,", '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Runn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5529,usability,User,UserWarning,5529,"84214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz. INFO:tensorflow:Calling model_fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5677,usability,input,inputs,5677,"fn. I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5756,usability,User,UserWarning,5756,"/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5904,usability,input,inputs,5904,"n. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Done calling model_fn. I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn. INFO:tensorflow:Graph was finalized. I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. INFO:tensorflow:Running local_init_op. I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op. INFO:tensorflow:Done running local_init_op. I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op. INFO:tensorflow:Reloading EMA... I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA... INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:35.138464 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt. I0826 20:44:37.459590",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13089,usability,Error,Errors,13089,"ssion.py"", line 1236, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13124,usability,input,input,13124,"n self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13141,usability,Input,Input,13141,"*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call. raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter. tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached. 	 [[node IteratorGetNext. (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60). ]]. Errors may have originated from an input operation. Input Source operations connected to node IteratorGetNext:. In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last). >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. >>> tf.compat.v1.app.run(). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run. >>> _run_main(main, args). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main. >>> sys.exit(main(argv)). >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. >>> call_variants(. >>> . >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants. >>> ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:16771,usability,input,inputs,16771,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17114,usability,user,user,17114,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17176,usability,ERROR,ERROR,17176,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17675,usability,Input,Input,17675,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17739,usability,command,command,17739,"ython3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict. features, input_hooks = self._get_features_from_input_fn(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn. result, _, hooks = estimator_util.parse_input_fn_result(result). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result. result = iterator.get_next(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next. flat_ret = gen_dataset_ops.iterator_get_next(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal. ret = Operation(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s. user	1063m44.358s. sys	25m21.900s. INFO: Cleaning up image... ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied. singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No. **Any additional context:**. Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/565:115,availability,avail,availability,115,"BAQ's effect on results quality (HiFi reads); Hi,. I am wondering if the DV team has done an evaluation on how the availability of BAQ (the `BQ:Z:...` tag) affects the quality of calls generated from HiFi reads. Thank you! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:115,reliability,availab,availability,115,"BAQ's effect on results quality (HiFi reads); Hi,. I am wondering if the DV team has done an evaluation on how the availability of BAQ (the `BQ:Z:...` tag) affects the quality of calls generated from HiFi reads. Thank you! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:115,safety,avail,availability,115,"BAQ's effect on results quality (HiFi reads); Hi,. I am wondering if the DV team has done an evaluation on how the availability of BAQ (the `BQ:Z:...` tag) affects the quality of calls generated from HiFi reads. Thank you! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:76,security,team,team,76,"BAQ's effect on results quality (HiFi reads); Hi,. I am wondering if the DV team has done an evaluation on how the availability of BAQ (the `BQ:Z:...` tag) affects the quality of calls generated from HiFi reads. Thank you! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:115,security,availab,availability,115,"BAQ's effect on results quality (HiFi reads); Hi,. I am wondering if the DV team has done an evaluation on how the availability of BAQ (the `BQ:Z:...` tag) affects the quality of calls generated from HiFi reads. Thank you! Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/566:278,availability,Operat,Operating,278,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:746,availability,Error,Error,746,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:15,deployability,fail,failed,15,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:192,deployability,log,log,192,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:211,deployability,fail,failed,211,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:319,deployability,version,version,319,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:337,deployability,Instal,Installation,337,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:319,integrability,version,version,319,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:319,modifiability,version,version,319,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:746,performance,Error,Error,746,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:15,reliability,fail,failed,15,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:211,reliability,fail,failed,211,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:891,reliability,Doe,Does,891,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:192,safety,log,log,192,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:746,safety,Error,Error,746,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:912,safety,test,test,912,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:948,safety,test,test,948,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:192,security,log,log,192,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:192,testability,log,log,192,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:434,testability,instrument,instrument,434,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:752,testability,trace,trace,752,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:912,testability,test,test,912,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:948,testability,test,test,948,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:1123,testability,context,context,1123,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:551,usability,Command,Command,551,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:746,usability,Error,Error,746,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:793,usability,user,user-images,793,"locale setting failed with latest docker image. ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**. According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**. - Operating system: CentOS7. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker pull . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**. - Command: . - singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. ...... - Error trace: (if applicable). ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/567:302,availability,error,error,302,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:120,interoperability,specif,specified,120,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:147,modifiability,paramet,parameter,147,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:161,modifiability,PAC,PACBIO,161,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:302,performance,error,error,302,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:302,safety,error,error,302,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:302,usability,error,error,302,"DeepVariant1.1.0 --model_type; Hello! I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus. I wonder how serious is this error? Do I have to run the program again? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/568:964,availability,Avail,Available,964,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1181,availability,avail,available,1181,"ublic/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1241,availability,checkpoint,checkpoint,1241,"ects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/refer",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1292,availability,checkpoint,checkpoint,1292,"alse) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1543,availability,checkpoint,checkpoint,1543," `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1699,availability,Operat,Operating,1699," represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2553,availability,Error,Error,2553,"ntains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2788,availability,checkpoint,checkpoint,2788,"ce, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3994,availability,checkpoint,checkpoint,3994,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4059,availability,checkpoint,checkpoint,4059,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4092,availability,checkpoint,checkpoint,4092,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1554,deployability,contain,contains,1554,"mples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1732,deployability,version,version,1732,"rmation gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1749,deployability,Instal,Installation,1749,"om population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1985,deployability,contain,container,1985,"apping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3258,deployability,modul,module,3258,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:109,energy efficiency,model,model,109,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:137,energy efficiency,cloud,cloud,137,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:403,energy efficiency,model,model,403,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:722,energy efficiency,frequenc,frequency,722,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1137,energy efficiency,model,model-ckpt,1137,".google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1286,energy efficiency,model,model,1286,"tering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1605,energy efficiency,current,currently,1605," channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the comm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2805,energy efficiency,model,models,2805,"ularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2816,energy efficiency,model,model,2816,"Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:185,integrability,pub,public,185,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1732,integrability,version,version,1732,"rmation gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3354,interoperability,platform,platform,3354,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1732,modifiability,version,version,1732,"rmation gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3258,modifiability,modul,module,3258,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3327,modifiability,pac,packages,3327,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1881,performance,time,time,1881,"default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2553,performance,Error,Error,2553,"ntains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2621,performance,time,time,2621,"o include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:409,reliability,doe,does,409,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:964,reliability,Availab,Available,964,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1181,reliability,availab,available,1181,"ublic/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1241,reliability,checkpoint,checkpoint,1241,"ects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/refer",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1292,reliability,checkpoint,checkpoint,1292,"alse) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1543,reliability,checkpoint,checkpoint,1543," `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2788,reliability,checkpoint,checkpoint,2788,"ce, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3994,reliability,checkpoint,checkpoint,3994,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4059,reliability,checkpoint,checkpoint,4059,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4092,reliability,checkpoint,checkpoint,4092,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:964,safety,Avail,Available,964,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1181,safety,avail,available,1181,"ublic/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2553,safety,Error,Error,2553,"ntains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3024,safety,input,input,3024,"/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The num",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3067,safety,input,input,3067,"r/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3258,safety,modul,module,3258,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:109,security,model,model,109,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:403,security,model,model,403,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:964,security,Availab,Available,964,"Varying the channels used to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1022,security,ident,identity,1022,"to call variants; **Describe the issue:**. I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1137,security,model,model-ckpt,1137,".google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1181,security,availab,available,1181,"ublic/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1286,security,model,model,1286,"tering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:. ```. --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets. (default: 'false'). --[no]add_hp_channel: If true, add another channel to represent HP tags per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2805,security,model,models,2805,"ularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2816,security,model,model,2816,"Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2559,testability,trace,trace,2559," during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, arg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3110,testability,Trace,Traceback,3110,"ulation_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1865,usability,Command,Command,1865,"gs per read. (default: 'false'). --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:. ```. --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls. ```. If so, do they include one additional channel or permutations of multiple channels? If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2553,usability,Error,Error,2553,"ntains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2606,usability,command,command,2606,"ntly unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**. - Operating system:. - DeepVariant version: v1.4. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: WGS. **Steps to reproduce:**. - Command: . ```. time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3024,usability,input,input,3024,"/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The num",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3067,usability,input,input,3067,"r/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif . /opt/deepvariant/bin/run_deepvariant . --model_type=WGS. --ref='/ref_dir/reference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4160,usability,user,user,4160,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4206,usability,user,user,4206,"ference.fa' . --reads='/bam_dir/id.bam' . --output_vcf='/out_dir/test1.vcf.gz' . --intermediate_results_dir='/out_dir/tmp/test1/' . --num_shards='39' . --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" . --regions=/region_dir/regions_to_test.bed . ```. - Error trace: (if applicable). ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants. raise ValueError('The number of channels in examples and checkpoint '. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s. user 0m4.066s. sys 0m4.174s. real 77m45.059s. user 2960m49.979s. sys 39m40.911s```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/571:610,availability,Operat,Operating,610,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:650,deployability,version,version,650,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:668,deployability,Instal,Installation,668,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:650,integrability,version,version,650,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:650,modifiability,version,version,650,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:861,modifiability,Pac,PacBio,861,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:222,safety,input,input,222,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:53,testability,plan,planning,53,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:759,testability,instrument,instrument,759,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:222,usability,input,input,222,"Outputting basepair resolution in DeepVariant; I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**. - Operating system: CentOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/573:409,availability,Error,Error,409,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:59,deployability,instal,installed,59,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:142,deployability,instal,installed,142,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:207,deployability,version,version,207,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:227,deployability,Instal,Installation,227,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:587,deployability,modul,module,587,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:616,deployability,Modul,ModuleNotFoundError,616,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:640,deployability,modul,module,640,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:668,deployability,instal,installed,668,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:17,integrability,wrap,wrapper,17,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:100,integrability,wrap,wrapper,100,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:207,integrability,version,version,207,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:17,interoperability,wrapper,wrapper,17,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:100,interoperability,wrapper,wrapper,100,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:207,modifiability,version,version,207,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:587,modifiability,modul,module,587,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:616,modifiability,Modul,ModuleNotFoundError,616,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:640,modifiability,modul,module,640,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:409,performance,Error,Error,409,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:409,safety,Error,Error,409,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:587,safety,modul,module,587,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:616,safety,Modul,ModuleNotFoundError,616,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:640,safety,modul,module,640,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:415,testability,trace,trace,415,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:440,testability,Trace,Traceback,440,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:322,usability,Command,Command,322,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:409,usability,Error,Error,409,"The deep variant wrapper dv_call_variants.py crushing when installed using conda.; the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**. - Ubuntu 20.04:. - DeepVariant version - 1.4.0:. - Installation method - Conda. - Type of data - sequencing, illumina. **Steps to reproduce:**. - Command:. dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) . Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>. import numpy as np. ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/574:95,deployability,version,version,95,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:175,deployability,version,versions,175,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:123,energy efficiency,gpu,gpu-latest,123,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:95,integrability,version,version,95,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:175,integrability,version,versions,175,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:95,modifiability,version,version,95,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:175,modifiability,version,versions,175,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:123,performance,gpu,gpu-latest,123,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:16,security,Team,Team,16,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:220,security,team,team,220,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:228,testability,understand,understand,228,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:254,usability,help,help,254,"DeepTrio; Hello Team,. This is regarding deepTrio. I have tried creating the docker images for version 1.2, 1.4 as well as gpu-latest. However, running into issues at all the versions. Is there a way to connect with the team to understand the issues and help in running it? I can be reached at ankur.a@lifecell.in. Looking forward to hearing from you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/pull/576:35,deployability,Log,Logo,35,DeepVariant RNA-seq; * DeepVariant Logo. * DeepVariant RNA-seq case study. * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/pull/576:97,deployability,releas,release,97,DeepVariant RNA-seq; * DeepVariant Logo. * DeepVariant RNA-seq case study. * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/pull/576:35,safety,Log,Logo,35,DeepVariant RNA-seq; * DeepVariant Logo. * DeepVariant RNA-seq case study. * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/pull/576:35,security,Log,Logo,35,DeepVariant RNA-seq; * DeepVariant Logo. * DeepVariant RNA-seq case study. * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/pull/576:35,testability,Log,Logo,35,DeepVariant RNA-seq; * DeepVariant Logo. * DeepVariant RNA-seq case study. * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/issues/577:107,deployability,Fail,Failed,107,"Could not open BAM; Hi! . I have a problem that docker can't find BAM file:. ```bash. [E::hts_open_format] Failed to open file ""/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.pica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:370,deployability,modul,module,370,"Could not open BAM; Hi! . I have a problem that docker can't find BAM file:. ```bash. [E::hts_open_format] Failed to open file ""/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.pica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2030,deployability,fail,failed,2030,"ogle_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2510,energy efficiency,gpu,gpus,2510,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2101,integrability,Pub,PublicData,2101,"om_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2640,integrability,Pub,PublicData,2640,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2771,integrability,Pub,PublicData,2771,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:370,modifiability,modul,module,370,"Could not open BAM; Hi! . I have a problem that docker can't find BAM file:. ```bash. [E::hts_open_format] Failed to open file ""/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.pica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2011,performance,parallel,parallel,2011,"9c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2510,performance,gpu,gpus,2510,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:107,reliability,Fail,Failed,107,"Could not open BAM; Hi! . I have a problem that docker can't find BAM file:. ```bash. [E::hts_open_format] Failed to open file ""/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.pica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2030,reliability,fail,failed,2030,"ogle_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:370,safety,modul,module,370,"Could not open BAM; Hi! . I have a problem that docker can't find BAM file:. ```bash. [E::hts_open_format] Failed to open file ""/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.pica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:222,testability,Trace,Traceback,222,"Could not open BAM; Hi! . I have a problem that docker can't find BAM file:. ```bash. [E::hts_open_format] Failed to open file ""/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.pica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:3106,testability,understand,understand,3106,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2379,usability,user,user,2379,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:3156,usability,help,help,3156,"ile ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_wjhib79c/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna --reads /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam --examples /tmp/tmpq8fl_xv9/make_examples.tfrecord@1.gz --channels insert_size --gvcf /tmp/tmpq8fl_xv9/gvcf.tfrecord@1.gz --task 0. real	0m2.791s. user	0m5.497s. sys	0m4.089s. ```. Here is my .sh file that i'm running:. ```bash. #!/bin/bash. . BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data/PublicData/hg38/GCA_000001405.15_GRCh38_no_alt_cleaned.fna \. --reads=/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam \. --output_vcf=/data/deepvariant/output/output.vcf.gz \. --output_gvcf=/data/deepvariant/output/output.g.vcf.gz \. ```. I suppose that's a problem with mounting a directory to docker, however I don't understand what's incorrect in my code. Could you help me please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/578:417,availability,Operat,Operating,417,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1420,availability,Error,Error,1420,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:459,deployability,version,version,459,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:491,deployability,version,version,491,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:597,deployability,Instal,Installation,597,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1356,deployability,log,logs,1356,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:459,integrability,version,version,459,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:491,integrability,version,version,491,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:234,modifiability,pac,pacbio,234,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:459,modifiability,version,version,459,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:491,modifiability,version,version,491,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1805,modifiability,pac,pacbio,1805,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1420,performance,Error,Error,1420,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1488,reliability,Doe,Does,1488,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1356,safety,log,logs,1356,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1420,safety,Error,Error,1420,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1509,safety,test,test,1509,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1545,safety,test,test,1545,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1356,security,log,logs,1356,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:725,testability,instrument,instrument,725,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1356,testability,log,logs,1356,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1426,testability,trace,trace,1426,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1509,testability,test,test,1509,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1545,testability,test,test,1545,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1881,testability,context,context,1881,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:193,usability,custom,custom,193,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:817,usability,custom,custom,817,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:859,usability,Command,Command,859,"DeepVariant has been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1420,usability,Error,Error,1420,"been running for 17 days; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**. I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**. - Operating system: centOS 7. - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now). - Installation method (Docker, built from source, etc.): converted docker image to singularity image. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**. - Command: . ```. singularity exec ~/virtual_server/deepvariant.sif \. bash -c "". /opt/deepvariant/bin/run_deepvariant \. --model_type=""HYBRID_PACBIO_ILLUMINA"" \. --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \. --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \. --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \. --num_shards=$SLURM_CPUS_PER_TASK \. --logging_dir=""${OUTPUT_DIR}""/logs \. --intermediate_results_dir=""${OUTPUT_DIR}""/tmp"". ```. - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**. [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/579:172,interoperability,format,format,172,"Trouble with DeepVariant after running Minimap2; Hello,. I am trying to run Deepvariant in Galaxy with a bam file from Minimap2 but it sais there is a problem with the vcf format. Quite new using these tools and I am lost! please anyone could help me? ![Captura](https://user-images.githubusercontent.com/116640228/197752262-65531e02-1092-46cb-9f8a-aa3ca3c75567.JPG).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:202,usability,tool,tools,202,"Trouble with DeepVariant after running Minimap2; Hello,. I am trying to run Deepvariant in Galaxy with a bam file from Minimap2 but it sais there is a problem with the vcf format. Quite new using these tools and I am lost! please anyone could help me? ![Captura](https://user-images.githubusercontent.com/116640228/197752262-65531e02-1092-46cb-9f8a-aa3ca3c75567.JPG).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:243,usability,help,help,243,"Trouble with DeepVariant after running Minimap2; Hello,. I am trying to run Deepvariant in Galaxy with a bam file from Minimap2 but it sais there is a problem with the vcf format. Quite new using these tools and I am lost! please anyone could help me? ![Captura](https://user-images.githubusercontent.com/116640228/197752262-65531e02-1092-46cb-9f8a-aa3ca3c75567.JPG).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:271,usability,user,user-images,271,"Trouble with DeepVariant after running Minimap2; Hello,. I am trying to run Deepvariant in Galaxy with a bam file from Minimap2 but it sais there is a problem with the vcf format. Quite new using these tools and I am lost! please anyone could help me? ![Captura](https://user-images.githubusercontent.com/116640228/197752262-65531e02-1092-46cb-9f8a-aa3ca3c75567.JPG).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/580:306,availability,error,error,306,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:398,availability,error,error,398,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:480,availability,error,error,480,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:653,availability,Operat,Operating,653,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:299,deployability,fail,failed,299,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:336,deployability,instal,installing,336,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:445,deployability,version,version,445,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:575,deployability,version,version,575,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:593,deployability,instal,install,593,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:687,deployability,version,version,687,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:705,deployability,Instal,Installation,705,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1621,deployability,modul,module,1621,"gularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1738,deployability,modul,module,1738,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1902,deployability,modul,module,1902,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2051,deployability,modul,module,2051,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2213,deployability,modul,module,2213,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2376,deployability,modul,module,2376,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2559,deployability,modul,module,2559,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:12,energy efficiency,GPU,GPU,12,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:249,energy efficiency,gpu,gpu,249,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:984,energy efficiency,gpu,gpu,984,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2076,energy efficiency,core,core,2076,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2168,energy efficiency,core,core,2168,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:445,integrability,version,version,445,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:486,integrability,messag,message,486,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:575,integrability,version,version,575,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:687,integrability,version,version,687,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:486,interoperability,messag,message,486,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1511,interoperability,bind,bind,1511,"er to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:366,modifiability,pac,package,366,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:419,modifiability,pac,package,419,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:445,modifiability,version,version,445,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:565,modifiability,pac,packages,565,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:575,modifiability,version,version,575,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:687,modifiability,version,version,687,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1511,modifiability,bind,bind,1511,"er to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1621,modifiability,modul,module,1621,"gularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1691,modifiability,pac,packages,1691,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1738,modifiability,modul,module,1738,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1848,modifiability,pac,packages,1848,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1902,modifiability,modul,module,1902,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1992,modifiability,pac,packages,1992,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2051,modifiability,modul,module,2051,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2148,modifiability,pac,packages,2148,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2213,modifiability,modul,module,2213,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2322,modifiability,pac,packages,2322,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2376,modifiability,modul,module,2376,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2487,modifiability,pac,packages,2487,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2559,modifiability,modul,module,2559,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:12,performance,GPU,GPU,12,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:249,performance,gpu,gpu,249,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:306,performance,error,error,306,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:398,performance,error,error,398,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:480,performance,error,error,480,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:899,performance,cach,cache,899,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:984,performance,gpu,gpu,984,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:299,reliability,fail,failed,299,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:306,safety,error,error,306,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:398,safety,error,error,398,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:480,safety,error,error,480,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:767,safety,test,test,767,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1621,safety,modul,module,1621,"gularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1738,safety,modul,module,1738,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1902,safety,modul,module,1902,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2051,safety,modul,module,2051,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2213,safety,modul,module,2213,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2376,safety,modul,module,2376,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2559,safety,modul,module,2559,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1431,security,sandbox,sandbox,1431," protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implement",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:767,testability,test,test,767,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1092,testability,unit,unittest,1092,"github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework impor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1524,testability,Trace,Traceback,1524,"riant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_impl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1947,testability,context,context,1947,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:2025,testability,context,context,2025,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:214,usability,guid,guide,214,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:306,usability,error,error,306,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:398,usability,error,error,398,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:480,usability,error,error,480,"Singularity GPU Quick Start TypeError: bases must be types; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. Yes. **Describe the issue:**. I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image? **Setup**. - Operating system: . - DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1770,usability,tool,tools,1770,"DeepVariant version: 1.4.0. - Installation method: singularity. - Type of data: quick start test. . **Steps to reproduce:**. . ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/581:0,availability,Error,Error,0,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13990,availability,error,error,13990,"NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15563,availability,error,error,15563,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17136,availability,error,error,17136,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18709,availability,error,error,18709,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20282,availability,error,error,20282,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21855,availability,error,error,21855,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23428,availability,error,error,23428,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:25001,availability,error,error,25001,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13727,deployability,Fail,Failed,13727,"xamples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15273,deployability,modul,module,15273,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15300,deployability,Fail,Failed,15300,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:16846,deployability,modul,module,16846,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:16873,deployability,Fail,Failed,16873,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18419,deployability,modul,module,18419,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18446,deployability,Fail,Failed,18446,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:19992,deployability,modul,module,19992,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20019,deployability,Fail,Failed,20019,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21565,deployability,modul,module,21565,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21592,deployability,Fail,Failed,21592,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23138,deployability,modul,module,23138,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23165,deployability,Fail,Failed,23165,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24711,deployability,modul,module,24711,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24738,deployability,Fail,Failed,24738,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26284,deployability,modul,module,26284,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26312,deployability,fail,failed,26312,"dow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26628,deployability,fail,failed,26628,"p/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26944,deployability,fail,failed,26944,"iant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27260,deployability,fail,failed,27260,"es.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27576,deployability,fail,failed,27576, --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27892,deployability,fail,failed,27892," --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28208,deployability,fail,failed,28208,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28524,deployability,fail,failed,28524,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:14006,energy efficiency,Current,Current,14006,"I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15579,energy efficiency,Current,Current,15579," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17152,energy efficiency,Current,Current,17152," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18725,energy efficiency,Current,Current,18725," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20298,energy efficiency,Current,Current,20298," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21871,energy efficiency,Current,Current,21871," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23444,energy efficiency,Current,Current,23444," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:25017,energy efficiency,Current,Current,25017," line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:93,integrability,buffer,buffer,93,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:6740,modifiability,deco,decode,6740,"data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7094,modifiability,deco,decode,7094,"rna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7448,modifiability,deco,decode,7448,":19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7802,modifiability,deco,decode,7802,"-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8156,modifiability,deco,decode,8156,"-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8510,modifiability,deco,decode,8510,"-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReade",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8864,modifiability,deco,decode,8864,"-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:9218,modifiability,deco,decode,9218,"-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435622 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15273,modifiability,modul,module,15273,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:16846,modifiability,modul,module,16846,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18419,modifiability,modul,module,18419,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:19992,modifiability,modul,module,19992,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21565,modifiability,modul,module,21565,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23138,modifiability,modul,module,23138,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24711,modifiability,modul,module,24711,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26284,modifiability,modul,module,26284,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28833,modifiability,interm,intermediate,28833,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:0,performance,Error,Error,0,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:50,performance,time,time,50,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:65,performance,parallel,parallel,65,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:10522,performance,Overhead,Overhead,10522,9:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435622 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.891901 139999733659456 make_examples_core.py:243] Task 5/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:10935,performance,Overhead,Overhead,10935,mics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.891901 139999733659456 make_examples_core.py:243] Task 5/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:11348,performance,Overhead,Overhead,11348, Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:11888,performance,Overhead,Overhead,11888,08736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:12428,performance,Overhead,Overhead,12428,mics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:12841,performance,Overhead,Overhead,12841,69600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13254,performance,Overhead,Overhead,13254," Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13667,performance,Overhead,Overhead,13667," Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13990,performance,error,error,13990,"NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15563,performance,error,error,15563,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17136,performance,error,error,17136,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18709,performance,error,error,18709,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20282,performance,error,error,20282,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21855,performance,error,error,21855,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23428,performance,error,error,23428,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:25001,performance,error,error,25001,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26293,performance,parallel,parallel,26293,"iant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26609,performance,parallel,parallel,26609,"n_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26925,performance,parallel,parallel,26925,"com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27241,performance,parallel,parallel,27241,"ariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27557,performance,parallel,parallel,27557,a/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_ex,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27873,performance,parallel,parallel,27873,"a/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28189,performance,parallel,parallel,28189,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28505,performance,parallel,parallel,28505,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13727,reliability,Fail,Failed,13727,"xamples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15300,reliability,Fail,Failed,15300,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:16873,reliability,Fail,Failed,16873,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18446,reliability,Fail,Failed,18446,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20019,reliability,Fail,Failed,20019,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21592,reliability,Fail,Failed,21592,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23165,reliability,Fail,Failed,23165,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24738,reliability,Fail,Failed,24738,"ndow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26312,reliability,fail,failed,26312,"dow_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26628,reliability,fail,failed,26628,"p/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26944,reliability,fail,failed,26944,"iant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27260,reliability,fail,failed,27260,"es.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27576,reliability,fail,failed,27576, --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode call,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:27892,reliability,fail,failed,27892," --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28208,reliability,fail,failed,28208,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28524,reliability,fail,failed,28524,"s job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 4. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 5. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 6. it produces intermediate dir but no vcf file produced, I don't know what is the meaning of this and why it happened .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:0,safety,Error,Error,0,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:609,safety,input,inputs,609,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1379,safety,input,inputs,1379,"ads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155034 139948131759936 make_examples_core.py:243] Task 0/8: Preparing inputs. I1029 09:19:01.163061 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175836 139948131759936 make_examples_core.py:243] Task 0/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2149,safety,input,inputs,2149,"tiveBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155034 139948131759936 make_examples_core.py:243] Task 0/8: Preparing inputs. I1029 09:19:01.163061 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175836 139948131759936 make_examples_core.py:243] Task 0/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184607 139948131759936 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129342 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139182 140209041569600 make_examples_core.py:243] Task 7/8: Preparing inputs. I1029 09:19:01.149531 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160770 140209041569600 make_examples_core.py:243] Task 7/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2919,safety,input,inputs,2919,"tiveBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155034 139948131759936 make_examples_core.py:243] Task 0/8: Preparing inputs. I1029 09:19:01.163061 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175836 139948131759936 make_examples_core.py:243] Task 0/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184607 139948131759936 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129342 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139182 140209041569600 make_examples_core.py:243] Task 7/8: Preparing inputs. I1029 09:19:01.149531 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160770 140209041569600 make_examples_core.py:243] Task 7/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171079 140209041569600 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129353 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.159007 140280424228672 make_examples_core.py:243] Task 1/8: Preparing inputs. I1029 09:19:01.167812 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.178546 140280424228672 make_examples_core.py:243] Task 1/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3689,safety,input,inputs,3689,"tiveBedReader. I1029 09:19:01.129342 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139182 140209041569600 make_examples_core.py:243] Task 7/8: Preparing inputs. I1029 09:19:01.149531 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160770 140209041569600 make_examples_core.py:243] Task 7/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171079 140209041569600 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129353 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.159007 140280424228672 make_examples_core.py:243] Task 1/8: Preparing inputs. I1029 09:19:01.167812 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.178546 140280424228672 make_examples_core.py:243] Task 1/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.186683 140280424228672 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155033 139760086697792 make_examples_core.py:243] Task 3/8: Preparing inputs. I1029 09:19:01.163016 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175488 139760086697792 make_examples_core.py:243] Task 3/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:4459,safety,input,inputs,4459,"tiveBedReader. I1029 09:19:01.129353 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.159007 140280424228672 make_examples_core.py:243] Task 1/8: Preparing inputs. I1029 09:19:01.167812 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.178546 140280424228672 make_examples_core.py:243] Task 1/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.186683 140280424228672 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155033 139760086697792 make_examples_core.py:243] Task 3/8: Preparing inputs. I1029 09:19:01.163016 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175488 139760086697792 make_examples_core.py:243] Task 3/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184188 139760086697792 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139694 139762738964288 make_examples_core.py:243] Task 2/8: Preparing inputs. I1029 09:19:01.149530 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160889 139762738964288 make_examples_core.py:243] Task 2/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5229,safety,input,inputs,5229,"tiveBedReader. I1029 09:19:01.129340 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155033 139760086697792 make_examples_core.py:243] Task 3/8: Preparing inputs. I1029 09:19:01.163016 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175488 139760086697792 make_examples_core.py:243] Task 3/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184188 139760086697792 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139694 139762738964288 make_examples_core.py:243] Task 2/8: Preparing inputs. I1029 09:19:01.149530 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160889 139762738964288 make_examples_core.py:243] Task 2/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171224 139762738964288 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5999,safety,input,inputs,5999,"tiveBedReader. I1029 09:19:01.129340 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139694 139762738964288 make_examples_core.py:243] Task 2/8: Preparing inputs. I1029 09:19:01.149530 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160889 139762738964288 make_examples_core.py:243] Task 2/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171224 139762738964288 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:6715,safety,input,input,6715,"s_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7069,safety,input,input,7069,"ding data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7423,safety,input,input,7423,"'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7777,safety,input,input,7777,"ed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8131,safety,input,input,8131,"ed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8485,safety,input,input,8485,"ed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8839,safety,input,input,8839,"ed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading da",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:9193,safety,input,input,9193,"ed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435622 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:10545,safety,input,inputs,10545,08736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435622 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.891901 139999733659456 make_examples_core.py:243] Task 5/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:10958,safety,input,inputs,10958,ading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.891901 139999733659456 make_examples_core.py:243] Task 5/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:11371,safety,input,inputs,11371,utput/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:11911,safety,input,inputs,11911,re.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:12451,safety,input,inputs,12451,ading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:12864,safety,input,inputs,12864,re.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13277,safety,input,inputs,13277,"utput/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13690,safety,input,inputs,13690,"utput/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/mak",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13990,safety,error,error,13990,"NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15273,safety,modul,module,15273,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15563,safety,error,error,15563,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:16846,safety,modul,module,16846,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17136,safety,error,error,17136,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18419,safety,modul,module,18419,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18709,safety,error,error,18709,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:19992,safety,modul,module,19992,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20282,safety,error,error,20282,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21565,safety,modul,module,21565,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21855,safety,error,error,21855,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23138,safety,modul,module,23138,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23428,safety,error,error,23428,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24711,safety,modul,module,24711,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:25001,safety,error,error,25001,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:26284,safety,modul,module,26284,"nt/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 7. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 1. parallel: This job failed:. /opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:0,usability,Error,Error,0,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:609,usability,input,inputs,609,"Error in trying RNA-Seq case study , it aborted ; time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] R",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1379,usability,input,inputs,1379,"ads --task {}. I1029 09:19:01.137503 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.142284 139999733659456 make_examples_core.py:243] Task 5/8: Preparing inputs. I1029 09:19:01.149530 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160975 139999733659456 make_examples_core.py:243] Task 5/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171208 139999733659456 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155034 139948131759936 make_examples_core.py:243] Task 0/8: Preparing inputs. I1029 09:19:01.163061 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175836 139948131759936 make_examples_core.py:243] Task 0/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2149,usability,input,inputs,2149,"tiveBedReader. I1029 09:19:01.129341 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155029 140082896508736 make_examples_core.py:243] Task 4/8: Preparing inputs. I1029 09:19:01.163015 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175610 140082896508736 make_examples_core.py:243] Task 4/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184050 140082896508736 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155034 139948131759936 make_examples_core.py:243] Task 0/8: Preparing inputs. I1029 09:19:01.163061 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175836 139948131759936 make_examples_core.py:243] Task 0/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184607 139948131759936 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129342 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139182 140209041569600 make_examples_core.py:243] Task 7/8: Preparing inputs. I1029 09:19:01.149531 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160770 140209041569600 make_examples_core.py:243] Task 7/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2919,usability,input,inputs,2919,"tiveBedReader. I1029 09:19:01.129348 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155034 139948131759936 make_examples_core.py:243] Task 0/8: Preparing inputs. I1029 09:19:01.163061 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175836 139948131759936 make_examples_core.py:243] Task 0/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184607 139948131759936 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129342 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139182 140209041569600 make_examples_core.py:243] Task 7/8: Preparing inputs. I1029 09:19:01.149531 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160770 140209041569600 make_examples_core.py:243] Task 7/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171079 140209041569600 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129353 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.159007 140280424228672 make_examples_core.py:243] Task 1/8: Preparing inputs. I1029 09:19:01.167812 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.178546 140280424228672 make_examples_core.py:243] Task 1/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3689,usability,input,inputs,3689,"tiveBedReader. I1029 09:19:01.129342 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139182 140209041569600 make_examples_core.py:243] Task 7/8: Preparing inputs. I1029 09:19:01.149531 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160770 140209041569600 make_examples_core.py:243] Task 7/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171079 140209041569600 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129353 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.159007 140280424228672 make_examples_core.py:243] Task 1/8: Preparing inputs. I1029 09:19:01.167812 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.178546 140280424228672 make_examples_core.py:243] Task 1/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.186683 140280424228672 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155033 139760086697792 make_examples_core.py:243] Task 3/8: Preparing inputs. I1029 09:19:01.163016 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175488 139760086697792 make_examples_core.py:243] Task 3/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:4459,usability,input,inputs,4459,"tiveBedReader. I1029 09:19:01.129353 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.159007 140280424228672 make_examples_core.py:243] Task 1/8: Preparing inputs. I1029 09:19:01.167812 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.178546 140280424228672 make_examples_core.py:243] Task 1/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.186683 140280424228672 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155033 139760086697792 make_examples_core.py:243] Task 3/8: Preparing inputs. I1029 09:19:01.163016 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175488 139760086697792 make_examples_core.py:243] Task 3/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184188 139760086697792 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139694 139762738964288 make_examples_core.py:243] Task 2/8: Preparing inputs. I1029 09:19:01.149530 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160889 139762738964288 make_examples_core.py:243] Task 2/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5229,usability,input,inputs,5229,"tiveBedReader. I1029 09:19:01.129340 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.155033 139760086697792 make_examples_core.py:243] Task 3/8: Preparing inputs. I1029 09:19:01.163016 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.175488 139760086697792 make_examples_core.py:243] Task 3/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.184188 139760086697792 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139694 139762738964288 make_examples_core.py:243] Task 2/8: Preparing inputs. I1029 09:19:01.149530 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160889 139762738964288 make_examples_core.py:243] Task 2/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171224 139762738964288 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5999,usability,input,inputs,5999,"tiveBedReader. I1029 09:19:01.129340 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139694 139762738964288 make_examples_core.py:243] Task 2/8: Preparing inputs. I1029 09:19:01.149530 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160889 139762738964288 make_examples_core.py:243] Task 2/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171224 139762738964288 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:6715,usability,input,input,6715,"s_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.129340 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.139380 140039545739072 make_examples_core.py:243] Task 6/8: Preparing inputs. I1029 09:19:01.149531 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7069,usability,input,input,7069,"ding data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:01.160860 140039545739072 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7423,usability,input,input,7423,"'chrY', 'chrM']. I1029 09:19:01.171361 140039545739072 genomics_reader.py:222] Reading data/chr20_CDS_3x.bed with NativeBedReader. I1029 09:19:01.962299 139999733659456 make_examples_core.py:243] Task 5/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:7777,usability,input,input,7777,"ed in with --ref. 2022-10-29 09:19:01.962564: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.958336 140082896508736 make_examples_core.py:243] Task 4/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8131,usability,input,input,8131,"ed in with --ref. 2022-10-29 09:19:01.958533: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.975741 139948131759936 make_examples_core.py:243] Task 0/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8485,usability,input,input,8485,"ed in with --ref. 2022-10-29 09:19:01.976085: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.969423 140209041569600 make_examples_core.py:243] Task 7/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:8839,usability,input,input,8839,"ed in with --ref. 2022-10-29 09:19:01.969733: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.970285 140280424228672 make_examples_core.py:243] Task 1/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading da",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:9193,usability,input,input,9193,"ed in with --ref. 2022-10-29 09:19:01.970651: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.977449 139760086697792 make_examples_core.py:243] Task 3/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.978013: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.960562 139762738964288 make_examples_core.py:243] Task 2/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.960805: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:01.949421 140039545739072 make_examples_core.py:243] Task 6/8: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-10-29 09:19:01.949617: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1029 09:19:03.446390 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.460500 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435622 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:10545,usability,input,inputs,10545,08736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.486031 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435608 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435622 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.891901 139999733659456 make_examples_core.py:243] Task 5/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:10958,usability,input,inputs,10958,ading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.435574 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.800781 139999733659456 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.891901 139999733659456 make_examples_core.py:243] Task 5/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:11371,usability,input,inputs,11371,utput/intermediate_results_dir/make_examples.tfrecord-00005-of-00008.gz. I1029 09:19:03.892162 139999733659456 make_examples_core.py:243] Task 5/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060145 140082896508736 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.166156 140082896508736 make_examples_core.py:243] Task 4/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00004-of-00008.gz. I1029 09:19:04.166650 140082896508736 make_examples_core.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:11911,usability,input,inputs,11911,re.py:243] Task 4/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.700758 139948131759936 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.762802 139948131759936 make_examples_core.py:243] Task 0/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00000-of-00008.gz. I1029 09:19:03.763408 139948131759936 make_examples_core.py:243] Task 0/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.627500 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:12451,usability,input,inputs,12451,ading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058238 140209041569600 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.149155 140209041569600 make_examples_core.py:243] Task 7/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00007-of-00008.gz. I1029 09:19:04.149482 140209041569600 make_examples_core.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:12864,usability,input,inputs,12864,re.py:243] Task 7/8: Overhead for preparing inputs: 3 seconds. I1029 09:19:03.563157 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.058246 140280424228672 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.135683 140280424228672 make_examples_core.py:243] Task 1/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13277,usability,input,inputs,13277,"utput/intermediate_results_dir/make_examples.tfrecord-00001-of-00008.gz. I1029 09:19:04.136067 140280424228672 make_examples_core.py:243] Task 1/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.707219 139760086697792 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.840352 139760086697792 make_examples_core.py:243] Task 3/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13690,usability,input,inputs,13690,"utput/intermediate_results_dir/make_examples.tfrecord-00003-of-00008.gz. I1029 09:19:03.840481 139760086697792 make_examples_core.py:243] Task 3/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/mak",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13836,usability,statu,statusor,13836," Overhead for preparing inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13859,usability,statu,status,13859,"g inputs: 2 seconds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13875,usability,statu,status,13875,"nds. I1029 09:19:03.690408 139762738964288 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13990,usability,error,error,13990,"NativeSamReader. I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz. I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds. I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz. I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15409,usability,statu,statusor,15409,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15432,usability,statu,status,15432,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15448,usability,statu,status,15448,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15563,usability,error,error,15563,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403. Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:16982,usability,statu,statusor,16982,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17005,usability,statu,status,17005,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17021,usability,statu,status,17021,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17136,usability,error,error,17136,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287. Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18555,usability,statu,statusor,18555,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18578,usability,statu,status,18578,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18594,usability,statu,status,18594,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18709,usability,error,error,18709,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101. Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20128,usability,statu,statusor,20128,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20151,usability,statu,status,20151,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20167,usability,statu,status,20167,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20282,usability,error,error,20282,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106. Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21701,usability,statu,statusor,21701,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21724,usability,statu,status,21724,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21740,usability,statu,status,21740,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21855,usability,error,error,21855,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165. Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23274,usability,statu,statusor,23274,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23297,usability,statu,status,23297,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23313,usability,statu,status,23313,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23428,usability,error,error,23428,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899. Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24847,usability,statu,statusor,24847,"ant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24870,usability,statu,status,24870,"ner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24886,usability,statu,status,24886,""", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:25001,usability,error,error,25001,"xamples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run. File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350. Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner. File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/582:356,integrability,topic,topic,356,"Can you determine why a variant was refcalled based on scores or stats in the vcf?; Hello, . This might be naive question but in the outputted vcf files are there any scores or outputs that can be used to determine why a variant may have been called as refcall or not, in comparison to those called as passed? I have read other answers in relation to this topic but I am still a bit confused. Thanks! Amy.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/583:63,modifiability,inherit,inherited,63,"Use of deepvariant for targeted haloplex data?; Hello,. I have inherited some haloplex data, and ideally I would like to use deepvariant for its analyses as I have used this for my WES. . Do you think deepvariant would work proficiently for haloplex data? Thanks! Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/583
https://github.com/google/deepvariant/issues/584:80,availability,state,states,80,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:8,energy efficiency,model,model,8,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:360,energy efficiency,model,model,360,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:80,integrability,state,states,80,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:14,safety,valid,valid,14,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:8,security,model,model,8,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:262,security,access,access,262,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:360,security,model,model,360,"RNA-seq model valid for genome-wide calling?; Hi,. From the RNA example doc, it states. > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? . Best,. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/585:1297,deployability,Fail,Failed,1297," --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.Index",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1524,deployability,modul,module,1524,"ctory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2889,deployability,Fail,Failed,2889,"mples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.Index",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:3116,deployability,modul,module,3116,"ons). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4193,deployability,fail,failed,4193,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2529,energy efficiency,load,load,2529,". app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4121,energy efficiency,load,load,4121,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:735,integrability,buffer,buffer,735,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:537,modifiability,interm,intermediate,537,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:585,modifiability,Interm,Intermediate,585,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1524,modifiability,modul,module,1524,"ctory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:3116,modifiability,modul,module,3116,"ons). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:692,performance,time,time,692,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:707,performance,parallel,parallel,707,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2529,performance,load,load,2529,". app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4121,performance,load,load,4121,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4174,performance,parallel,parallel,4174,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1297,reliability,Fail,Failed,1297," --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.Index",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2889,reliability,Fail,Failed,2889,"mples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.Index",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4193,reliability,fail,failed,4193,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:185,safety,input,input,185,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:325,safety,input,input,325,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:353,safety,input,input,353,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:800,safety,input,input,800,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:830,safety,input,input,830,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1049,safety,input,input,1049,"variant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1142,safety,input,input,1142,"sers\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1269,safety,input,inputs,1269,"pvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1325,safety,input,input,1325,"ut/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1524,safety,modul,module,1524,"ctory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2562,safety,input,input,2562,"runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2641,safety,input,input,2641,"in, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2734,safety,input,input,2734,"n_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2861,safety,input,inputs,2861," line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2917,safety,input,input,2917,"ner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:3116,safety,modul,module,3116,"ons). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4154,safety,input,input,4154,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4259,safety,input,input,4259,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4287,safety,input,input,4287,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1376,testability,Trace,Traceback,1376,"_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2968,testability,Trace,Traceback,2968,"iles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:87,usability,User,Users,87,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:144,usability,User,Users,144,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:185,usability,input,input,185,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:197,usability,User,Users,197,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:325,usability,input,input,325,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:353,usability,input,input,353,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:677,usability,command,command,677,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:800,usability,input,input,800,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:830,usability,input,input,830,"Running Issue DeepVariant; Hello,. I am running Deepvariant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1049,usability,input,input,1049,"variant and facing an issue. PS C:\Users\Seungmo Lee\Desktop\researchProj> docker run -v C:\Users\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1142,usability,input,input,1142,"sers\Seungmo` Lee\Desktop\researchProj:/input -v C:\Users\Seungmo` Lee\Desktop\researchProj:/output google/deepvariant /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1269,usability,input,inputs,1269,"pvariant/bin/run_deepvariant --model_type=WGS --ref=/input/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:1325,usability,input,input,1325,"ut/chr19_new.fa --reads=/input/A_J.chr19.bam --output_vcf=/output --output_gvcf=/output --num_shards=2 --dry_run=false. I1114 07:56:43.730724 140466373666624 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpr4ux434h. ***** Intermediate results will be written to /tmp/tmpr4ux434h in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/chr19_new.fa"" --reads ""/input/A_J.chr19.bam"" --examples ""/tmp/tmpr4ux434h/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpr4ux434h/gvcf.tfrecord@2.gz"" --task {}. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139676 140084824217408 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142330 140084824217408 make_examples_core.py:243] Task 1/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2562,usability,input,input,2562,"runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2641,usability,input,input,2641,"in, args). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2734,usability,input,input,2734,"n_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2861,usability,input,inputs,2861," line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_option",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:2917,usability,input,input,2917,"ner(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4154,usability,input,input,4154,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4259,usability,input,input,4259,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4287,usability,input,input,4287,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4454,usability,user,user,4454,"e(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'. I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader. I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs. [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options. ref_contigs = fasta.IndexedFastaReader(. File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__. self._reader = reference.IndexedFastaReader.from_file(. ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s. user 0m2.534s. sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/586:1242,availability,Operat,Operating,1242,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1288,deployability,version,version,1288,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1319,deployability,Instal,Installation,1319,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:97,integrability,batch,batch,97,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1288,integrability,version,version,1288,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:44,interoperability,distribut,distribution,44,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:88,interoperability,specif,specific,88,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:166,interoperability,distribut,distributions,166,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1288,modifiability,version,version,1288,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:97,performance,batch,batch,97,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:253,reliability,doe,doesn,253,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:404,safety,input,input,404,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1415,testability,instrument,instrument,1415,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:404,usability,input,input,404,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:570,usability,visual,visual,570,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:643,usability,user,user-images,643,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1011,usability,user,user-images,1011,"Lower than expected GQ values, with bimodal distribution; **Describe the issue:**. On a specific batch of samples, GQs and QUALs seem to be abnormal. The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. . ```. chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22. ```. ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated. Thank you. **Setup**. - Operating system: Ubuntu 20.04. - DeepVariant version: 1.4 (but also 1.2). - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). Novaseq, 100bp paired, HG38. **Steps to reproduce:**. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/587:302,modifiability,interm,intermediate,302,"If I stop halfway while running deepvariant, do I need to start all the steps again?; I finnished make_example and call_variant by docker, but somehow it stoped. So i restart docker and realized i have to do make_example and call_variant again even I already have set intermediate_results_dir to store intermediate outputs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/587
https://github.com/google/deepvariant/issues/587:5,usability,stop,stop,5,"If I stop halfway while running deepvariant, do I need to start all the steps again?; I finnished make_example and call_variant by docker, but somehow it stoped. So i restart docker and realized i have to do make_example and call_variant again even I already have set intermediate_results_dir to store intermediate outputs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/587
https://github.com/google/deepvariant/issues/587:154,usability,stop,stoped,154,"If I stop halfway while running deepvariant, do I need to start all the steps again?; I finnished make_example and call_variant by docker, but somehow it stoped. So i restart docker and realized i have to do make_example and call_variant again even I already have set intermediate_results_dir to store intermediate outputs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/587
https://github.com/google/deepvariant/issues/588:249,availability,Operat,Operating,249,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:922,availability,Error,Error,922,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:65,deployability,pipelin,pipeline,65,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:95,deployability,pipelin,pipeline,95,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:136,deployability,pipelin,pipeline,136,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:301,deployability,version,version,301,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:319,deployability,Instal,Installation,319,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:959,deployability,fail,failed,959,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2373,deployability,fail,failed,2373,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:65,integrability,pipelin,pipeline,65,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:95,integrability,pipelin,pipeline,95,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:136,integrability,pipelin,pipeline,136,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:301,integrability,version,version,301,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:301,modifiability,version,version,301,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:922,performance,Error,Error,922,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:940,performance,parallel,parallel,940,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2354,performance,parallel,parallel,2354,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:959,reliability,fail,failed,959,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2373,reliability,fail,failed,2373,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:538,safety,input,input,538,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:547,safety,input,input,547,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:688,safety,input,input,688,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:745,safety,input,input,745,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:922,safety,Error,Error,922,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2324,safety,input,input,2324,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2439,safety,input,input,2439,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2493,safety,input,input,2493,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2722,safety,test,test,2722,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:407,testability,instrument,instrument,407,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:928,testability,trace,trace,928,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2722,testability,test,test,2722,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:479,usability,Command,Command,479,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:538,usability,input,input,538,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:547,usability,input,input,547,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:688,usability,input,input,688,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:745,usability,input,input,745,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:922,usability,Error,Error,922,"Getting ""ValueError: NOT_FOUND: Could not open"" when running the pipeline; Hi. I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue. Can you assist in any way? Thanks. **Setup**. - Operating system: Ubuntu 20.04.5 LTS. - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**. - Command:. ```. BIN_VERSION=""1.4.0"". sudo docker run \. -v ""input"":""/input"" \. -v ""output"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2324,usability,input,input,2324,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2439,usability,input,input,2439,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2493,usability,input,input,2493,"fa.gz \. --reads=/input/1115492_23181_0_0.cram \. --regions ""chr3:10,049,322-10,156,156"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=5 . ```. - Error trace:. . > parallel: This job failed:. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q. 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/589:1079,deployability,log,log,1079,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:79,energy efficiency,model,model,79,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:224,energy efficiency,model,model,224,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:397,integrability,buffer,buffer,397,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:72,modifiability,pac,pacbio,72,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:155,modifiability,pac,pacbio-hifi,155,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:340,performance,time,time,340,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:372,performance,parallel,parallel,372,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:1079,safety,log,log,1079,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:79,security,model,model,79,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:224,security,model,model,224,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:910,security,ident,identity,910,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:1079,security,log,log,1079,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:1079,testability,log,log,1079,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/589:328,usability,command,command,328,"Problem encountered while make_example ; Hello, I am trying to train my pacbio model using DeepVariant-inception_v3-1.4.0+data-pacbio_standard on HG003.pacbio-hifi.21x.haplotag.grch38.bam. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --line-buffer \. sudo docker run \. -v ${BASE}:${BASE} \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM_003}"" \. --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \. --truth_variants ""${TRUTH_VCF_003}"" \. --confident_regions ""${TRUTH_BED_003}"" \. --task {} \. --regions ' ""chr20"" ' \. 	 --sort_by_haplotypes \. 	 --parse_sam_aux_fields \. 	 --add_hp_channel \. 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \. ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]. I'm curious how do I get channels 9 and 10Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/590:158,deployability,version,version,158,"How to run the pre-built bunaries DeepVariant; **Describe the issue:**. Since I couldn't run DeepVariant with Docker, I thought I'd try the prebuilt binaries version, but I couldn't find a guide on how to use the prebuilt binaries DeepVariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/590
https://github.com/google/deepvariant/issues/590:158,integrability,version,version,158,"How to run the pre-built bunaries DeepVariant; **Describe the issue:**. Since I couldn't run DeepVariant with Docker, I thought I'd try the prebuilt binaries version, but I couldn't find a guide on how to use the prebuilt binaries DeepVariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/590
https://github.com/google/deepvariant/issues/590:158,modifiability,version,version,158,"How to run the pre-built bunaries DeepVariant; **Describe the issue:**. Since I couldn't run DeepVariant with Docker, I thought I'd try the prebuilt binaries version, but I couldn't find a guide on how to use the prebuilt binaries DeepVariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/590
https://github.com/google/deepvariant/issues/590:189,usability,guid,guide,189,"How to run the pre-built bunaries DeepVariant; **Describe the issue:**. Since I couldn't run DeepVariant with Docker, I thought I'd try the prebuilt binaries version, but I couldn't find a guide on how to use the prebuilt binaries DeepVariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/590
https://github.com/google/deepvariant/issues/591:329,availability,operat,operating,329,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:482,availability,Operat,Operating,482,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:25,deployability,build,build,25,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:175,deployability,releas,release,175,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:217,deployability,fail,failed,217,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:247,deployability,instal,install,247,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:280,deployability,build,build,280,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:320,deployability,Updat,Updating,320,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:426,deployability,build,build,426,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:531,deployability,version,version,531,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:551,deployability,Instal,Installation,551,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:531,integrability,version,version,531,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:255,modifiability,pac,packages,255,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:531,modifiability,version,version,531,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:217,reliability,fail,failed,217,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:320,safety,Updat,Updating,320,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:227,security,modif,modified,227,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:320,security,Updat,Updating,320,"Is ubuntu20.04 a must to build DV-1.4?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed. I modified scripts to install packages that is need to build DV-1.4, which didn't work for me. Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**. - Operating system: **Ubuntu16.04**. - DeepVariant version: **1.4**. - Installation method (Docker, built from source, etc.): **built from source**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/592:1119,availability,Operat,Operating,1119,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1828,availability,Error,Error,1828,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1070,deployability,version,versions,1070,"epvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1164,deployability,version,version,1164,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1182,deployability,Instal,Installation,1182,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1070,integrability,version,versions,1070,"epvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1164,integrability,version,version,1164,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1070,modifiability,version,versions,1070,"epvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1164,modifiability,version,version,1164,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1828,performance,Error,Error,1828,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1860,reliability,Doe,Does,1860,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1642,safety,INPUT,INPUT,1642,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1828,safety,Error,Error,1828,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1881,safety,test,test,1881,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1917,safety,test,test,1917,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1273,testability,instrument,instrument,1273,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1834,testability,trace,trace,1834,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1881,testability,test,test,1881,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1917,testability,test,test,1917,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:142,usability,clear,clear,142,"Strange GT value; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:258,usability,visual,visualisation,258,"Strange GT value; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:310,usability,clear,clearly,310,"Strange GT value; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:378,usability,user,user-images,378,"Strange GT value; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1083,usability,command,commands,1083,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1454,usability,Command,Command,1454,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1642,usability,INPUT,INPUT,1642,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1828,usability,Error,Error,1828,"riant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:. ```. chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0. ```. .gvcf file:. ```. chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990. ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:. ```. chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0. ```. ```. chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990. ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same? **Setup**. - Operating system: Ubuntu16.04. - DeepVariant version: 1.2.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**. - Command:. ```. docker run \. -v ${MOUNT_DIR}:${MOUNT_DIR} \. google/deepvariant:1.2.0-rc0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""${REFERENCE}"" \. --reads=""${INPUT}"" \. --regions=""${CAPTURE_KIT}"" \. --output_vcf=${OUTPUT_VCF} \. --output_gvcf=${OUTPUT_GVCF} \. --num_shards=64 \. --postprocess_variants_extra_args=""only_keep_pass=true"". ```. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/593:168,availability,error,error,168,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:265,availability,error,error,265,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:168,performance,error,error,168,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:265,performance,error,error,265,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:168,safety,error,error,168,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:265,safety,error,error,265,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:24,usability,command,command,24,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:75,usability,command,command,75,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:168,usability,error,error,168,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:265,usability,error,error,265,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:345,usability,user,user-images,345,"Problem with docker run command; Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. . <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,. Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/594:290,usability,tool,tool,290,"3-generation pedigree analysis possible?; Hi, I am toying with the idea to get a 3-generation trio sample for a condition I am interested in and 1 parent and child generation has the condition while the grandparent generation is not. May I know if this kind of pedigree can be used for the tool effectively using the 3-generation pedigree structure or it can only take 2 generation?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/594
https://github.com/google/deepvariant/issues/594:295,usability,effectiv,effectively,295,"3-generation pedigree analysis possible?; Hi, I am toying with the idea to get a 3-generation trio sample for a condition I am interested in and 1 parent and child generation has the condition while the grandparent generation is not. May I know if this kind of pedigree can be used for the tool effectively using the 3-generation pedigree structure or it can only take 2 generation?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/594
https://github.com/google/deepvariant/issues/595:371,availability,error,error,371,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:400,availability,error,error,400,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:634,deployability,pipelin,pipeline,634,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:867,deployability,pipelin,pipeline,867,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:634,integrability,pipelin,pipeline,634,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:867,integrability,pipelin,pipeline,867,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:371,performance,error,error,371,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:400,performance,error,error,400,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:960,performance,time,times,960,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:175,safety,valid,validation,175,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:227,safety,test,test,227,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:371,safety,error,error,371,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:400,safety,error,error,400,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:625,safety,test,test,625,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:175,security,validat,validation,175,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:227,testability,test,test,227,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:625,testability,test,test,625,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:371,usability,error,error,371,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:400,usability,error,error,400,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:415,usability,command,command,415,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:464,usability,help,helpshort,464,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:479,usability,help,helpfull,479,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:495,usability,help,help,495,"BQSR bam files with --use_original_quality_scores; Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive! I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields . --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'. Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/596:105,availability,down,downloading,105,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:272,availability,Operat,Operating,272,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:311,deployability,version,version,311,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:329,deployability,Instal,Installation,329,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:54,energy efficiency,model,model,54,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:311,integrability,version,version,311,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:311,modifiability,version,version,311,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:54,security,model,model,54,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:183,usability,command,command,183,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:506,usability,user,user-images,506,"Ran into a compilation issue when running DeepVariant model on MacOS; After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS. - DeepVariant version: 1.4.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/597:43,availability,error,error,43,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:69,availability,error,error,69,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6727,availability,checkpoint,checkpoint,6727,"3934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7488,availability,operat,operations,7488,".324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7542,availability,operat,operations,7542,"he command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9142,availability,Restor,Restoring,9142,"tputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9249,availability,Restor,Restoring,9249,"ng: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:651,deployability,log,logs,651,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:702,deployability,contain,containers,702,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8092,deployability,version,version,8092,"all_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8318,deployability,version,version,8318,"ture_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8567,deployability,version,version,8567,"w with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instruct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8793,deployability,version,version,8793,"st performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9020,deployability,version,version,9020,"arning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variabl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9554,deployability,version,version,9554,"a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9580,deployability,updat,updating,9580,"se `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9943,deployability,version,version,9943,"UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9969,deployability,updat,updating,9969," is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platfo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10277,deployability,version,version,10277,"odels/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10303,deployability,updat,updating,10303,"ING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10637,deployability,version,version,10637,"constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10663,deployability,updat,updating,10663,".056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10871,deployability,modul,module,10871,"ework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6744,energy efficiency,model,models,6744,"amples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6755,energy efficiency,model,model,6755,".py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7127,energy efficiency,model,models,7127,"core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7138,energy efficiency,model,model,7138,"3] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method inste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7301,energy efficiency,core,core,7301,"08 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be remov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7367,energy efficiency,optim,optimized,7367,"idate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7447,energy efficiency,CPU,CPU,7447,"43] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7651,energy efficiency,core,core,7651,".tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7898,energy efficiency,model,models,7898,"zyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7909,energy efficiency,model,model,7909,"amples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9173,energy efficiency,model,models,9173,"/usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_gr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9184,energy efficiency,model,model,9184,"lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9280,energy efficiency,model,models,9280,"ed and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future versio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9291,energy efficiency,model,model,9291," be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instruct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:11723,energy efficiency,model,model,11723,"tants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1023,integrability,buffer,buffer,1023,"' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8092,integrability,version,version,8092,"all_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8318,integrability,version,version,8318,"ture_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8567,integrability,version,version,8567,"w with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instruct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8793,integrability,version,version,8793,"st performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9020,integrability,version,version,9020,"arning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variabl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9554,integrability,version,version,9554,"a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9943,integrability,version,version,9943,"UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10277,integrability,version,version,10277,"odels/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10637,integrability,version,version,10637,"constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7306,interoperability,platform,platform,7306,"55214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10967,interoperability,platform,platform,10967,"dating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:825,modifiability,interm,intermediate,825,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:873,modifiability,Interm,Intermediate,873,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2296,modifiability,deco,decode,2296,"fzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3392,modifiability,deco,decode,3392,"/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.0728",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7979,modifiability,pac,packages,7979,"mples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7996,modifiability,layer,layers,7996,", 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8003,modifiability,layer,layers,8003,"hannels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be remove",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8033,modifiability,layer,layer,8033," 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8092,modifiability,version,version,8092,"all_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8113,modifiability,layer,layer,8113," From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8155,modifiability,layer,layer,8155,"nfo.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parame",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8206,modifiability,pac,packages,8206,"annels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8223,modifiability,layer,layers,8223,"examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 14036301",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8230,modifiability,layer,layers,8230,"s: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8259,modifiability,layer,layer,8259,"22-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring par",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8318,modifiability,version,version,8318,"ture_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8339,modifiability,layer,layer,8339,"his TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8381,modifiability,layer,layer,8381,"eAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8454,modifiability,pac,packages,8454,"tions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8471,modifiability,layer,layers,8471,"ance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8478,modifiability,layer,layers,8478,"itical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8508,modifiability,layer,layer,8508,"F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8567,modifiability,version,version,8567,"w with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instruct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8588,modifiability,layer,layer,8588,"te compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8630,modifiability,layer,layer,8630,"084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8681,modifiability,pac,packages,8681,"c:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 1403630192",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8698,modifiability,layer,layers,8698,"new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecatio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8705,modifiability,layer,layers,8705,"ead pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:34",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8734,modifiability,layer,layer,8734,"p setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8793,modifiability,version,version,8793,"st performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8814,modifiability,layer,layer,8814,"4 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8856,modifiability,layer,layer,8856,"_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8907,modifiability,pac,packages,8907,"del.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8924,modifiability,layer,layers,8924,"_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be remo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8931,modifiability,layer,layers,8931,"[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8961,modifiability,layer,layer,8961,"python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9020,modifiability,version,version,9020,"arning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variabl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9041,modifiability,layer,layer,9041,"` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9083,modifiability,layer,layer,9083,"uture version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9152,modifiability,paramet,parameters,9152,"yer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9259,modifiability,paramet,parameters,9259,".apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9554,modifiability,version,version,9554,"a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9943,modifiability,version,version,9943,"UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10096,modifiability,pac,packages,10096,"s, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10277,modifiability,version,version,10277,"odels/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10456,modifiability,pac,packages,10456,"om tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10637,modifiability,version,version,10637,"constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10871,modifiability,modul,module,10871,"ework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10940,modifiability,pac,packages,10940,"ersion. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:43,performance,error,error,43,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:69,performance,error,error,69,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:980,performance,time,time,980,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:995,performance,parallel,parallel,995,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:4451,performance,Overhead,Overhead,4451,12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrec,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:5159,performance,Overhead,Overhead,5159,"cords to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I1214 06:02:02.278903 140052653934400 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:02:02.320155 140052653934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6565,performance,time,time,6565,"le_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:02:02.320155 140052653934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild Tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7367,performance,optimiz,optimized,7367,"idate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7401,performance,Network,Network,7401,"8840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, trai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7447,performance,CPU,CPU,7447,"43] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7467,performance,perform,performance-critical,7467,"mples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7751,performance,Tune,Tune,7751,"s/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is dep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7800,performance,perform,performance,7800," --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Plea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6727,reliability,checkpoint,checkpoint,6727,"3934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9142,reliability,Restor,Restoring,9142,"tputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9249,reliability,Restor,Restoring,9249,"ng: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:43,safety,error,error,43,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:69,safety,error,error,69,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:207,safety,input,input,207,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:376,safety,input,input,376,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:404,safety,input,input,404,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:651,safety,log,logs,651,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1088,safety,input,input,1088,"et me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1118,safety,input,input,1118,"anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1442,safety,input,input,1442,"4f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1626,safety,input,inputs,1626,"--logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1705,safety,input,input,1705,"ners/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2271,safety,input,input,2271,"ize"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2538,safety,input,input,2538,"I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2722,safety,input,inputs,2722,"work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2801,safety,input,input,2801,"I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3367,safety,input,input,3367,":34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-0000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3634,safety,input,input,3634,"I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 1400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3804,safety,input,input,3804,"60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 1400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3974,safety,input,input,3974,"mmon contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:4474,safety,input,inputs,4474, I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:4682,safety,input,input,4682,"d1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I1214 06:02:02.278903 140052653934400 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:5182,safety,input,inputs,5182,"zyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I1214 06:02:02.278903 140052653934400 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:02:02.320155 140052653934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6974,safety,input,input,6974,"Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dis",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7017,safety,input,input,7017,"ke_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: U",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7177,safety,input,input,7177," 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7220,safety,input,input,7220,"les_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8167,safety,input,inputs,8167,"ape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8393,safety,input,inputs,8393,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8642,safety,input,inputs,8642,"rflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_cons",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8868,safety,input,inputs,8868,"y:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9095,safety,input,inputs,9095,"n. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9580,safety,updat,updating,9580,"se `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9969,safety,updat,updating,9969," is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platfo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10303,safety,updat,updating,10303,"ING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10663,safety,updat,updating,10663,".056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10871,safety,modul,module,10871,"ework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:651,security,log,logs,651,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6744,security,model,models,6744,"amples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6755,security,model,model,6755,".py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7127,security,model,models,7127,"core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7138,security,model,model,7138,"3] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method inste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7401,security,Network,Network,7401,"8840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, trai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7898,security,model,models,7898,"zyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7909,security,model,model,7909,"amples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9173,security,model,models,9173,"/usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_gr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9184,security,model,model,9184,"lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9280,security,model,models,9280,"ed and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future versio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9291,security,model,model,9291," be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instruct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9580,security,updat,updating,9580,"se `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9969,security,updat,updating,9969," is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platfo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10303,security,updat,updating,10303,"ING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10663,security,updat,updating,10663,".056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:11723,security,model,model,11723,"tants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:651,testability,log,logs,651,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:657,testability,Emul,Emulate,657,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:10723,testability,Trace,Traceback,10723,"unfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. W1214 06:10:41.057430 140363019278144 deprecation.py:341] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py:929: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.extract_sub_graph`. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main. call_variants(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants. ie_estimator = OpenVINOEstimator(. File ""/tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__. freeze_graph(model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:43,usability,error,error,43,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:69,usability,error,error,69,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:189,usability,Document,Documents,189,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:207,usability,input,input,207,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:231,usability,Document,Documents,231,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:376,usability,input,input,376,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:404,usability,input,input,404,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:965,usability,command,command,965,"optimize_for_inference_lib' is not defined error; Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1088,usability,input,input,1088,"et me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1118,usability,input,input,1118,"anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1442,usability,input,input,1442,"4f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1626,usability,input,inputs,1626,"--logging_dir=/output/logs. Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:1705,usability,input,input,1705,"ners/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****. time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2271,usability,input,input,2271,"ize"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2538,usability,input,input,2538,"I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs. I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2722,usability,input,inputs,2722,"work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:2801,usability,input,input,2801,"I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.198254 140555214505792 make_examples_core.py:243] Task 1/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3367,usability,input,input,3367,":34.198784: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:33.916420 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-0000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3634,usability,input,input,3634,"I1214 05:45:33.947322 140052653934400 make_examples_core.py:243] Task 0/2: Preparing inputs. I1214 05:45:34.025260 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 1400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3804,usability,input,input,3804,"60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:34.073680 140052653934400 make_examples_core.py:243] Task 0/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 1400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:3974,usability,input,input,3974,"mmon contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I1214 05:45:34.124348 140052653934400 make_examples_core.py:243] Task 0/2: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2022-12-14 05:45:34.124915: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_exam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:4474,usability,input,inputs,4474, I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1214 05:45:40.845054 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:4682,usability,input,input,4682,"d1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:40.834452 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.058780 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.070213 140555214505792 make_examples_core.py:243] Task 1/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I1214 06:02:02.278903 140052653934400 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:5182,usability,input,inputs,5182,"zyx/gvcf.tfrecord-00001-of-00002.gz. I1214 05:45:43.072572 140555214505792 make_examples_core.py:243] Task 1/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz. I1214 05:45:43.072886 140555214505792 make_examples_core.py:243] Task 1/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:43.768549 140555214505792 make_examples_core.py:243] Task 1/2: 2 candidates (2 examples) [0.70s elapsed]. I1214 05:45:43.182209 140052653934400 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader. I1214 05:45:43.196409 140052653934400 make_examples_core.py:243] Task 0/2: Writing gvcf records to /tmp/tmpiy9bfzyx/gvcf.tfrecord-00000-of-00002.gz. I1214 05:45:43.198944 140052653934400 make_examples_core.py:243] Task 0/2: Writing examples to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz. I1214 05:45:43.199340 140052653934400 make_examples_core.py:243] Task 0/2: Overhead for preparing inputs: 9 seconds. I1214 05:45:45.989331 140052653934400 make_examples_core.py:243] Task 0/2: 7 candidates (12 examples) [2.79s elapsed]. I1214 06:02:02.274300 140052653934400 make_examples_core.py:243] Task 0/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json. I1214 06:02:02.278903 140052653934400 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:02:02.320155 140052653934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6500,usability,user,user,6500,"06:02:02.278903 140052653934400 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:02:02.320155 140052653934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6550,usability,command,command,6550,"y:1883] example_shape = [100, 221, 7]. I1214 06:02:02.279304 140052653934400 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:02:02.320155 140052653934400 make_examples_core.py:243] Task 0/2: Found 77 candidate variants. I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples. I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6974,usability,input,input,6974,"Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dis",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7017,usability,input,input,7017,"ke_examples.tfrecord-00001-of-00002.gz.example_info.json. I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]. I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: U",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7177,usability,input,input,7177," 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7220,usability,input,input,7220,"les_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants. I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7467,usability,perform,performance-critical,7467,"mples. real	25m4.324s. user	39m40.647s. sys	0m24.239s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7800,usability,perform,performance,7800," --use_openvino. I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Plea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8019,usability,User,UserWarning,8019,"amples: [1, 2, 3, 4, 5, 6, 19]. I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future versi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8167,usability,input,inputs,8167,"ape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8245,usability,User,UserWarning,8245," 6, 19]. 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8393,usability,input,inputs,8393,"ural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8494,usability,User,UserWarning,8494,"AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_uti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8642,usability,input,inputs,8642,"rflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_cons",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8720,usability,User,UserWarning,8720,"ult inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8868,usability,input,inputs,8868,"y:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]. /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8947,usability,User,UserWarning,8947,"/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:9095,usability,input,inputs,9095,"n. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs). /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead. outputs = layer.apply(inputs, training=is_training). INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt. I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt. WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.compat.v1.graph_util.convert_variables_to_constants`. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/598:74,availability,error,error,74,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:126,availability,error,error,126,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1288,availability,error,error,1288,"rong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1346,availability,error,error,1346,"ot permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1404,availability,error,error,1404," and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1462,availability,error,error,1462," --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1520,availability,error,error,1520,".uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1578,availability,error,error,1578,". ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1636,availability,error,error,1636,"you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1694,availability,error,error,1694," Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1752,availability,error,error,1752,". Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1810,availability,error,error,1810,",. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1868,availability,error,error,1868,"helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1926,availability,error,error,1926," CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1984,availability,error,error,1984,"U Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2042,availability,error,error,2042,": run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambafo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2100,availability,error,error,2100,"obs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2158,availability,error,error,2158,"ompleted/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2216,availability,error,error,2216,": 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subproce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2274,availability,error,error,2274,"ttributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2332,availability,error,error,2332,"ttributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2390,availability,error,error,2390,"ttributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:21,deployability,instal,installed,21,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:541,deployability,log,logdir,541,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:817,deployability,log,login,817,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2854,deployability,modul,module,2854,"ttributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:3565,deployability,fail,failed,3565,"tes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --sample_name QJ --examples EXAMPLES/QJ.tfrecord@3.gz --task 2. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:458,energy efficiency,core,cores,458,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:803,energy efficiency,Power,Power,803,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1086,energy efficiency,CPU,CPU,1086,"file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1090,energy efficiency,core,cores,1090,"or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:727,integrability,pub,publication,727,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:3081,integrability,sub,subprocess,3081,"tes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --sample_name QJ --examples EXAMPLES/QJ.tfrecord@3.gz --task 2. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:3211,integrability,sub,subprocess,3211,"tes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --sample_name QJ --examples EXAMPLES/QJ.tfrecord@3.gz --task 2. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:3342,integrability,sub,subprocess,3342,"tes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --sample_name QJ --examples EXAMPLES/QJ.tfrecord@3.gz --task 2. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2737,interoperability,share,share,2737,"attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2904,interoperability,share,share,2904," (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --sample_name QJ --examples EXAMPLES/QJ.tfrecord@3.gz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:3655,interoperability,share,share,3655,"tes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --sample_name QJ --examples EXAMPLES/QJ.tfrecord@3.gz --task 2. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:171,modifiability,Pac,Pacbio,171,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2854,modifiability,modul,module,2854,"ttributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. Traceback (most recent call last):. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main. ""__main__"", mod_spec). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code. exec(code, run_globals). File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>. File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 360, in Main. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 287, in call. with Popen(*popenargs, **kwargs) as p:. File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 729, in __init__. restore_signals, start_new_session). File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/subprocess.py"", line 1364, in _execute_child. raise child_exception_type(errno_num, err_msg, err_filename). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'. parallel: This job failed:. /path/Mambaforge-4.14.0-1/envs/dpv/bin/python /path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip --mode calling --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --gvcf GVCF/QJ.gvcf.tfrecord@3.gz --s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:74,performance,error,error,74,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:126,performance,error,error,126,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:698,performance,Parallel,Parallel,698,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:775,performance,Parallel,Parallel,775,"deepvariant software installed using mamba does not run correctly ;lchmod error;No such file or directory: '/usr/bin/python3' error; Hi,. I want to call variations on the Pacbio bam data to get gvcf files. But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? . Please help! (No root permission;Centos7 x86;Only the user directory has read and write permission). ```. dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF. ```. ```. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run. 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete. ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function not implemented. lchmod (file attributes) error: Function ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
