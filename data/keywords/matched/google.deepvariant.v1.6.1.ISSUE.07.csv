id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/194:181,deployability,log,logged,181,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:101,energy efficiency,model,model,101,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:281,energy efficiency,model,models,281,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:45,performance,perform,performance,45,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:260,performance,perform,performance,260,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:21,reliability,doe,does,21,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:341,reliability,doe,does,341,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:0,safety,Log,Logged,0,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:181,safety,log,logged,181,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:316,safety,valid,validation,316,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:0,security,Log,Logged,0,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:16,security,loss,loss,16,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:101,security,model,model,101,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:181,security,log,logged,181,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:197,security,loss,loss,197,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:281,security,model,models,281,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:316,security,validat,validation,316,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:0,testability,Log,Logged,0,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:119,testability,simpl,simple,119,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:181,testability,log,logged,181,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:45,usability,perform,performance,45,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:119,usability,simpl,simple,119,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/194:260,usability,perform,performance,260,"Logged training loss does not decrease while performance improves; I'm trying to train a deepvariant model with a very simple topology. After a few thousands of training steps, the logged training loss starts to vibrate around a rather high value. However the performance of saved models still keeps improving on my validation data set. Why does this happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/194
https://github.com/google/deepvariant/issues/195:834,interoperability,format,format,834,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:886,performance,content,content,886,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:413,safety,input,input,413,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:578,safety,input,input,578,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:670,safety,input,input,670,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:413,usability,input,input,413,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:578,usability,input,input,578,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:670,usability,input,input,670,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:860,usability,help,help,860,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/195:998,usability,help,help,998,"Launching deepvariant in a bash script; Hello,. I realise that might be a Docker question rather than a deepvariant one. . I am unable to run deepvariant from within a bash script, however it works perfectly well at the prompt. . ```. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}"". BIN_VERSION=""0.8.0"". ```. Then I put the following in a script. ```. #!/usr/bin/zsh. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Avaga.Masurca.Graal.l5_n100_c1_N5_unpolished.fasta.sorted.min1000.renamed \. --reads=/input/out.bam \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=48. ```. which returns. ```. docker: invalid reference format. See 'docker run --help'. ```. Launching the content of the script by pasting it directly in the terminal works perfectly well, however. . Thank you for any help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/195
https://github.com/google/deepvariant/issues/196:41,deployability,pipelin,pipeline,41,chrY variants on Females; When I run the pipeline on females I get lots of PASSED variants on chrY. Why is that?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/196:41,integrability,pipelin,pipeline,41,chrY variants on Females; When I run the pipeline on females I get lots of PASSED variants on chrY. Why is that?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/196
https://github.com/google/deepvariant/issues/197:409,reliability,doe,does,409,"Genotype likelihood normalization for alt1/alt2; I was interested in understanding how heterozygous alt cases are dealt with, and came upon the explanation in [pileup_image.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/pileup_image.py),. which says that three different images are evaluated to obtain the necessary genotype likelihoods. I tried to scan further to see the code that actually does the evaluation of multiple images to obtain genotype likelihoods, but I am unable to locate the code. Could you please point me to the relevant source code section?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/197:69,testability,understand,understanding,69,"Genotype likelihood normalization for alt1/alt2; I was interested in understanding how heterozygous alt cases are dealt with, and came upon the explanation in [pileup_image.py](https://github.com/google/deepvariant/blob/r0.8/deepvariant/pileup_image.py),. which says that three different images are evaluated to obtain the necessary genotype likelihoods. I tried to scan further to see the code that actually does the evaluation of multiple images to obtain genotype likelihoods, but I am unable to locate the code. Could you please point me to the relevant source code section?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/197
https://github.com/google/deepvariant/issues/198:245,deployability,resourc,resources,245,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:245,energy efficiency,resourc,resources,245,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:285,energy efficiency,model,models,285,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:351,energy efficiency,model,model,351,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:459,energy efficiency,model,models,459,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:373,modifiability,paramet,parameters,373,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:231,performance,computational resourc,computational resources,231,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:245,safety,resourc,resources,245,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:285,security,model,models,285,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:351,security,model,model,351,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:459,security,model,models,459,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:39,testability,simul,simultaneously,39,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:101,testability,simul,simultaneously,101,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:245,testability,resourc,resources,245,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:522,usability,help,help,522,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/198:531,usability,support,support,531,"Using model_eval after model_train not simultaneously ; I know now that I should have run model_eval simultaneously with model_train. However, I did not do that and it is so hard for me to repeat the model_train step given limited computational resources. Now, I have a folder full of models but when I run model_evelm it just evaluates only the last model. . Is there any parameters to change or a turn around this issue to make model_eval evaluate multiple models after model_train is finished. I really appreciate your help and support",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/198
https://github.com/google/deepvariant/issues/199:244,availability,down,downloaded,244,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:298,availability,error,error,298,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:268,deployability,fail,fails,268,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:394,deployability,contain,container,394,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:2095,deployability,modul,module,2095," inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:2194,interoperability,platform,platform,2194,"ader type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.config.ws_config, self.ref_reader, reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_googl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:2095,modifiability,modul,module,2095," inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:2167,modifiability,pac,packages,2167,"cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.config.ws_config, self.ref_reader, reads, region). File ""/tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:298,performance,error,error,298,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:53,reliability,doe,does,53,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:268,reliability,fail,fails,268,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:22,safety,test,tests,22,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:71,safety,test,test,71,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:128,safety,Test,Tests,128,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:298,safety,error,error,298,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:415,safety,input,input,415,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:435,safety,test,testdata,435,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:494,safety,input,input,494,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:543,safety,input,input,543,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:966,safety,test,testdata,966,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1099,safety,input,inputs,1099," source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1304,safety,test,testdata,1304,"ealign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1886,safety,test,testdata,1886,"7:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:2095,safety,modul,module,2095," inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:3796,safety,valid,valid,3796,"pvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.config.ws_config, self.ref_reader, reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 232, in select_windows. candidates = _candidates_from_reads(config, ref_reader, reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 84, in _candidates_from_reads. region, expanded_region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 152, in _allele_count_linear_selector. allele_counter, model_conf)). TypeError: allele_count_linear_candidates_from_allele_counter() argument counter is not valid for ::learning::genomics::deepvariant::AlleleCounter (deepvariant.python.allelecounter.AlleleCounter instance given): expecting deepvariant.python.allelecounter.AlleleCounter instance, got deepvariant.python.allelecounter.AlleleCounter instance. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:22,testability,test,tests,22,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:71,testability,test,test,71,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:128,testability,Test,Tests,128,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:216,testability,simpl,simple,216,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:435,testability,test,testdata,435,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:516,testability,unit,unittest,516,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:966,testability,test,testdata,966,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1304,testability,test,testdata,1304,"ealign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1886,testability,test,testdata,1886,"7:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1948,testability,Trace,Traceback,1948,"./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:216,usability,simpl,simple,216,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:298,usability,error,error,298,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:415,usability,input,input,415,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:494,usability,input,input,494,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:543,usability,input,input,543,"Compiled from source, tests pass but ""make examples"" does not run with test data.; Hi! I compiled from source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:1099,usability,input,inputs,1099," source on Ubuntu 14.4. . Tests pass, including `./bazel-bin/deepvariant/make_examples_test`. However, running as simple `make_examples` with downloaded example data fails with confusing (for me) error in realign script. Same script worked fine when I ran pre-compiled binary from the Docker container 🤷‍♂️. ```. input=""./quickstart-testdata"". ./bazel-bin/deepvariant/make_examples \. --ref=$input/ucsc.hg19.chr20.unittest.fasta \. --reads=$input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --examples examples.tfrecord@1.gz \. --mode calling \. --logging_every_n_candidates 10 \. --realign_reads. ```. ```. ./make_examples_demo.sh . 2019-07-16 17:49:02.877175: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:02.877284 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.117142 139897470359360 make_examples.py:1110] Preparing inputs. 2019-07-16 17:49:03.117644: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.117749 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0716 17:49:03.118745 139897470359360 make_examples.py:1034] Common contigs are [u'chr20']. I0716 17:49:03.120177 139897470359360 make_examples.py:1116] Writing examples to examples.tfrecord-00000-of-00001.gz. 2019-07-16 17:49:03.121118: I third_party/nucleus/io/sam_reader.cc:600] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2019-07-16 17:49:03.124279: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring: . I0716 17:49:03.124422 139897470359360 genomics_reader.py:218] Reading ./quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/199:3808,usability,learn,learning,3808,"pvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/home/nyakovenko/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1225, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1127, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 849, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 889, in region_reads. _, reads = self.realigner.realign_reads(reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 606, in realign_reads. self.config.ws_config, self.ref_reader, reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 232, in select_windows. candidates = _candidates_from_reads(config, ref_reader, reads, region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 84, in _candidates_from_reads. region, expanded_region). File ""/tmp/Bazel.runfiles_yOE450/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 152, in _allele_count_linear_selector. allele_counter, model_conf)). TypeError: allele_count_linear_candidates_from_allele_counter() argument counter is not valid for ::learning::genomics::deepvariant::AlleleCounter (deepvariant.python.allelecounter.AlleleCounter instance given): expecting deepvariant.python.allelecounter.AlleleCounter instance, got deepvariant.python.allelecounter.AlleleCounter instance. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/199
https://github.com/google/deepvariant/issues/200:16,testability,plan,plants,16,Is it useful to plants？; Is it useful to plants？Such as wheat,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/200:41,testability,plan,plants,41,Is it useful to plants？; Is it useful to plants？Such as wheat,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/200
https://github.com/google/deepvariant/issues/201:80,availability,down,downloaded,80,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:672,energy efficiency,model,model,672,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:702,integrability,pub,publication,702,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:396,interoperability,Specif,Specifically,396,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:0,modifiability,Pac,PacBio,0,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:55,modifiability,Pac,PacBio,55,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:366,modifiability,pac,pacbio-ccs-with-deepvariant,366,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:672,security,model,model,672,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/201:108,testability,trace,trace,108,"PacBio evaluation; I ran an eval on chr20 of HG002 for PacBio CCS Sequel 2 data downloaded from https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/. The results are different from that given in the following blog:. https://google.github.io/deepvariant/posts/2019-01-14-highly-accurate-snp-and-indel-calling-on-pacbio-ccs-with-deepvariant/. Specifically, the indel results are improved by ~4% (F1 is 0.982) and SNV results are largely unchanged. I wonder what is the reason for the difference in the results. Are the two datasets (the one I mentioned, and the one in the blog) the same? If they are the same, has the model been improved since the publication of the blog?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/201
https://github.com/google/deepvariant/issues/202:2042,integrability,event,event,2042,"Chrom_6 5425539 . A C 17.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:96:44,52:0.541667:17,0,47. Chrom_6 5425544 . TA T 37.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:37:94:45,48:0.510638:37,0,52. ```. Sample 2 . ```. Chrom_6 5425208 . C T 44.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2141,integrability,event,event,2141,"544 . TA T 37.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:37:94:45,48:0.510638:37,0,52. ```. Sample 2 . ```. Chrom_6 5425208 . C T 44.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,99",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2295,integrability,event,events,2295,"44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	.	G	A,<*>	30.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:30:106:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2370,integrability,event,event,2370,"F:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	.	G	A,<*>	30.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:30:106:46,56,0:0.528302,0:30,0,65,990,990,990. ```. Sample 2:. ```. Chrom_6	542534",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2342,performance,parallel,parallel,2342," A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	.	G	A,<*>	30.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:30:106:46,56,0:0.528302,0:30,0,65,990,990,990. ```. Sam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2314,security,ident,identical,2314,"4,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	.	G	A,<*>	30.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:30:106:46,56,0:0.528302,0:30",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2243,testability,simpl,simple,2243,"_6 5425208 . C T 44.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2278,testability,understand,understand,2278,":AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	.	G	A,<*>	30.4	PASS	.	GT:GQ:DP:AD:VAF",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2466,testability,coverag,coverage,2466,"/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	.	G	A,<*>	30.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:30:106:46,56,0:0.528302,0:30,0,65,990,990,990. ```. Sample 2:. ```. Chrom_6	5425342	.	A	T,<*>	3	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:3:49:34,15,0:0.306122,0:0,0,41,990,990,990. Chrom_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:46,usability,behavi,behaviour,46,"Same site, different calls (non deterministic behaviour?); Hello! . I am comparing 2 vcf files of 2 different samples. I noticed that deepvariant had a tendency, for the same site and the same genomic variant, present in the 2 samples (as visually checked by looking at the bam alignment) to call the site differently for each sample. . Here is what I mean, the site of interest is highlighted with ** . Sample1: . ```. Chrom_6 5425277 . G A 47.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:48:101:45,54:0.534653:47,0,68. Chrom_6 5425341 . T C 15.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:105:51,53:0.504762:15,0,54. Chrom_6 5425342 . A T 34.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:104:50,53:0.509615:34,0,150. Chrom_6 5425399 . TGG T 33.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:108:47,58:0.537037:33,0,61. Chrom_6 **5425403** . T TTC 36.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:105:47,57:0.542857:36,0,61. Chrom_6 5425421 . T C 39.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:39:105:46,59:0.561905:39,0,62. Chrom_6 5425460 . G A 30.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:106:46,56:0.528302:30,0,65. Chrom_6 5425539 . A C 17.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:96:44,52:0.541667:17,0,47. Chrom_6 5425544 . TA T 37.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:37:94:45,48:0.510638:37,0,52. ```. Sample 2 . ```. Chrom_6 5425208 . C T 44.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:239,usability,visual,visually,239,"Same site, different calls (non deterministic behaviour?); Hello! . I am comparing 2 vcf files of 2 different samples. I noticed that deepvariant had a tendency, for the same site and the same genomic variant, present in the 2 samples (as visually checked by looking at the bam alignment) to call the site differently for each sample. . Here is what I mean, the site of interest is highlighted with ** . Sample1: . ```. Chrom_6 5425277 . G A 47.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:48:101:45,54:0.534653:47,0,68. Chrom_6 5425341 . T C 15.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:105:51,53:0.504762:15,0,54. Chrom_6 5425342 . A T 34.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:104:50,53:0.509615:34,0,150. Chrom_6 5425399 . TGG T 33.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:108:47,58:0.537037:33,0,61. Chrom_6 **5425403** . T TTC 36.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:105:47,57:0.542857:36,0,61. Chrom_6 5425421 . T C 39.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:39:105:46,59:0.561905:39,0,62. Chrom_6 5425460 . G A 30.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:106:46,56:0.528302:30,0,65. Chrom_6 5425539 . A C 17.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:96:44,52:0.541667:17,0,47. Chrom_6 5425544 . TA T 37.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:37:94:45,48:0.510638:37,0,52. ```. Sample 2 . ```. Chrom_6 5425208 . C T 44.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/202:2243,usability,simpl,simple,2243,"_6 5425208 . C T 44.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:44:42:22,20:0.47619:44,0,56. Chrom_6 5425277 . G A 32 PASS . GT:GQ:DP:AD:VAF:PL 0/1:32:45:28,17:0.377778:31,0,57. Chrom_6 **5425401** . G T 30.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:60:46,14:0.233333:30,0,50. Chrom_6 **5425402** . G T 18.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:59:46,13:0.220339:18,0,47. Chrom_6 **5425403** . T C 13.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:14:59:46,13:0.220339:13,0,45. Chrom_6 5425421 . T C 6.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:63:50,13:0.206349:5,0,40. Chrom_6 5425460 . G A 8.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:8:61:48,12:0.196721:7,0,40. Chrom_6 5425539 . A C 14.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:15:45:36,9:0.2:14,0,45. Chrom_6 5425555 . G A 20.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:34,10:0.227273:20,0,50. ```. As you see, the event which is a change of 3 consecutive nucleotides, is called in one sample as a single T to TTC event and in the other sample as 3 SNPs. . This is annoying if one wants to compare the 2 samples, as simple comparison scripts will not understand those events are in fact identical. . We ran GATK in parallel and GATK calls the event in both sample as T to TTC. . The only difference between the 2 samples is the sequencing coverage which is higher in Sample1. . I also looked into the gVCF and the same phenomenom happens. Sample 1:. ```. Chrom_6	5425343	.	G	<*>	0	.	END=5425398	GT:GQ:MIN_DP:PL	0/0:50:104:0,300,2999. Chrom_6	5425399	.	TGG	T,<*>	33.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:33:108:47,58,0:0.537037,0:33,0,61,990,990,990. Chrom_6	5425402	.	G	<*>	0	.	END=5425402	GT:GQ:MIN_DP:PL	0/0:50:106:0,180,2759. Chrom_6	**5425403**	.	T	TTC,<*>	36.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:36:105:47,57,0:0.542857,0:36,0,61,990,990,990. Chrom_6	5425404	.	A	<*>	0	.	END=5425420	GT:GQ:MIN_DP:PL	0/0:50:106:0,300,2999. Chrom_6	5425421	.	T	C,<*>	39.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:105:46,59,0:0.561905,0:39,0,62,990,990,990. Chrom_6	5425422	.	C	<*>	0	.	END=5425459	GT:GQ:MIN_DP:PL	0/0:50:105:0,180,2759. Chrom_6	5425460	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/202
https://github.com/google/deepvariant/issues/203:1194,availability,checkpoint,checkpoint-,1194,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1213,availability,checkpoint,checkpoint-,1213,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1487,availability,checkpoint,checkpoint-,1487,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:68,energy efficiency,model,model,68,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1183,energy efficiency,model,model,1183,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:165,integrability,batch,batch,165,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1416,integrability,batch,batch,1416,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1382,modifiability,paramet,parameters,1382,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:165,performance,batch,batch,165,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1416,performance,batch,batch,1416,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1194,reliability,checkpoint,checkpoint-,1194,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1213,reliability,checkpoint,checkpoint-,1213,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1487,reliability,checkpoint,checkpoint-,1487,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:68,security,model,model,68,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:415,security,loss,loss,415,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:805,security,loss,loss,805,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1183,security,model,model,1183,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:9,usability,behavi,behavior,9,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:50,usability,custom,customize,50,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:144,usability,learn,learning,144,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1401,usability,learn,learning,1401,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/203:1537,usability,behavi,behavior,1537,"Abnormal behavior of model_eval; We are trying to customize the WES model to call variants on RNA-Seq reads. . Regardless of how low we set the learning rate or the batch size or saving the intervals, the value of either the values of (TNs/All) and (FNs/All) is set to 0. or the values of (TPs/All) and (FPs/All) is set to zero. . I am not sure I clarified the case enough so here is a sample of the first case:. {'loss': 1.9104841, 'global_step': 0, 'TNs/All': 0.0, 'FNs/All': 0.0, 'F1/Class2': 0.0, 'Recall/Class1': 1.0, 'Recall/All': 1.0, 'Precision/All': 0.49536133, 'Precision/Class2': 0.0, 'Precision/Class1': 0.18457031, 'Accuracy/All': 0.18457031, 'F1/All': 0.6625306, 'FPs/All': 2067.0, 'Recall/Class2': 0.0, 'TPs/All': 2029.0, 'F1/Class1': 0.31162408}. Here is an example of the second case . {'loss': 1.0544469, 'global_step': 3252, 'TNs/All': 2067.0, 'FNs/All': 2029.0, 'F1/Class2': 0.0, 'Recall/Class1': 0.0, 'Recall/All': 0.0, 'Precision/All': 0.0, 'Precision/Class2': 0.0, 'Precision/Class1': 0.0, 'Accuracy/All': 0.5046387, 'F1/All': 0.0, 'FPs/All': 0.0, 'Recall/Class2': 0.0, 'TPs/All': 0.0, 'F1/Class1': 0.0}. One experiment the first case was the case for all the model from checkpoint-0 until checkpoint-1779 then the second case suddenly appeared till the end of the evaluation. We run shorter experiments and as I mentioned before, no matter how we change the parameters for the learning rate, batch size, or saving the interval, one of the two cases appears since checkpoint-0. Can you guess any reason for such a behavior?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/203
https://github.com/google/deepvariant/issues/204:128,deployability,releas,release,128,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:21,energy efficiency,model,model,21,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:136,energy efficiency,model,models,136,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:272,energy efficiency,model,model,272,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:195,integrability,pub,published,195,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:101,performance,network,networks,101,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:21,security,model,model,21,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:101,security,network,networks,101,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:136,security,model,models,136,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:272,security,model,model,272,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/204:120,testability,plan,plan,120,"Adding the non human model?; Hello,. I apologise if my question is naive I am a beginner with neural networks. . Do you plan to release models trained with non-humans? Like the mosquito analysis published on your blog? And would it made sense to have a kind of ""universal model""? . thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/204
https://github.com/google/deepvariant/issues/205:157,usability,tool,tool,157,"Variant Normalization; Hi,. I would like to know Deepvariant do the variant normalization (for example left-align for InDels)?, or I need to it with another tool? Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/205
https://github.com/google/deepvariant/issues/206:124,deployability,scale,scaled,124,"How is QUAL calculated?; Hi there! How is the QUAL score calculated when using DeepVariant? E.g., with GATK, it's the phred-scaled posterior probability of a variant being homozygous ref. I've been comparing known true positives detected by both HaplotypeCaller and DeepVariant, and found that DV's QUAL score is approximately correlated with HC's QualByDepth, so I'm wondering whether the QUAL score is already normalized by depth or is calculated in some other way. Thanks! Bari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/206:124,energy efficiency,scale,scaled,124,"How is QUAL calculated?; Hi there! How is the QUAL score calculated when using DeepVariant? E.g., with GATK, it's the phred-scaled posterior probability of a variant being homozygous ref. I've been comparing known true positives detected by both HaplotypeCaller and DeepVariant, and found that DV's QUAL score is approximately correlated with HC's QualByDepth, so I'm wondering whether the QUAL score is already normalized by depth or is calculated in some other way. Thanks! Bari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/206:124,modifiability,scal,scaled,124,"How is QUAL calculated?; Hi there! How is the QUAL score calculated when using DeepVariant? E.g., with GATK, it's the phred-scaled posterior probability of a variant being homozygous ref. I've been comparing known true positives detected by both HaplotypeCaller and DeepVariant, and found that DV's QUAL score is approximately correlated with HC's QualByDepth, so I'm wondering whether the QUAL score is already normalized by depth or is calculated in some other way. Thanks! Bari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/206:124,performance,scale,scaled,124,"How is QUAL calculated?; Hi there! How is the QUAL score calculated when using DeepVariant? E.g., with GATK, it's the phred-scaled posterior probability of a variant being homozygous ref. I've been comparing known true positives detected by both HaplotypeCaller and DeepVariant, and found that DV's QUAL score is approximately correlated with HC's QualByDepth, so I'm wondering whether the QUAL score is already normalized by depth or is calculated in some other way. Thanks! Bari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/206:229,safety,detect,detected,229,"How is QUAL calculated?; Hi there! How is the QUAL score calculated when using DeepVariant? E.g., with GATK, it's the phred-scaled posterior probability of a variant being homozygous ref. I've been comparing known true positives detected by both HaplotypeCaller and DeepVariant, and found that DV's QUAL score is approximately correlated with HC's QualByDepth, so I'm wondering whether the QUAL score is already normalized by depth or is calculated in some other way. Thanks! Bari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/206:229,security,detect,detected,229,"How is QUAL calculated?; Hi there! How is the QUAL score calculated when using DeepVariant? E.g., with GATK, it's the phred-scaled posterior probability of a variant being homozygous ref. I've been comparing known true positives detected by both HaplotypeCaller and DeepVariant, and found that DV's QUAL score is approximately correlated with HC's QualByDepth, so I'm wondering whether the QUAL score is already normalized by depth or is calculated in some other way. Thanks! Bari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/206
https://github.com/google/deepvariant/issues/207:16,availability,error,error,16,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:90,availability,error,error,90,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1887,availability,error,error,1887,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1937,availability,failur,failure,1937,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:45,deployability,stage,stage,45,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:70,deployability,pipelin,pipeline,70,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:115,deployability,stage,stage,115,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:183,deployability,log,log,183,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:485,deployability,Log,Logging,485,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1478,deployability,fail,failed,1478,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1924,deployability,fail,failed,1924,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1937,deployability,fail,failure,1937,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:70,integrability,pipelin,pipeline,70,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1893,integrability,messag,message,1893,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1893,interoperability,messag,message,1893,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:16,performance,error,error,16,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:90,performance,error,error,90,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1459,performance,parallel,parallel,1459,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1887,performance,error,error,1887,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1905,performance,parallel,parallel,1905,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1937,performance,failur,failure,1937,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1478,reliability,fail,failed,1478,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1924,reliability,fail,failed,1924,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1937,reliability,fail,failure,1937,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1945,reliability,doe,doesn,1945,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:16,safety,error,error,16,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:90,safety,error,error,90,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:183,safety,log,log,183,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:277,safety,input,input,277,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:485,safety,Log,Logging,485,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:619,safety,input,input,619,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:792,safety,input,inputs,792,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:883,safety,input,input,883,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1172,safety,input,input,1172,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1696,safety,input,input,1696,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1802,safety,input,input,1802,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1887,safety,error,error,1887,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:7,security,ident,identify,7,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:183,security,log,log,183,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:485,security,Log,Logging,485,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:183,testability,log,log,183,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:485,testability,Log,Logging,485,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:16,usability,error,error,16,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:90,usability,error,error,90,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:132,usability,help,help,132,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:277,usability,input,input,277,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:619,usability,input,input,619,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:792,usability,input,inputs,792,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:883,usability,input,input,883,"Cannot identify error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1172,usability,input,input,1172,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1696,usability,input,input,1696,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1802,usability,input,input,1802,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/207:1887,usability,error,error,1887,"y error cause in make_examples stage; Hi. I'm running a pipeline but get an error on ""make_examples"" stage. Could you help me to debug possible cause, please? Here is a log:. ```. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:51.456603: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . WARNING: Logging before flag parsing goes to stderr. I0814 12:36:53.581777 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:36:54.201131 140158089049856 make_examples.py:1024] Preparing inputs. [W::hts_idx_load2] The index file is older than the data file: /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam.bai. 2019-08-14 12:36:58.286794: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I0814 12:36:59.914532 140158089049856 genomics_reader.py:174] Reading /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam with NativeSamReader. I0814 12:45:36.568115 140158089049856 make_examples.py:946] Common contigs are [u'LKUA01000001.1', u'LKUA01000002.1', ...<ANOTHER 300k NAMES>..., u'LKUA01311038.1', u'LKUA01311039.1']. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --examples /mnt/google/.google/output/cannabis-3k-vcf/staging/SRS1107973_LKUA01/staging/examples/0/examples_output.tfrecord@512.gz --reads /mnt/google/.google/input/cannabis-3k-results/manual/merged_bam/SRS1107973_LKUA01.sorted.merged.bam --ref /mnt/google/.google/input/cannabis-3k/reference/LKUA01/LKUA01.fa --task 8. ```. For me it looks that the error message is `parallel: This job failed:` and failure doesn't relate to the warnings at the beginning of the file? Regards,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/207
https://github.com/google/deepvariant/issues/208:85,deployability,instal,installing,85,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:157,deployability,pipelin,pipeline,157,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:551,deployability,LOG,LOGDIR,551,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:560,deployability,log,log,560,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:573,deployability,LOG,LOGDIR,573,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:37,energy efficiency,current,currently,37,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:368,energy efficiency,core,core,368,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:382,energy efficiency,CPU,CPU,382,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:386,energy efficiency,optim,optimized,386,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:157,integrability,pipelin,pipeline,157,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:346,modifiability,Pac,PacBio,346,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:928,modifiability,variab,variables,928,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:210,performance,perform,performed,210,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:382,performance,CPU,CPU,382,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:386,performance,optimiz,optimized,386,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:481,performance,time,time,481,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:515,performance,parallel,parallel,515,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:1037,performance,parallel,parallel,1037,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:551,safety,LOG,LOGDIR,551,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:560,safety,log,log,560,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:573,safety,LOG,LOGDIR,573,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:637,safety,input,input,637,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:783,safety,input,input,783,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:822,safety,input,input,822,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:551,security,LOG,LOGDIR,551,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:560,security,log,log,560,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:573,security,LOG,LOGDIR,573,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:979,security,ssh,ssh,979,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:337,testability,coverag,coverage,337,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:551,testability,LOG,LOGDIR,551,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:560,testability,log,log,560,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:573,testability,LOG,LOGDIR,573,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:210,usability,perform,performed,210,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:458,usability,command,command,458,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:637,usability,input,input,637,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:783,usability,input,input,783,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:822,usability,input,input,822,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/208:1141,usability,help,help,1141,"make_examples Runtime with CCS; I am currently running DeepVariant on CCS data after installing via Docker on an AWS instance. The make_examples step of the pipeline is taking much longer than expected. I have performed this in the past with 30X Illumina Data, and it has taken a few hours. This has been running for about a week on 23X coverage PacBio HiFi with a 16 core machine (CPU optimized), and I was wondering if that was expected. Below, I have the command issued:. `sudo time seq 0 $((N_SHARDS-1)) | sudo parallel --eta --halt 2 --joblog ""${LOGDIR}""/log --res ""${LOGDIR}"" sudo docker run -v ${HOME}:${HOME} -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/make_examples --mode calling --ref=/input/ucsc.hg38.no_alts.fasta --reads=/input/hg00733_ccs_to_hg38.bam --examples ""${OUTPUT_DIR}/examples.tfrecord@${N_SHARDS}.gz"" --task {}`. All variables listed have been set as expected. When I ssh in to the node I can see that it is running python in parallel and writing to the proper output files, but it is just taking forever to process anything. Any help would be greatly appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/208
https://github.com/google/deepvariant/issues/209:1305,energy efficiency,optim,optimal,1305,"f vcfeval but after submitting the case to the RTG guys, they ran a little analysis that concluded that . > $ rtg extract vcfeval.out/output.vcf.gz. > Chrom_2 6000819 . G GACA . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000820 . A . . . CALL=IGN GT . 0/0. > Chrom_2 6000828 . G A . . SYNC=6000819,6000828;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000829 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > Chrom_2 6000831 . GA G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000833 . C . . . CALL=IGN GT . 0/0. > Chrom_2 6000834 . GCC G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000836 . C G . . SYNC=6000819,6000836;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000837 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > . > The --XX debugging options I used let us verify that the resulting baseline and call haplotypes are identical within the region, and enable an experimental annotation to flag variants that were matched on less optimal solutions. The variants at 6000828 and 6000836 are CALL=FP, because vcfeval was able to instead match three call variants at 6000819, 6000831, and 6000834. It's like the call set in this region is the union of two ways to represent the baseline haplotype. I thereafter compared with called made by GATK and Octopus for that location . Here is what Octopus reports, so nothing for the sites 19, 31, 34. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	chaos. Chrom_2	6000828	.	G	A	1609.23	PASS	AC=1;AN=2;DP=51;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=26.99	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:51:60:6000828:100:26.99:PASS. Chrom_2	6000836	.	C	G	1609.23	PASS	AC=1;AN=2;DP=53;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=30.51	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:53:60:6000828:100:30.51:PASS. ```. And here is what GATK 4 reports, explicitly reporting no het site for 19, 31, 34. ```. Chrom_2	6000811	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000812	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:329,integrability,sub,submitting,329,"deepvariant calling too many variants? ; Hello, it seems deepvariant is producing ""overcalling"" in some regions. . I was using RTG vcfeval to compare different vcf (one vcf = one population )and ended up with a strange case with some variants being both true and false positive. I first thought it was a bug of vcfeval but after submitting the case to the RTG guys, they ran a little analysis that concluded that . > $ rtg extract vcfeval.out/output.vcf.gz. > Chrom_2 6000819 . G GACA . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000820 . A . . . CALL=IGN GT . 0/0. > Chrom_2 6000828 . G A . . SYNC=6000819,6000828;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000829 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > Chrom_2 6000831 . GA G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000833 . C . . . CALL=IGN GT . 0/0. > Chrom_2 6000834 . GCC G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000836 . C G . . SYNC=6000819,6000836;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000837 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > . > The --XX debugging options I used let us verify that the resulting baseline and call haplotypes are identical within the region, and enable an experimental annotation to flag variants that were matched on less optimal solutions. The variants at 6000828 and 6000836 are CALL=FP, because vcfeval was able to instead match three call variants at 6000819, 6000831, and 6000834. It's like the call set in this region is the union of two ways to represent the baseline haplotype. I thereafter compared with called made by GATK and Octopus for that location . Here is what Octopus reports, so nothing for the sites 19, 31, 34. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	chaos. Chrom_2	6000828	.	G	A	1609.23	PASS	AC=1;AN=2;DP=51;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=26.99	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:51:60:6000828:100:26.99:PASS. Chrom_2	6000836	.	C	G	1609.23	PASS	AC=1;AN=2;DP=53;MQ=60;MQ0=0;NS=1;RFQUAL_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1747,integrability,FILTER,FILTER,1747,"31 . GA G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000833 . C . . . CALL=IGN GT . 0/0. > Chrom_2 6000834 . GCC G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000836 . C G . . SYNC=6000819,6000836;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000837 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > . > The --XX debugging options I used let us verify that the resulting baseline and call haplotypes are identical within the region, and enable an experimental annotation to flag variants that were matched on less optimal solutions. The variants at 6000828 and 6000836 are CALL=FP, because vcfeval was able to instead match three call variants at 6000819, 6000831, and 6000834. It's like the call set in this region is the union of two ways to represent the baseline haplotype. I thereafter compared with called made by GATK and Octopus for that location . Here is what Octopus reports, so nothing for the sites 19, 31, 34. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	chaos. Chrom_2	6000828	.	G	A	1609.23	PASS	AC=1;AN=2;DP=51;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=26.99	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:51:60:6000828:100:26.99:PASS. Chrom_2	6000836	.	C	G	1609.23	PASS	AC=1;AN=2;DP=53;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=30.51	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:53:60:6000828:100:30.51:PASS. ```. And here is what GATK 4 reports, explicitly reporting no het site for 19, 31, 34. ```. Chrom_2	6000811	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000812	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000813	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000814	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000815	.	A	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000816	.	G	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000817	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000818	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. **Chrom_2	6000819**	.	G	.	156.54	.	DP=49	GT:A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1759,interoperability,FORMAT,FORMAT,1759,". SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000833 . C . . . CALL=IGN GT . 0/0. > Chrom_2 6000834 . GCC G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000836 . C G . . SYNC=6000819,6000836;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000837 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > . > The --XX debugging options I used let us verify that the resulting baseline and call haplotypes are identical within the region, and enable an experimental annotation to flag variants that were matched on less optimal solutions. The variants at 6000828 and 6000836 are CALL=FP, because vcfeval was able to instead match three call variants at 6000819, 6000831, and 6000834. It's like the call set in this region is the union of two ways to represent the baseline haplotype. I thereafter compared with called made by GATK and Octopus for that location . Here is what Octopus reports, so nothing for the sites 19, 31, 34. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	chaos. Chrom_2	6000828	.	G	A	1609.23	PASS	AC=1;AN=2;DP=51;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=26.99	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:51:60:6000828:100:26.99:PASS. Chrom_2	6000836	.	C	G	1609.23	PASS	AC=1;AN=2;DP=53;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=30.51	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:53:60:6000828:100:30.51:PASS. ```. And here is what GATK 4 reports, explicitly reporting no het site for 19, 31, 34. ```. Chrom_2	6000811	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000812	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000813	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000814	.	T	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000815	.	A	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000816	.	G	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000817	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. Chrom_2	6000818	.	C	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0:49,0:49:118. **Chrom_2	6000819**	.	G	.	156.54	.	DP=49	GT:AD:DP:RGQ	0/0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1195,security,ident,identical,1195," up with a strange case with some variants being both true and false positive. I first thought it was a bug of vcfeval but after submitting the case to the RTG guys, they ran a little analysis that concluded that . > $ rtg extract vcfeval.out/output.vcf.gz. > Chrom_2 6000819 . G GACA . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000820 . A . . . CALL=IGN GT . 0/0. > Chrom_2 6000828 . G A . . SYNC=6000819,6000828;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000829 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > Chrom_2 6000831 . GA G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000833 . C . . . CALL=IGN GT . 0/0. > Chrom_2 6000834 . GCC G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000836 . C G . . SYNC=6000819,6000836;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000837 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > . > The --XX debugging options I used let us verify that the resulting baseline and call haplotypes are identical within the region, and enable an experimental annotation to flag variants that were matched on less optimal solutions. The variants at 6000828 and 6000836 are CALL=FP, because vcfeval was able to instead match three call variants at 6000819, 6000831, and 6000834. It's like the call set in this region is the union of two ways to represent the baseline haplotype. I thereafter compared with called made by GATK and Octopus for that location . Here is what Octopus reports, so nothing for the sites 19, 31, 34. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	chaos. Chrom_2	6000828	.	G	A	1609.23	PASS	AC=1;AN=2;DP=51;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=26.99	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:51:60:6000828:100:26.99:PASS. Chrom_2	6000836	.	C	G	1609.23	PASS	AC=1;AN=2;DP=53;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=30.51	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:53:60:6000828:100:30.51:PASS. ```. And here is what GATK 4 reports, explicitly reporting no het site for 19, 31, 34. ```. Chrom_2	6000811	.	C	.	156.54	.	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/209:1136,testability,verif,verify,1136,"to compare different vcf (one vcf = one population )and ended up with a strange case with some variants being both true and false positive. I first thought it was a bug of vcfeval but after submitting the case to the RTG guys, they ran a little analysis that concluded that . > $ rtg extract vcfeval.out/output.vcf.gz. > Chrom_2 6000819 . G GACA . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000820 . A . . . CALL=IGN GT . 0/0. > Chrom_2 6000828 . G A . . SYNC=6000819,6000828;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000829 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > Chrom_2 6000831 . GA G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000833 . C . . . CALL=IGN GT . 0/0. > Chrom_2 6000834 . GCC G . . SYNC=6000819;CALL_WEIGHT=0.667;CALL=TP GT . 0/1. > Chrom_2 6000836 . C G . . SYNC=6000819,6000836;BASE=TP;CALL=FP;CALL_ALTERNATE GT 0/1 0/1. > Chrom_2 6000837 . A . . . BASE=IGN;CALL=IGN GT 0/0 0/0. > . > The --XX debugging options I used let us verify that the resulting baseline and call haplotypes are identical within the region, and enable an experimental annotation to flag variants that were matched on less optimal solutions. The variants at 6000828 and 6000836 are CALL=FP, because vcfeval was able to instead match three call variants at 6000819, 6000831, and 6000834. It's like the call set in this region is the union of two ways to represent the baseline haplotype. I thereafter compared with called made by GATK and Octopus for that location . Here is what Octopus reports, so nothing for the sites 19, 31, 34. ```. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	chaos. Chrom_2	6000828	.	G	A	1609.23	PASS	AC=1;AN=2;DP=51;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=26.99	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:51:60:6000828:100:26.99:PASS. Chrom_2	6000836	.	C	G	1609.23	PASS	AC=1;AN=2;DP=53;MQ=60;MQ0=0;NS=1;RFQUAL_ALL=30.51	GT:GQ:DP:MQ:PS:PQ:RFQUAL:FT	1|0:1609:53:60:6000828:100:30.51:PASS. ```. And here is what GATK 4 reports, explicitly reporting no ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/209
https://github.com/google/deepvariant/issues/210:1278,availability,servic,service-account-scopes,1278,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1198,deployability,pipelin,pipeline,1198,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1230,deployability,pipelin,pipelines,1230,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1278,deployability,servic,service-account-scopes,1278,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1355,deployability,log,logging,1355,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1439,deployability,log,log,1439,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1506,deployability,pipelin,pipelines,1506,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1573,deployability,log,logs,1573,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1655,deployability,fail,failed,1655,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1807,deployability,fail,failed,1807,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:23,energy efficiency,Model,Model,23,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:71,energy efficiency,MODEL,MODEL,71,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:94,energy efficiency,model,models,94,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:572,energy efficiency,model,model,572,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:580,energy efficiency,MODEL,MODEL,580,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1334,energy efficiency,cloud,cloud-platform,1334,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1491,energy efficiency,cloud,cloud-genomics-pipelines,1491,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:746,integrability,pub,public-data,746,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1198,integrability,pipelin,pipeline,1198,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1230,integrability,pipelin,pipelines,1230,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1278,integrability,servic,service-account-scopes,1278,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1506,integrability,pipelin,pipelines,1506,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1340,interoperability,platform,platform,1340,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1278,modifiability,servic,service-account-scopes,1278,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1636,performance,parallel,parallel,1636,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1788,performance,parallel,parallel,1788,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1655,reliability,fail,failed,1655,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1807,reliability,fail,failed,1807,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1355,safety,log,logging,1355,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1439,safety,log,log,1439,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1573,safety,log,logs,1573,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1675,safety,input,input-gcsfused-,1675,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1731,safety,input,input-gcsfused-,1731,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1827,safety,input,input-gcsfused-,1827,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1883,safety,input,input-gcsfused-,1883,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:23,security,Model,Model,23,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:71,security,MODEL,MODEL,71,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:94,security,model,models,94,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:572,security,model,model,572,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:580,security,MODEL,MODEL,580,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1329,security,auth,auth,1329,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1355,security,log,logging,1355,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1439,security,log,log,1439,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1544,security,command-lin,command-line,1544,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1573,security,log,logs,1573,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1355,testability,log,logging,1355,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1439,testability,log,log,1439,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1573,testability,log,logs,1573,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:261,usability,COMMAND,COMMAND,261,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1544,usability,command,command-line,1544,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1560,usability,COMMAND,COMMAND,1560,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1617,usability,command,command,1617,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1675,usability,input,input-gcsfused-,1675,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1731,usability,input,input-gcsfused-,1731,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1769,usability,command,command,1769,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1827,usability,input,input-gcsfused-,1827,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1883,usability,input,input-gcsfused-,1883,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/210:1921,usability,command,command,1921,"cant find gcsfuse; . # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_gVCF_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bam \. --bai gs://files_jays/bam/bqsr.realign.markdup.sorted.merged.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --preemptible \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". # logs on one of the VMs. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-0 && gcsfuse --implicit-dirs files_jays /input-gcsfused-0. /bin/bash: gcsfuse: command not found. parallel: This job failed:. mkdir -p ./input-gcsfused-1 && gcsfuse --implicit-dirs files_jays /input-gcsfused-1. /bin/bash: gcsfuse: command not found.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/210
https://github.com/google/deepvariant/issues/211:47,deployability,instal,installed,47,Deep variant and Cancer exome; Hi . I recently installed docker version of deep variant for cancer exome analysis. I like to know if I don't use paired cancer samples for variant calling with deep variant will it be right approach,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/211
https://github.com/google/deepvariant/issues/211:64,deployability,version,version,64,Deep variant and Cancer exome; Hi . I recently installed docker version of deep variant for cancer exome analysis. I like to know if I don't use paired cancer samples for variant calling with deep variant will it be right approach,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/211
https://github.com/google/deepvariant/issues/211:64,integrability,version,version,64,Deep variant and Cancer exome; Hi . I recently installed docker version of deep variant for cancer exome analysis. I like to know if I don't use paired cancer samples for variant calling with deep variant will it be right approach,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/211
https://github.com/google/deepvariant/issues/211:64,modifiability,version,version,64,Deep variant and Cancer exome; Hi . I recently installed docker version of deep variant for cancer exome analysis. I like to know if I don't use paired cancer samples for variant calling with deep variant will it be right approach,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/211
https://github.com/google/deepvariant/issues/212:0,energy efficiency,CPU,CPU,0,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:132,energy efficiency,CPU,CPU,132,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:191,energy efficiency,CPU,CPU,191,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:29,modifiability,Extens,Extensions,29,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:0,performance,CPU,CPU,0,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:132,performance,CPU,CPU,132,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/212:191,performance,CPU,CPU,191,"CPU with SSE (Streaming SIMD Extensions) instruction; HI,. In spite of great interest, desecrated to use DeepVariant because of the CPU issue. I found to have a machine with Intel(R) Xeon(R) CPU E7- 8870 @ 2.40GHz processors. As I found on the company webpage it is not an AVX -rather to be SSE- processor. Is there any way/trick to use DeepVariant on such machine? Thank you in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/212
https://github.com/google/deepvariant/issues/213:557,reliability,doe,does,557,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1127,safety,input,input,1127,"nments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your pati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1617,safety,compl,complete,1617,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1617,security,compl,complete,1617,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:529,testability,understand,understand,529,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1860,testability,understand,understanding,1860,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:278,usability,indicat,indicates,278,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:410,usability,support,support,410,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:638,usability,support,support,638,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:745,usability,support,support,745,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:873,usability,confirm,confirm,873,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:924,usability,support,support,924,"Regarding treating ambiguous/partially overlapping read alignments; I have two questions. . The first is about ambiguous read alignments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect del",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1127,usability,input,input,1127,"nments. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your pati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1271,usability,support,supports,1271,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1592,usability,indicat,indicate,1592,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1601,usability,support,support,1601,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1698,usability,support,supporting,1698,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/213:1734,usability,support,support,1734,"s. This can happen, for example, in a region of homopolymer repeats (or other short repeats). ACTGTACTAC**X**GGGGGGAT (Reference sequence: ""X"" indicates an inserted base). ACTGTACTACGGGGGGGAT (Read0). ACTGTACTACGGG (Read1). In this case, Read1 could be interpreted to either support the insertion or not. BWA would choose to ignore the insertion, since it would be penalized in SW alignment. I understand that DeepVariant does internal realignment of reads. However, even after realignment, Read1 would support one or the other allele (reference/insertion) exclusively. In reality, we cannot attribute Read1's support to either allele exclusively (prior to variant calling) because we do not have sufficient information. Could you please confirm that in these cases DeepVariant counts the support from the ambiguous read (Read1 in this case) for only one of the alleles, and not both? I am not speaking about the CNN itself, but the algorithms in DeepVariant up until the construction of the input feature maps for the CNN. The second question I have is regarding reads which partially overlap alleles. In allelecounter.cc, I find that supports for alleles are determined based on their cigar strings. However, for insertion alleles that are, say 30-50 bp long, there may be a plurality of reads which partially overlap with the non-reference allele, because a read terminates or starts its alignment within the allele. In these cases, cigar strings do not indicate support for the complete allele, but only for a part of it. Are these reads considered to be non-supporting? If, instead of counting support from cigar strings, the original contigs in the local reassembly were used, such problems wouldn't arise. However, my understanding of allelecounter.cc code is that such information is not used. Also, I believe this problem, if it exists, wouldn't affect deletions, because the partial overlap would then be with the reference allele. Please correct me if I am wrong. Thanks for your patience.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/213
https://github.com/google/deepvariant/issues/214:227,availability,recov,recover,227,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:286,availability,recov,recover,286,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1451,availability,servic,service-account-scopes,1451,"0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1772,availability,error,error,1772,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:130,deployability,fail,fails,130,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:227,deployability,recov,recover,227,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:286,deployability,recov,recover,286,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1371,deployability,pipelin,pipeline,1371,"dels/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1403,deployability,pipelin,pipelines,1403,"t-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1451,deployability,servic,service-account-scopes,1451,"0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1528,deployability,log,logging,1528,"SION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1612,deployability,log,log,1612,"{PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1683,deployability,pipelin,pipelines,1683,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2163,deployability,fail,fail,2163,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:302,energy efficiency,Model,Model,302,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:350,energy efficiency,MODEL,MODEL,350,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:373,energy efficiency,model,models,373,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:850,energy efficiency,model,model,850,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:858,energy efficiency,MODEL,MODEL,858,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1507,energy efficiency,cloud,cloud-platform,1507,"riant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1668,energy efficiency,cloud,cloud-genomics-pipelines,1668,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1371,integrability,pipelin,pipeline,1371,"dels/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1403,integrability,pipelin,pipelines,1403,"t-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1451,integrability,servic,service-account-scopes,1451,"0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1683,integrability,pipelin,pipelines,1683,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1513,interoperability,platform,platform,1513,"nt:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --tas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1451,modifiability,servic,service-account-scopes,1451,"0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1772,performance,error,error,1772,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1809,performance,time,timeout,1809,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1886,performance,parallel,parallel,1886,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2058,performance,parallel,parallel,2058,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2149,performance,time,timeout,2149,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2170,performance,Time,Time,2170,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2312,performance,parallel,parallel,2312,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:130,reliability,fail,fails,130,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:227,reliability,recov,recover,227,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:286,reliability,recov,recover,286,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2163,reliability,fail,fail,2163,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:227,safety,recov,recover,227,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:286,safety,recov,recover,286,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1528,safety,log,logging,1528,"SION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1612,safety,log,log,1612,"{PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1772,safety,error,error,1772,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1809,safety,timeout,timeout,1809,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1917,safety,input,input-gcsfused,1917,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1981,safety,input,input-gcsfused,1981,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2099,safety,input,input-gcsfused,2099,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2121,safety,test,test,2121,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2149,safety,timeout,timeout,2149,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2462,safety,input,input-gcsfused,2462,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:227,security,recov,recover,227,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:286,security,recov,recover,286,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:302,security,Model,Model,302,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:350,security,MODEL,MODEL,350,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:373,security,model,models,373,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:850,security,model,model,850,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:858,security,MODEL,MODEL,858,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1502,security,auth,auth,1502,"ker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1528,security,log,logging,1528,"SION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1612,security,log,log,1612,"{PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1721,security,command-lin,command-line,1721,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2652,security,ident,identify,2652,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1528,testability,log,logging,1528,"SION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1612,testability,log,log,1612,"{PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2121,testability,test,test,2121,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:5,usability,statu,status,5,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:32,usability,command,command,32,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:540,usability,COMMAND,COMMAND,540,"exit status 127: bash: gcsfuse: command not found; Hi, . I am trying to run the following:. #!/bin/bash. #set -euo pipefail <- it fails if I use this! # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/recover. STAGING_FOLDER_NAME=recover_tmp. OUTPUT_FILE_NAME=recover.gvcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1721,usability,command,command-line,1721,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1737,usability,COMMAND,COMMAND,1737,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1772,usability,error,error,1772,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1789,usability,Stop,Stopped,1789,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1917,usability,input,input-gcsfused,1917,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:1981,usability,input,input-gcsfused,1981,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2099,usability,input,input-gcsfused,2099,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2462,usability,input,input-gcsfused,2462,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2588,usability,statu,status,2588,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:2615,usability,command,command,2615,"IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --gvcf_outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --shards 512 \. --make_examples_workers 32 \. --make_examples_cores_per_worker 16 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 32 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --postprocess_variants_disk_gb 200 \. --gcsfuse "". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions europe-west1 \. --docker-image gcr.io/cloud-genomics-pipelines/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". And i get the following error:. 07:03:22 Stopped running ""-c timeout=10; elapsed=0; seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""mkdir -p ./input-gcsfused-{} && gcsfuse --implicit-dirs \""${GCS_BUCKET}\"" /input-gcsfused-{}\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""until mountpoint -q /input-gcsfused-{}; do test \""${elapsed}\"" -lt \""${timeout}\"" || fail \""Time out waiting for gcsfuse mount points\""; sleep 1; elapsed=$((elapsed+1)); done\"" && seq \""${SHARD_START_INDEX}\"" \""${SHARD_END_INDEX}\"" | parallel --halt 2 \""/opt/deepvariant/bin/make_examples --mode calling --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --reads \""/input-gcsfused-{}/${BAM}\"" --ref \""${INPUT_REF}\"" --task {} --gvcf \""${GVCF}\""/gvcf_output.tfrecord@\""${SHARDS}\"".gz\"""": exit status 127: bash: gcsfuse: command not found. Is it possible to identify the problem/typo? .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/pull/215:8,deployability,updat,updates,8,DV blog updates; Note: this pull request is from the DeepVariant team,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/215
https://github.com/google/deepvariant/pull/215:8,safety,updat,updates,8,DV blog updates; Note: this pull request is from the DeepVariant team,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/215
https://github.com/google/deepvariant/pull/215:8,security,updat,updates,8,DV blog updates; Note: this pull request is from the DeepVariant team,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/215
https://github.com/google/deepvariant/pull/215:65,security,team,team,65,DV blog updates; Note: this pull request is from the DeepVariant team,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/215
https://github.com/google/deepvariant/pull/216:124,deployability,updat,update,124,"Adding new blog post.; We are not taking pull requests at this time. (Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by @pichuan , a DeepVariant team member.)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/216
https://github.com/google/deepvariant/pull/216:169,integrability,sub,submitted,169,"Adding new blog post.; We are not taking pull requests at this time. (Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by @pichuan , a DeepVariant team member.)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/216
https://github.com/google/deepvariant/pull/216:63,performance,time,time,63,"Adding new blog post.; We are not taking pull requests at this time. (Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by @pichuan , a DeepVariant team member.)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/216
https://github.com/google/deepvariant/pull/216:124,safety,updat,update,124,"Adding new blog post.; We are not taking pull requests at this time. (Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by @pichuan , a DeepVariant team member.)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/216
https://github.com/google/deepvariant/pull/216:124,security,updat,update,124,"Adding new blog post.; We are not taking pull requests at this time. (Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by @pichuan , a DeepVariant team member.)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/216
https://github.com/google/deepvariant/pull/216:207,security,team,team,207,"Adding new blog post.; We are not taking pull requests at this time. (Note: this PR is on the gh-pages branch, meant for an update for the goo.gl/deepvariant blog. It's submitted by @pichuan , a DeepVariant team member.)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/216
https://github.com/google/deepvariant/issues/217:78,availability,avail,available,78,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:330,availability,down,downloading,330,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:865,availability,error,error,865,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1430,availability,avail,available,1430,"input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:306,deployability,instal,install,306,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1599,deployability,modul,module,1599," --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2619,deployability,FAIL,FAILED,2619,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2665,deployability,instal,install,2665,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1313,energy efficiency,core,core,1313,"he tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:945,integrability,buffer,buffer,945,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1895,integrability,sub,subprocess,1895,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1988,integrability,sub,subprocess,1988,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2069,integrability,sub,subprocess,2069,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2143,integrability,buffer,buffer,2143,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1318,interoperability,platform,platform,1318,". After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1599,modifiability,modul,module,1599," --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1659,modifiability,pac,packages,1659,"put/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1759,modifiability,pac,packages,1759,"utput/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:865,performance,error,error,865,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:911,performance,time,time,911,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:926,performance,parallel,parallel,926,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2109,performance,time,time,2109,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2124,performance,parallel,parallel,2124,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:78,reliability,availab,available,78,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1430,reliability,availab,available,1430,"input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2619,reliability,FAIL,FAILED,2619,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:78,safety,avail,available,78,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:435,safety,input,input,435,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:610,safety,input,input,610,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:661,safety,input,input,661,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:865,safety,error,error,865,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1010,safety,input,input,1010,"w library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1058,safety,input,input,1058,"but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1430,safety,avail,available,1430,"input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1599,safety,modul,module,1599," --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2208,safety,input,input,2208,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2256,safety,input,input,2256,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:78,security,availab,available,78,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1430,security,availab,available,1430,"input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:632,testability,unit,unittest,632,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1032,testability,unit,unittest,1032,"to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1501,testability,Trace,Traceback,1501,"eepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2230,testability,unit,unittest,2230,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:318,usability,tool,tool,318,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:379,usability,command,command,379,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:435,usability,input,input,435,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:610,usability,input,input,610,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:661,usability,input,input,661,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:865,usability,error,error,865,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:896,usability,command,command,896,"The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1010,usability,input,input,1010,"w library was compiled to use AVX instructions, but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1058,usability,input,input,1058,"but these aren't available on your machine; Dear Developer,. I am going to use DeepVariant for variant calling. I have followed the instruction provided [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), to install the tool. After downloading the all needed sample data I run the command:. ```. sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1472,usability,user,user,1472,"\. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/input/ucsc.hg19.chr20.unittest.fasta \. > --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' retu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:1917,usability,command,command,1917,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2100,usability,Command,Command,2100,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2208,usability,input,input,2208,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2256,usability,input,input,2256,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2493,usability,statu,status,2493,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:2743,usability,user,users,2743,"hards=1 . ```. I faced the error:. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. 2019-09-11 14:44:44.030589: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m2.456s. user	0m1.443s. sys	0m1.926s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. I googled for solution also asked you before and found may be compiling from source code would works for me. I FAILED TO DO THIS. Is still any chance to use install and work with DeepVariant? Please consider that a number of potential users -like me- are biologist with limited knowledge of informatics. . Thanks in advance. Hamid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/pull/218:98,deployability,updat,update,98,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:81,performance,time,time,81,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:98,safety,updat,update,98,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:5,security,auth,author,5,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:98,security,updat,update,98,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:145,security,team,team,145,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:184,security,auth,author,184,Show author images in blog posts; (Note: We are not taking pull requests at this time. This is an update to the blog from within the DeepVariant team.). This adds a system for showing author images at the top of blog posts.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/issues/219:2945,availability,consist,consisting,2945,"s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 11",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:829,deployability,modul,module,829,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2080,deployability,modul,module,2080," main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3507,deployability,Fail,Failed,3507,"raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3702,deployability,modul,module,3702,"иссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4959,deployability,modul,module,4959,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:436,integrability,buffer,buffer,436,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2376,integrability,sub,subprocess,2376,"deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/ho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2469,integrability,sub,subprocess,2469," self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2550,integrability,sub,subprocess,2550,"iles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2624,integrability,buffer,buffer,2624," _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3278,integrability,buffer,buffer,3278,"main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nuc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5255,integrability,sub,subprocess,5255,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5348,integrability,sub,subprocess,5348,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5429,integrability,sub,subprocess,5429,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5503,integrability,buffer,buffer,5503,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:915,interoperability,platform,platform,915,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3788,interoperability,platform,platform,3788,"examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /ho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:829,modifiability,modul,module,829,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:888,modifiability,pac,packages,888,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:1878,modifiability,deco,decode,1878,"7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2080,modifiability,modul,module,2080," main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2140,modifiability,pac,packages,2140,"AGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2240,modifiability,pac,packages,2240,", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3702,modifiability,modul,module,3702,"иссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3761,modifiability,pac,packages,3761,"тация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4959,modifiability,modul,module,4959,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5019,modifiability,pac,packages,5019,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5119,modifiability,pac,packages,5119,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:402,performance,time,time,402,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:417,performance,parallel,parallel,417,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2590,performance,time,time,2590,"ty/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2605,performance,parallel,parallel,2605,".py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2929,performance,time,time,2929,"(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3244,performance,time,time,3244,"es/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3259,performance,parallel,parallel,3259,"line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5469,performance,time,time,5469,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5484,performance,parallel,parallel,5484,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:8,reliability,doe,does,8,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3507,reliability,Fail,Failed,3507,"raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:829,safety,modul,module,829,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2080,safety,modul,module,2080," main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3116,safety,test,test,3116,"al/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3150,safety,test,test,3150,"l/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3190,safety,test,test,3190,"ain, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3355,safety,test,test,3355,"line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._nat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3391,safety,test,test,3391,"call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3540,safety,test,test,3540,", cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3702,safety,modul,module,3702,"иссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_qual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4802,safety,test,test,4802,", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4959,safety,modul,module,4959,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5580,safety,test,test,5580,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5616,safety,test,test,5616,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:682,testability,Trace,Traceback,682,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:1982,testability,Trace,Traceback,1982,"zel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3116,testability,test,test,3116,"al/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3150,testability,test,test,3150,"l/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3190,testability,test,test,3190,"ain, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3355,testability,test,test,3355,"line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._nat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3391,testability,test,test,3391,"call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3540,testability,test,test,3540,", cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3555,testability,Trace,Traceback,3555,".CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4802,testability,test,test,4802,", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4861,testability,Trace,Traceback,4861,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5580,testability,test,test,5580,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5616,testability,test,test,5616,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:387,usability,command,command,387,"Calling does not work; Distro: elementary OS 5.0. First attempt to run a calling:. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/_0_Диссертация/Exp/seq1/seq1.fa --reads=/home/platon/_0_Диссертация/Exp/seq1/seq1.bam --output_vcf=/home/platon/_0_Диссертация/Exp/seq1/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:1953,usability,user,user,1953,".exit(main(argv)). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2398,usability,command,command,2398,"ty/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2581,usability,Command,Command,2581,"ird_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_vtX6qv/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 224, in __init__. input_path.encode('utf8'),. UnicodeDecodeError: 'ascii' codec can't decode byte 0xd0 in position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call la",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2893,usability,statu,status,2893,"n position 16: ordinal not in range(128). real	0m1.622s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:2945,usability,consist,consisting,2945,"s. user	0m1.578s. sys	0m0.693s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 11",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:3229,usability,command,command,3229,"7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/_0_Диссертация/Exp/seq1/seq1.fa"" --reads ""/home/platon/_0_Диссертация/Exp/seq1/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Second attempt. This time with paths consisting only of latin characters. `sudo docker run gcr.io/deepvariant-docker/deepvariant:0.8.0 /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/home/platon/test/seq1.fa --reads=/home/platon/test/seq1.bam --output_vcf=/home/platon/test/seq1.vcf`. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}. [E::hts_open_format] Failed to open file /home/platon/test/seq1.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:4832,usability,user,user,4832,"main(argv)). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5277,usability,command,command,5277,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5460,usability,Command,Command,5460,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:5734,usability,statu,status,5734,"azel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_AruJXP/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /home/platon/test/seq1.bam. real	0m1.571s. user	0m1.481s. sys	0m0.786s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/platon/test/seq1.fa"" --reads ""/home/platon/test/seq1.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ```. Source data:. [test_seq_data.tar.gz](https://github.com/google/deepvariant/files/3611565/test_seq_data.tar.gz)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/220:160,modifiability,concern,concerned,160,"De novo variant calling; I am using Deepvariant (v.0.7.2) for germline calling and now I have a trio, for which I need to identify de novo variants. . I am bit concerned, as based on this pre-print, it seems like Deepvariant is extremely bad for de novo variant calling:. https://www.biorxiv.org/content/10.1101/456103v1.full . Are there any recommendations how to better do it ? Or maybe somebody has an experience with that ? . I was thinking of combining gVCFs using GLnexus and then try out GATK genotype refinement and de novo annotating. Thanks ! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:296,performance,content,content,296,"De novo variant calling; I am using Deepvariant (v.0.7.2) for germline calling and now I have a trio, for which I need to identify de novo variants. . I am bit concerned, as based on this pre-print, it seems like Deepvariant is extremely bad for de novo variant calling:. https://www.biorxiv.org/content/10.1101/456103v1.full . Are there any recommendations how to better do it ? Or maybe somebody has an experience with that ? . I was thinking of combining gVCFs using GLnexus and then try out GATK genotype refinement and de novo annotating. Thanks ! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:122,security,ident,identify,122,"De novo variant calling; I am using Deepvariant (v.0.7.2) for germline calling and now I have a trio, for which I need to identify de novo variants. . I am bit concerned, as based on this pre-print, it seems like Deepvariant is extremely bad for de novo variant calling:. https://www.biorxiv.org/content/10.1101/456103v1.full . Are there any recommendations how to better do it ? Or maybe somebody has an experience with that ? . I was thinking of combining gVCFs using GLnexus and then try out GATK genotype refinement and de novo annotating. Thanks ! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:160,testability,concern,concerned,160,"De novo variant calling; I am using Deepvariant (v.0.7.2) for germline calling and now I have a trio, for which I need to identify de novo variants. . I am bit concerned, as based on this pre-print, it seems like Deepvariant is extremely bad for de novo variant calling:. https://www.biorxiv.org/content/10.1101/456103v1.full . Are there any recommendations how to better do it ? Or maybe somebody has an experience with that ? . I was thinking of combining gVCFs using GLnexus and then try out GATK genotype refinement and de novo annotating. Thanks ! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:405,usability,experien,experience,405,"De novo variant calling; I am using Deepvariant (v.0.7.2) for germline calling and now I have a trio, for which I need to identify de novo variants. . I am bit concerned, as based on this pre-print, it seems like Deepvariant is extremely bad for de novo variant calling:. https://www.biorxiv.org/content/10.1101/456103v1.full . Are there any recommendations how to better do it ? Or maybe somebody has an experience with that ? . I was thinking of combining gVCFs using GLnexus and then try out GATK genotype refinement and de novo annotating. Thanks ! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/221:12,availability,error,error,12,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:178,availability,Error,Error,178,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:482,availability,Error,Error,482,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:419,deployability,fail,failed,419,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:43,energy efficiency,current,currently,43,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:409,interoperability,registr,registry,409,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:12,performance,error,error,12,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:178,performance,Error,Error,178,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:482,performance,Error,Error,482,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:419,reliability,fail,failed,419,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:12,safety,error,error,12,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:178,safety,Error,Error,178,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:482,safety,Error,Error,482,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:433,security,checksum,checksum,433,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:12,usability,error,error,12,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:178,usability,Error,Error,178,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/221:482,usability,Error,Error,482,"Docker pull error.; Your dockerhub repo is currently having issues when trying to pull it, regardless of how:. ```. $> docker pull google/deepvariant. Using default tag: latest. Error response from daemon: manifest for google/deepvariant:latest not found: manifest unknown: manifest unknown. ```. ```. $> singularity pull deepvariant.img docker://google/deepvariant:latest. FATAL: While making image from oci registry: failed to get checksum for docker://google/deepvariant:latest: Error reading manifest latest in docker.io/google/deepvariant: manifest unknown: manifest unknown. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/222:87,availability,down,downloaded,87,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1124,availability,error,error,1124,"following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1507,deployability,modul,module,1507,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1130,integrability,messag,message,1130,"ng test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:972,interoperability,coordinat,coordinate,972,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1130,interoperability,messag,message,1130,"ng test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1593,interoperability,platform,platform,1593,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1507,modifiability,modul,module,1507,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1566,modifiability,pac,packages,1566,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1124,performance,error,error,1124,"following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:45,safety,input,input,45,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:137,safety,test,test,137,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:196,safety,test,test,196,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:224,safety,test,testdata,224,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:248,safety,test,test,248,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:340,safety,input,input,340,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:505,safety,input,input,505,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:554,safety,input,input,554,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:853,safety,input,input,853,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1124,safety,error,error,1124,"following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1323,safety,input,input,1323,"INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1329,safety,test,test,1329,"_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1507,safety,modul,module,1507,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:2202,safety,input,input,2202,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:2287,safety,input,input,2287,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:739,security,modif,modified,739,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:137,testability,test,test,137,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:196,testability,test,test,196,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:224,testability,test,testdata,224,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:248,testability,test,test,248,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:527,testability,unit,unittest,527,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1329,testability,test,test,1329,"_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1360,testability,Trace,Traceback,1360,"R}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:45,usability,input,input,45,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:340,usability,input,input,340,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:505,usability,input,input,505,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:554,usability,input,input,554,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:800,usability,custom,custom,800,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:853,usability,input,input,853,"Issue 'No non-empty sample name found in the input reads. Please provide the '; I just downloaded the docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1098,usability,tool,tool,1098,"e docker image and ran the following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1124,usability,error,error,1124,"following test on Centos OS 7. Everything worked fine. . INPUT_DIR=""/test/DeepVariant/quickstart-testdata"". OUTPUT_DIR=""/test/DeepVariant/quickstart-output"". BIN_VERSION=""0.8.0"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1323,usability,input,input,1323,"INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:2202,usability,input,input,2202,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:2287,usability,input,input,2287,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:2386,usability,user,user,2386,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. Then I modified the shell script to run my sample . > I'm using the custom ref - included fa, fai, .gz. gzi files in the input dir. >RHA. CTGGG ..... > I aligned my reads to the ref and extracted only mapped paired-end reads. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 /..... > now when I run the docker tool, I get the following error message. 2019-09-24 15:23:14.405094: W third_party/nucleus/io/sam_reader.cc:564] Unrecognized SAM header type, ignoring:. I0924 15:23:14.405213 139913087186688 genomics_reader.py:218] Reading /input/test.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 316, in default_options. sample_name = extract_sample_name_from_sam_reader(sam_reader). File ""/tmp/Bazel.runfiles_iYr42Y/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 458, in extract_sample_name_from_sam_reader. 'No non-empty sample name found in the input reads. Please provide the '. ValueError: No non-empty sample name found in the input reads. Please provide the name of the sample with the --sample_name argument. real 0m1.587s. user 0m3.748s. sys 0m6.337s. What could be wrong? Thanks,. Azita",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/223:142,availability,down,downloaded,142,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1917,availability,error,error,1917,"c.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1953,availability,error,error,1953," -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2228,availability,error,error,2228,"ocker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:116,deployability,API,API,116,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:120,deployability,version,version,120,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1117,deployability,instal,installed,1117,"rsion 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/uc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1198,deployability,updat,update,1198,"PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1222,deployability,instal,install,1222,". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:116,integrability,API,API,116,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:120,integrability,version,version,120,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:116,interoperability,API,API,116,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:120,modifiability,version,version,120,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2378,modifiability,variab,variable,2378,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1917,performance,error,error,1917,"c.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1953,performance,error,error,1953," -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2228,performance,error,error,2228,"ocker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:25,reliability,doe,doesn,25,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:217,safety,test,testdata,217,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:297,safety,test,testdata,297,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1198,safety,updat,update,1198,"PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1336,safety,test,test,1336," ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1412,safety,test,testdata,1412,"UT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1509,safety,input,input,1509,"_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1676,safety,input,input,1676,"}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1725,safety,input,input,1725," wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. An",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1917,safety,error,error,1917,"c.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1953,safety,error,error,1953," -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2114,safety,input,input,2114,"installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2228,safety,error,error,2228,"ocker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2430,safety,test,tested,2430,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2570,safety,test,testdata,2570,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2626,safety,input,input,2626,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2719,safety,input,input,2719,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2748,safety,input,input,2748,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2787,safety,input,input,2787,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2830,safety,input,input,2830,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2877,safety,input,input,2877,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2927,safety,input,input,2927,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2981,safety,input,input,2981,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3020,safety,input,input,3020,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3063,safety,input,input,3063,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3105,safety,input,input,3105,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3151,safety,input,input,3151,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3254,safety,input,input,3254,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1191,security,apt,apt,1191,"_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1198,security,updat,update,1198,"PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1211,security,apt,apt-get,1211,"t-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different comput",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:217,testability,test,testdata,217,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:297,testability,test,testdata,297,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:785,testability,unit,unittest,785,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:857,testability,unit,unittest,857,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:933,testability,unit,unittest,933,"DeepVariant docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1008,testability,unit,unittest,1008,"docker image doesn't find the reference genome. ; Dears,. I'm working on Ubuntu 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1087,testability,unit,unittest,1087," 16.04.5 LTS, and Docker API version 1.39,. I have downloaded the data according to the script:. INPUT_DIR=""${PWD}/quickstart-testdata"". DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata"". mkdir -p ${INPUT_DIR}. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1336,testability,test,test,1336," ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1412,testability,test,testdata,1412,"UT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1698,testability,unit,unittest,1698,"100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2136,testability,unit,unittest,2136,"nt image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fast",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2430,testability,test,tested,2430,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2570,testability,test,testdata,2570,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3003,testability,unit,unittest,3003,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3042,testability,unit,unittest,3042,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3085,testability,unit,unittest,3085,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3127,testability,unit,unittest,3127,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3173,testability,unit,unittest,3173,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1509,usability,input,input,1509,"_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1676,usability,input,input,1676,"}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1725,usability,input,input,1725," wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. An",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1917,usability,error,error,1917,"c.hg19.chr20.unittest.fasta.gz. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:1953,usability,error,error,1953," -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai. wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2030,usability,help,helpshort,2030," -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2045,usability,help,helpfull,2045,"R} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2061,usability,help,help,2061,"P_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi. I have installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2114,usability,input,input,2114,"installed the DeepVariant image according to: . BIN_VERSION=""0.8.0"". sudo apt -y update. sudo apt-get -y install docker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2228,usability,error,error,2228,"ocker.io. sudo docker pull gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2349,usability,user,user,2349,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2626,usability,input,input,2626,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2719,usability,input,input,2719,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2748,usability,input,input,2748,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2787,usability,input,input,2787,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2830,usability,input,input,2830,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2877,usability,input,input,2877,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2927,usability,input,input,2927,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:2981,usability,input,input,2981,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3020,usability,input,input,3020,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3063,usability,input,input,3063,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3105,usability,input,input,3105,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3151,usability,input,input,3151,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3254,usability,input,input,3254,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:3285,usability,help,help,3285,"BIN_VERSION}"". When I run the script test: . OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""0.8.0"". sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"". \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \ . --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. The following error happens:. FATAL Flags parsing error: flag --ref=None: Flag --ref must have a value other than None. Pass --helpshort or --helpfull to see help on flags. ./run_deepvariant.sh: line 12: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory. I tried it on three different computers, and the error was the same. There is a previous issue in this forum (https://github.com/google/deepvariant/issues/181) where the user did not set BIN_VERSION variable correctly, and **IT IS NOT MY CASE**!!!! I tested if the volumes were mounted correctly, according to the script:. OUTPUT_DIR=""${PWD}/quickstart-output"". INPUT_DIR=""${PWD}/quickstart-testdata"". sudo docker run \. -i \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:0.8.0 \. find /input. And the result was:. /input/NA12878_S1.chr20.10_10p1mb.bam. /input/NA12878_S1.chr20.10_10p1mb.bam.bai. /input/test_nist.b37_chr20_100kbp_at_10mb.bed. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz. /input/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi. /input/ucsc.hg19.chr20.unittest.fasta. /input/ucsc.hg19.chr20.unittest.fasta.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz. /input/ucsc.hg19.chr20.unittest.fasta.gz.fai. /input/ucsc.hg19.chr20.unittest.fasta.gz.gzi. It means that all files are in the mounted Docker volume /input . Thanks so much for any help,. Rogério",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/224:130,energy efficiency,model,models,130,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:417,integrability,sub,subset,417,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:556,interoperability,Specif,Specifically,556,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:21,safety,valid,validation,21,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:81,safety,valid,validation,81,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:294,safety,valid,validation,294,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:351,safety,valid,validation,351,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:451,safety,valid,validation,451,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:21,security,validat,validation,21,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:81,security,validat,validation,81,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:130,security,model,models,130,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:294,security,validat,validation,294,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:351,security,validat,validation,351,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:451,security,validat,validation,451,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:257,usability,prefer,prefer,257,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:628,usability,prefer,preferring,628,"Question about train/validation split; Hi,. I had a question regarding how train/validation split was determined for training the models. From the DeepVariant paper, I noticed that chromosome 1-19 was used for training. Within chr1-19, is there a reason to prefer one of the following training-validation splits:. 1. Designate chr-a, 1 <= a <= 19, as validation set, and remaining as training set. 2. Use some random subset of all labeled images as a validation set, and the disjoint set as training set (the random split may be grouped by sites, or not). Specifically, I am interested in knowing whether there was a reason for preferring one split over the other, or whether it is an arbitrary choice, that is considered equivalent. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/225:316,availability,error,error,316,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1720,availability,servic,service-account-scopes,1720,"ant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:186,deployability,build,build,186,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1640,deployability,pipelin,pipeline,1640," whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1672,deployability,pipelin,pipelines,1672,"DEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1720,deployability,servic,service-account-scopes,1720,"ant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1797,deployability,log,logging,1797,"IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [stagin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1881,deployability,log,log,1881,"variant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2011,deployability,log,log,2011,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2462,deployability,build,build,2462,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:366,energy efficiency,Cloud,Cloud,366,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:627,energy efficiency,Model,Model,627,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:675,energy efficiency,MODEL,MODEL,675,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:698,energy efficiency,model,models,698,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1116,energy efficiency,model,model,1116,". Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1124,energy efficiency,MODEL,MODEL,1124,"that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1776,energy efficiency,cloud,cloud-platform,1776,"ION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Than",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1933,energy efficiency,cloud,cloud-lifesciences,1933,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1640,integrability,pipelin,pipeline,1640," whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1672,integrability,pipelin,pipelines,1672,"DEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1720,integrability,servic,service-account-scopes,1720,"ant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1782,interoperability,platform,platform,1782,"=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2099,interoperability,mismatch,mismatch,2099,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1720,modifiability,servic,service-account-scopes,1720,"ant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:316,performance,error,error,316,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:108,safety,input,input,108,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:316,safety,error,error,316,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1797,safety,log,logging,1797,"IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [stagin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1881,safety,log,log,1881,"variant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2011,safety,log,log,2011,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2384,safety,input,input,2384,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:627,security,Model,Model,627,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:675,security,MODEL,MODEL,675,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:698,security,model,models,698,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1116,security,model,model,1116,". Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1124,security,MODEL,MODEL,1124,"that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1771,security,auth,auth,1771,"IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreci",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1797,security,log,logging,1797,"IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [stagin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1881,security,log,log,1881,"variant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1980,security,command-lin,command-line,1980,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2011,security,log,log,2011,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1797,testability,log,logging,1797,"IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [stagin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1881,testability,log,log,1881,"variant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2011,testability,log,log,2011,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:108,usability,input,input,108,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:316,usability,error,error,316,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:865,usability,COMMAND,COMMAND,865,"ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. ; Attempting to run variant analysis on bam file aligned to GRCh38.p13 using GRCh38.p13 as the reference but receiving the error below from make_examples. Running in Google Cloud with the following script.sh:. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=mbh-deepvariant-1. OUTPUT_BUCKET=gs://mbh-deepvariant-ouput-vcf. STAGING_FOLDER_NAME=staging_folder1. OUTPUT_FILE_NAME=HR090610illuminagr38DeepVariant.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.8.0/DeepVariant-inception_v3-0.8.0+data-wgs_standard. IMAGE_VERSION=0.8.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMM",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1980,usability,command,command-line,1980,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:1996,usability,COMMAND,COMMAND,1996,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2265,usability,command,command,2265,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2384,usability,input,input,2384,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:2748,usability,feedback,feedback,2748,"project ${PROJECT_ID} \. --zones us-west2-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://mbh-bam-files1/HR090610.final.bam \. --bai gs://mbh-bam-files1/HR090610.final.bam.bai \. --ref gs://mbh-bam-files1/GCA_000001405.28_GRCh38.p13_genomic.fa \. --shards 224 \. --make_examples_workers 7 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 200 \. --call_variants_workers 7 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 200 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west2 \. --docker-image gcr.io/cloud-lifesciences/gcp-deepvariant-runner \. --command-line ""${COMMAND}"". The log file is attached, but part of it is also pasted below. Is it saying that there is a mismatch between the .fai and .fa files for the reference or between the reference and the bam file? The .fai file was created from the .fa file using samtools index command. . ValueError: Reference contigs span 3270284521 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""CM000663.2"" is 248956422 bp and IS MISSING, ""KI270706.1"" is 175055 bp and IS MISSING, ""KI270707.1"" is 32032 bp and IS MISSING, ""KI270708.1"" is 127682 bp and IS MISSING, ""KI270709.1"" is 66860 bp and IS MISSING, ""KI270710.1"" is 40176 bp and IS MISSING... Any feedback would be appreciated. Thanks, -Matt. [staging_folder1_logs_make_examples_7.txt](https://github.com/google/deepvariant/files/3700231/staging_folder1_logs_make_examples_7.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/226:0,availability,Error,Error,0,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:105,availability,error,errors,105,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1139,availability,avail,available,1139,"s/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1324,availability,avail,available,1324,"est.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1494,deployability,modul,module,1494,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1022,energy efficiency,core,core,1022,"iant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | paral",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1207,energy efficiency,core,core,1207,". > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:618,integrability,buffer,buffer,618,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1790,integrability,sub,subprocess,1790,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1883,integrability,sub,subprocess,1883,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1964,integrability,sub,subprocess,1964,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2038,integrability,buffer,buffer,2038,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1027,interoperability,platform,platform,1027," Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1212,interoperability,platform,platform,1212,"t/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1494,modifiability,modul,module,1494,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1554,modifiability,pac,packages,1554,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1654,modifiability,pac,packages,1654,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:0,performance,Error,Error,0,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:105,performance,error,errors,105,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:584,performance,time,time,584,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:599,performance,parallel,parallel,599,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2004,performance,time,time,2004,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2019,performance,parallel,parallel,2019,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1139,reliability,availab,available,1139,"s/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1324,reliability,availab,available,1324,"est.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:0,safety,Error,Error,0,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:105,safety,error,errors,105,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:170,safety,test,test,170,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:299,safety,test,testdata,299,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:368,safety,test,testdata,368,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:698,safety,test,testdata,698,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:764,safety,test,testdata,764,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1139,safety,avail,available,1139,"s/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1324,safety,avail,available,1324,"est.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1494,safety,modul,module,1494,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2118,safety,test,testdata,2118,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2184,safety,test,testdata,2184,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1139,security,availab,available,1139,"s/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1324,security,availab,available,1324,"est.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:170,testability,test,test,170,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:299,testability,test,testdata,299,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:324,testability,unit,unittest,324,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:368,testability,test,testdata,368,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:698,testability,test,testdata,698,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:723,testability,unit,unittest,723,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:764,testability,test,testdata,764,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1396,testability,Trace,Traceback,1396,"mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2118,testability,test,testdata,2118,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2143,testability,unit,unittest,2143,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2184,testability,test,testdata,2184,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:0,usability,Error,Error,0,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:105,usability,error,errors,105,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:569,usability,command,command,569,"Error in running DeepVariant in Docker on CentOS 7; I ran deepvariant in docker on centos 7 but had some errors:. docker run -v \. > /db_students/genetic_map/dv_workarea/test \. > dajunluo/deepvariant:latest \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WGS \. > --ref=/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. > --reads=/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1367,usability,user,user,1367,"estdata/NA12878_S1.chr20.10_10p1mb.bam \. > --regions ""chr20:10,000,000-10,010,000"" \. > --output_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1812,usability,command,command,1812,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:1995,usability,Command,Command,1995,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/226:2424,usability,statu,status,2424,"_vcf=test_output.vcf.gz \. > --output_gvcf=test_output.g.vcf.gz \. > --num_shards=2. ***** Running the command:*****. time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}. 2019-10-15 11:18:39.819615: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. 2019-10-15 11:18:39.819621: F tensorflow/core/platform/cpu_feature_guard.cc:37] The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine. real	0m23.020s. user	0m1.610s. sys	0m3.206s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 1 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/opt/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/opt/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@2.gz"" --regions ""chr20:10,000,000-10,010,000"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@2.gz"" --task {}' returned non-zero exit status 2. Do anyone know how to handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/227:20,energy efficiency,GPU,GPUs,20,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:45,energy efficiency,GPU,GPU,45,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:146,energy efficiency,GPU,GPUs,146,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:20,performance,GPU,GPUs,20,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:45,performance,GPU,GPU,45,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:146,performance,GPU,GPUs,146,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:122,usability,command,command,122,How to use multiple GPUs ?; I found that the GPU only uses one when executing the call variant. Is there any other way or command to use multiple GPUs? Thank you. Jacky,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/228:12,availability,Down,Downloaded,12,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:219,availability,error,errors,219,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:267,availability,Down,Downloaded,267,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:515,availability,down,downloaded,515,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:72,deployability,instal,install,72,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:128,deployability,instal,install,128,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:162,deployability,version,version,162,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:184,deployability,instal,installed,184,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:240,deployability,instal,installation,240,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:162,integrability,version,version,162,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:162,modifiability,version,version,162,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:43,performance,Content,Content-Length,43,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:219,performance,error,errors,219,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:298,performance,Content,Content-Length,298,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:488,performance,Content,Content-Length,488,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:219,safety,error,errors,219,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:113,usability,command,command,113,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:219,usability,error,errors,219,"CondaError: Downloaded bytes did not match Content-Length; Hi, . when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. CondaError: Downloaded bytes did not match Content-Length. url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. Content-Length: 229846992. downloaded bytes: 217650750. Best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/229:766,availability,error,error,766,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:790,deployability,Fail,Failed,790,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:842,energy efficiency,core,core,842,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:200,modifiability,deco,decode,200,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:766,performance,error,error,766,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:790,reliability,Fail,Failed,790,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:766,safety,error,error,766,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:729,usability,close,close,729,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:766,usability,error,error,766,"show image generated from make example; I would like to view and save the pileup images generated. . I was trying to get the features (image/encoded, and image/shape) from the example genereated, and decode then save it using the following code. ````. for candidate in candidates:. for example in self.create_pileup_examples(candidate):. features_temp = tf.parse_single_example(example_temp, features={'image/encoded': tf.FixedLenFeature([], tf.string),""image/shape"": tf.FixedLenFeature([], tf.int64)}). . image_temp = features_temp['image/encoded'] . shape_temp = features_temp['image/shape'] . image_temp1 = tf.reshape(tf.decode_raw(image_temp, tf.uint8), shape_temp). fh = open(filename_temp, ""wb""). fh.write(image_temp1). fh.close(). ````. and got the following error. ````. TypeError: Failed to convert object of type <class 'tensorflow.core.example.example_pb2.Example'> to Tensor. ````. Is there a neat way to save all pileup images generated when we run the ""make example"" code?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/230:574,availability,down,downsampled,574,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:331,energy efficiency,current,currently,331,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:784,energy efficiency,model,model,784,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:646,interoperability,distribut,distributed,646,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:933,interoperability,distribut,distribution,933,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:379,performance,time,times,379,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:4,reliability,doe,does,4,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:816,safety,test,testing,816,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:984,safety,test,test,984,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:784,security,model,model,784,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:456,testability,coverag,coverages,456,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:615,testability,coverag,coverages,615,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:677,testability,coverag,coverages,677,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:802,testability,coverag,coverages,802,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:816,testability,test,testing,816,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:854,testability,coverag,coverage,854,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:984,testability,test,test,984,"How does dowsample_fraction work?; I looked at https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-details-training-data.md, where it says ""and, more `dowsample_fraction` during training"". Looking through make_examples it seems `downsample_fraction` is a fixed number for any given run of make_examples. My assumption currently is that make_examples is run multiple times with different `downsample_fraction` settings to obtain a wider mix of coverages in the training data, before running training (please correct me if wrong). I also had questions of how the downsampled mix was selected. E.g., were coverages in [20, 60]x equally distributed, or were the lower coverages used sparingly (since, for example, 20x is not a very interesting case)? Also, training a single model on multiple coverages and testing (variant calling) on a single coverage could be problematic (but in DeepVariant it is not), because the data distribution is different between the training and test sets. If there is a blog or article with some of these details, that would also be great!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/231:37,availability,error,error,37,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:416,availability,error,error,416,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:570,availability,avail,available,570,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1503,availability,error,error,1503,"g signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1657,availability,avail,available,1657,"nux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2090,availability,Down,Downloads,2090,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2247,availability,Down,Downloads,2247,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2364,availability,Down,Downloads,2364,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2467,availability,error,error,2467,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2517,availability,Down,Downloads,2517,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2579,availability,Down,Downloads,2579,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2764,availability,error,error,2764,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:6,deployability,instal,installing,6,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:47,deployability,build,build-prereq,47,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:140,deployability,Stage,Stage,140,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:147,deployability,Instal,Install,147,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:262,deployability,Stage,Stage,262,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:333,deployability,Stage,Stage,333,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:340,deployability,Updat,Update,340,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:756,deployability,Stage,Stage,756,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:763,deployability,Instal,Install,763,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:845,deployability,Stage,Stage,845,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:852,deployability,Instal,Install,852,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:877,deployability,infrastructur,infrastructure,877,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1067,deployability,Stage,Stage,1067,"===== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1074,deployability,Instal,Install,1074,"ad config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1151,deployability,Stage,Stage,1151," the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1158,deployability,Instal,Install,1158,"time packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1200,deployability,Instal,Installing,1200,"nfig settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1292,deployability,Stage,Stage,1292,"====== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1299,deployability,Instal,Install,1299,"Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1375,deployability,Stage,Stage,1375,"password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1458,deployability,Stage,Stage,1458,"ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1465,deployability,Updat,Update,1465,"xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1843,deployability,Stage,Stage,1843,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1850,deployability,Instal,Install,1850,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1932,deployability,Stage,Stage,1932,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1939,deployability,Instal,Install,1939,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2814,deployability,version,version,2814,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:76,energy efficiency,Load,Load,76,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:198,energy efficiency,Load,Load,198,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:431,energy efficiency,cloud,cloud,431,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:636,energy efficiency,cloud,cloud,636,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1219,energy efficiency,CPU,CPU-only,1219,"======= [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1518,energy efficiency,cloud,cloud,1518,"uldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Down",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1723,energy efficiency,cloud,cloud,1723,"Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2663,energy efficiency,Current,Current,2663,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:552,integrability,pub,public,552,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:616,integrability,repositor,repository,616,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1639,integrability,pub,public,1639,"r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1703,integrability,repositor,repository,1703,"gned. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2783,integrability,rout,routines,2783,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2814,integrability,version,version,2814,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:616,interoperability,repositor,repository,616,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1703,interoperability,repositor,repository,1703,"gned. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:167,modifiability,pac,packages,167,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:347,modifiability,pac,package,347,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:783,modifiability,pac,packages,783,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:867,modifiability,pac,packaging,867,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:998,modifiability,pac,packages,998,"ile installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proces",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1089,modifiability,pac,packages,1089,"ngs. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Dow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1181,modifiability,pac,package,1181,". ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1313,modifiability,pac,packages,1313,"26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1472,modifiability,pac,package,1472,"ran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1870,modifiability,pac,packages,1870,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2814,modifiability,version,version,2814,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:37,performance,error,error,37,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:76,performance,Load,Load,76,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:198,performance,Load,Load,198,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:416,performance,error,error,416,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1219,performance,CPU,CPU-only,1219,"======= [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1503,performance,error,error,1503,"g signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2467,performance,error,error,2467,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2648,performance,Time,Time,2648,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2653,performance,Time,Time,2653,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2658,performance,Time,Time,2658,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2764,performance,error,error,2764,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:570,reliability,availab,available,570,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1657,reliability,availab,available,1657,"nux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:37,safety,error,error,37,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:340,safety,Updat,Update,340,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:416,safety,error,error,416,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:570,safety,avail,available,570,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1396,safety,compl,complete,1396,"atics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1465,safety,Updat,Update,1465,"xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1503,safety,error,error,1503,"g signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1657,safety,avail,available,1657,"nux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2467,safety,error,error,2467,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2764,safety,error,error,2764,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:340,security,Updat,Update,340,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:378,security,password,password,378,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:508,security,sign,signatures,508,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:570,security,availab,available,570,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:706,security,sign,signed,706,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1396,security,compl,complete,1396,"atics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1465,security,Updat,Update,1465,"xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1595,security,sign,signatures,1595,"084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1657,security,availab,available,1657,"nux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1793,security,sign,signed,1793,"rting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2779,security,SSL,SSL,2779,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:531,testability,verif,verified,531,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1618,testability,verif,verified,1618,"tory 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Recei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:37,usability,error,error,37,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:416,usability,error,error,416,"while installing im getting an bazel error ; ./build-prereq.sh . ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Install the runtime packages' starting. ========== Load config settings. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Misc setup' starting. ========== [Tue Oct 29 17:26:45 IST 2019] Stage 'Update package list' starting. [sudo] password for bioinformatics: . W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_proc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:1503,usability,error,error,1503,"g signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:28:53 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2467,usability,error,error,2467,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:2764,usability,error,error,2764,"28:54 IST 2019] Stage 'Install python packaging infrastructure' starting. Python 2.7.16 :: Anaconda, Inc. pip 19.3.1 from /home/bioinformatics/.local/lib/python2.7/site-packages/pip (python 2.7). ========== [Tue Oct 29 17:28:57 IST 2019] Stage 'Install python packages' starting. ========== [Tue Oct 29 17:29:14 IST 2019] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow wheel. ========== [Tue Oct 29 17:29:15 IST 2019] Stage 'Install other packages' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'run-prereq.sh complete' starting. ========== [Tue Oct 29 17:29:16 IST 2019] Stage 'Update package list' starting. W: GPG error: https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 51716619E084DAB9. W: The repository 'https://cloud.r-project.org/bin/linux/ubuntu xenial-cran35/ InRelease' is not signed. ========== [Tue Oct 29 17:29:24 IST 2019] Stage 'Install development packages' starting. ========== [Tue Oct 29 17:29:25 IST 2019] Stage 'Install bazel' starting. [bazel INFO src/main/cpp/option_processor.cc:388] Looking for the following rc files: /etc/bazel.bazelrc,/home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc,/home/bioinformatics/.bazelrc,/dev/null. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/.bazelrc. [bazel INFO src/main/cpp/rc_file.cc:56] Parsing the RcFile /home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc. [bazel FATAL src/main/cpp/blaze.cc:1311] Unexpected error reading .blazerc file '/home/bioinformatics/Downloads/deepvariant-r0.8/../tensorflow/.bazelrc'. ~/bazel ~/Downloads/deepvariant-r0.8. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (35) error:1408F10B:SSL routines:ssl3_get_record:wrong version number.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/232:249,availability,error,errors,249,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:759,deployability,modul,module,759,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1055,integrability,sub,subprocess,1055,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1148,integrability,sub,subprocess,1148,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1229,integrability,sub,subprocess,1229,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1304,integrability,buffer,buffer,1304,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:759,modifiability,modul,module,759,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:819,modifiability,pac,packages,819,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:919,modifiability,pac,packages,919,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:249,performance,error,errors,249,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1269,performance,time,time,1269,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1285,performance,parallel,parallel,1285,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:5,reliability,doe,does,5,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:86,safety,input,input,86,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:231,safety,compl,completed,231,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:249,safety,error,errors,249,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:759,safety,modul,module,759,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1385,safety,input,input,1385,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:231,security,compl,completed,231,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:68,testability,verif,verified,68,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:661,testability,Trace,Traceback,661,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:15,usability,statu,status,15,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:86,usability,input,input,86,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:249,usability,error,errors,249,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:629,usability,user,user,629,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1077,usability,command,command,1077,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1260,usability,Command,Command,1260,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1385,usability,input,input,1385,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1581,usability,statu,status,1581,"What does exit status 16 mean?; Germline deep variant 0.8.0. I have verified that the input mapping, the bed file, and the ref genome are all based on the same reference. The same script was used for several other samples and they completed without errors. ```. I1030 18:44:39.325231 140247813654272 make_examples.py:1164] Writing MakeExamplesRunInfo to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00063-of-00064.gz.run_info.pbtxt. I1030 18:44:39.367234 140247813654272 make_examples.py:1167] Found 484 candidate variants. I1030 18:44:39.367513 140247813654272 make_examples.py:1168] Created 496 examples. real	5m38.670s. user	85m59.188s. sys	1m53.684s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""ref.fa"" --reads ""input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 16. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/233:1049,integrability,filter,filtering,1049,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:109,modifiability,Pac,PacBio,109,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:976,reliability,doe,doesn,976,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:54,safety,test,testing,54,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:896,safety,test,test,896,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:54,testability,test,testing,54,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:143,testability,trace,trace,143,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:661,testability,simul,simultaneously,661,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:896,testability,test,test,896,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:441,usability,user,user-images,441,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:829,usability,support,support,829,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1040,usability,tip,tips,1040,"Why no variants called in these regions?; Hi, . I was testing the variants calling by deepvariant (DV) using PacBio CCS long reads https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/PacBio_SequelII_CCS_11kb/HG002.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.10x.trio.bam. But I found some issues in the region 22:16,977,867-16,978,040 (hs37d5) show in the following IGV screenshot. ![fig1](https://user-images.githubusercontent.com/27715065/68264666-81b49500-0084-11ea-8887-2283259b3df3.png). In the region, DV can call SNPs at position 16977891(A->G) and 17977975(A->G). A strange question, all the variants come out simultaneously in some reads at pos 16977870(A->T), 16977879(7bp insertion), 16977911(G->A), 16977924(T->C), 16977984(A->G) and 16978027(2bp deletion), the read counts support reference and variant allele is 15:12. What's more, I also test GATK4, both DV and GATK4 don't give these variants. So I doubt that why DV doesn't give these positions as variants, if so, are there some tips for filtering these positions? Looking forward to your answer. Best!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/pull/234:4,deployability,Updat,Update,4,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:18,deployability,version,version,18,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:64,deployability,updat,updat,64,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:264,deployability,Updat,Update,264,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:18,integrability,version,version,18,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:18,modifiability,version,version,18,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:384,performance,time,time,384,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:4,safety,Updat,Update,4,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:64,safety,updat,updat,64,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:264,safety,Updat,Update,264,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:4,security,Updat,Update,4,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:64,security,updat,updat,64,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/pull/234:264,security,Updat,Update,264,"(1) Update binary version to 0.7.1. Re-run all case studies and updat…; …ed information. Note that previously there was a typo in WGS case study -- instead of 209m 53s, it was 309m 53s. (2) Remove BIN_VERSION in the *_binaries.sh script because it was unused. (3) Update a few instructions in training case study. PiperOrigin-RevId: 220115965. We are not taking pull requests at this time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/234
https://github.com/google/deepvariant/issues/235:75,availability,error,error,75,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:321,availability,error,error,321,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:413,availability,Error,Error,413,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:472,availability,Error,Error,472,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:664,availability,Error,Error,664,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:519,deployability,fail,failed,519,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:560,deployability,contain,container,560,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:1320,deployability,releas,release,1320,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:327,integrability,messag,message,327,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:419,integrability,messag,message,419,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:670,integrability,messag,message,670,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:327,interoperability,messag,message,327,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:419,interoperability,messag,message,419,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:670,interoperability,messag,message,670,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:75,performance,error,error,75,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:321,performance,error,error,321,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:413,performance,Error,Error,413,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:472,performance,Error,Error,472,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:664,performance,Error,Error,664,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:397,reliability,doe,does,397,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:519,reliability,fail,failed,519,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:1022,reliability,doe,does,1022,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:75,safety,error,error,75,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:321,safety,error,error,321,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:413,safety,Error,Error,413,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:472,safety,Error,Error,472,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:635,safety,permiss,permission,635,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:664,safety,Error,Error,664,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:48,security,team,team,48,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:75,usability,error,error,75,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:129,usability,document,documentation,129,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:275,usability,interact,interactively,275,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:321,usability,error,error,321,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:413,usability,Error,Error,413,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:446,usability,document,documentation,446,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:472,usability,Error,Error,472,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:664,usability,Error,Error,664,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:1397,usability,tool,tool,1397,"Unable to run vcf stats report; Hi Deep Variant team,. I receive the below error when attempting to follow the [VCF stats report documentation](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-vcf-stats-report.md); however, attempting to run vcf stats report interactively inside of the docker yielded an error message that was a bit more informative, telling me that the .py file does not exist. Error message from following the documentation . > docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""exec: \""/opt/deepvariant/bin/vcf_stats_report\"": permission denied"": unknown. Error message from inside the docker. > python: can't open file '/opt/deepvariant/bin/vcf_stats_report.py': [Errno 2] No such file or directory. It seems that [lines 79 to 81 of the Dockerfile](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L79-L82) create the file called, /opt/deepvariant/bin/vcf_stats_report, but the underlying python script does not seem to be copied into the Docker. It looks like other files in the /opt/deepvariant/bin directory are copied over in [lines 42 to 50](https://github.com/google/deepvariant/blob/r0.9/Dockerfile#L42-L50), maybe a similar line needs to be added for vcf_stats_report? Thank you for the 0.9.0 release and for being so active on Github. I’m looking forward to using this tool for my research.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/236:20,availability,error,error,20,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:349,availability,error,error,349,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,availability,error,error,433,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:731,availability,error,error,731,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:32,deployability,updat,update,32,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:213,deployability,version,version,213,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:278,deployability,releas,release,278,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:376,deployability,stage,stage,376,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:613,deployability,releas,releases,613,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:775,deployability,instal,install,775,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:797,deployability,depend,dependencies,797,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:213,integrability,version,version,213,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:797,integrability,depend,dependencies,797,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:213,modifiability,version,version,213,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:797,modifiability,depend,dependencies,797,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:20,performance,error,error,20,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:349,performance,error,error,349,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,performance,error,error,433,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:731,performance,error,error,731,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:20,safety,error,error,20,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:32,safety,updat,update,32,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:227,safety,test,tests,227,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:349,safety,error,error,349,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,safety,error,error,433,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:731,safety,error,error,731,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:797,safety,depend,dependencies,797,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:32,security,updat,update,32,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:80,security,team,team,80,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:227,testability,test,tests,227,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:797,testability,depend,dependencies,797,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:20,usability,error,error,20,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:117,usability,tool,tool,117,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:349,usability,error,error,349,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,usability,error,error,433,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:731,usability,error,error,731,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:746,usability,help,help,746,#include <optional> error after update from v0.8.0 to v0.9.0; Hello DeepVariant team. We're trying to use your great tool and I'm creating our own Docker for this. Yesterday I finally fixed all issues with v0.8.0 version - all tests from build_and_test.sh passed and saw v0.9.0 release happened several days before - I tried to switch to in and get error at build_and_test.sh stage:. ```. deepvariant/variant_calling.cc:36:20: fatal error: optional: No such file or directory. #include <optional>. ^. compilation terminated. ```. Looks like you added new include lines in `deepvariant/variant_calling.cc` between releases - [this](https://github.com/google/deepvariant/blob/r0.9/deepvariant/variant_calling.cc#L36) line causing my error. Can you help me please? Do I need to install some external dependencies or what?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/237:255,availability,avail,available,255,"How to get the Capture target BED file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""; I have searched at the [Evaluation regions for HG002 · Issue #15 · google/deepvariant](https://github.com/google/deepvariant/issues/15), but the website is not available. Here is the non-intersected BED file:. https://dl.dnanex.us/F/D/y61fXf4qz5G8F4QvXz14bkYQ5Q9Yy5q5JPf1K3kg/agilent_sureselect_human_all_exon_v5_b37_targets.bed. Would you please offer the reachable site of the file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""? Thanks a lot.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/237
https://github.com/google/deepvariant/issues/237:255,reliability,availab,available,255,"How to get the Capture target BED file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""; I have searched at the [Evaluation regions for HG002 · Issue #15 · google/deepvariant](https://github.com/google/deepvariant/issues/15), but the website is not available. Here is the non-intersected BED file:. https://dl.dnanex.us/F/D/y61fXf4qz5G8F4QvXz14bkYQ5Q9Yy5q5JPf1K3kg/agilent_sureselect_human_all_exon_v5_b37_targets.bed. Would you please offer the reachable site of the file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""? Thanks a lot.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/237
https://github.com/google/deepvariant/issues/237:255,safety,avail,available,255,"How to get the Capture target BED file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""; I have searched at the [Evaluation regions for HG002 · Issue #15 · google/deepvariant](https://github.com/google/deepvariant/issues/15), but the website is not available. Here is the non-intersected BED file:. https://dl.dnanex.us/F/D/y61fXf4qz5G8F4QvXz14bkYQ5Q9Yy5q5JPf1K3kg/agilent_sureselect_human_all_exon_v5_b37_targets.bed. Would you please offer the reachable site of the file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""? Thanks a lot.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/237
https://github.com/google/deepvariant/issues/237:255,security,availab,available,255,"How to get the Capture target BED file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""; I have searched at the [Evaluation regions for HG002 · Issue #15 · google/deepvariant](https://github.com/google/deepvariant/issues/15), but the website is not available. Here is the non-intersected BED file:. https://dl.dnanex.us/F/D/y61fXf4qz5G8F4QvXz14bkYQ5Q9Yy5q5JPf1K3kg/agilent_sureselect_human_all_exon_v5_b37_targets.bed. Would you please offer the reachable site of the file ""agilent_sureselect_human_all_exon_v5_b37_targets.bed""? Thanks a lot.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/237
https://github.com/google/deepvariant/issues/238:177,availability,down,downstream,177,"MNP Support; Dear DeepVariant Team,. I have a short question. Are there any plans for calling MNPs in near future? This would be really helpfull for variant annotations further downstream. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:30,security,Team,Team,30,"MNP Support; Dear DeepVariant Team,. I have a short question. Are there any plans for calling MNPs in near future? This would be really helpfull for variant annotations further downstream. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:76,testability,plan,plans,76,"MNP Support; Dear DeepVariant Team,. I have a short question. Are there any plans for calling MNPs in near future? This would be really helpfull for variant annotations further downstream. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:4,usability,Support,Support,4,"MNP Support; Dear DeepVariant Team,. I have a short question. Are there any plans for calling MNPs in near future? This would be really helpfull for variant annotations further downstream. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:136,usability,help,helpfull,136,"MNP Support; Dear DeepVariant Team,. I have a short question. Are there any plans for calling MNPs in near future? This would be really helpfull for variant annotations further downstream. Sebastian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/239:852,deployability,observ,observed,852,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1104,deployability,scale,scaled,1104,"have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26166,deployability,contain,containing,26166,"ORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,deployability,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115798,deployability,version,version,115798,"=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 48 0 44 0 1 1 0,916667 1 . SNP ALL 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. SNP PASS 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. ```. Is it normal? Is `test_nist.b37_chr20_100kbp_at_10mb.vcf` outdated or it is made on latest deepvariant version?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:335,energy efficiency,model,model,335,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1104,energy efficiency,scale,scaled,1104,"have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:239,integrability,FILTER,FILTER,239,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:272,integrability,filter,filters,272,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:292,integrability,FILTER,FILTER,292,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:377,integrability,FILTER,FILTER,377,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1230,integrability,FILTER,FILTER,1230,".2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:36:0,36:1:45,50,0. chr20	10001617	.	C	A	30.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:31:43:23,20:0.4651",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24084,integrability,FILTER,FILTER,24084,"0.333333:0,28,55. chr20	10099079	.	C	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:38:23,15:0.394737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24180,integrability,FILTER,FILTER,24180,":0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24255,integrability,filter,filtered,24255,"4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24321,integrability,FILTER,FILTER,24321,":GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24393,integrability,filter,filtered,24393,".4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24439,integrability,FILTER,FILTER,24439,".574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24563,integrability,FILTER,FILTER,24563,"	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,D",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24601,integrability,Filter,Filtered,24601,",18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed acr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24662,integrability,filter,filtered,24662,"DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Nu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24722,integrability,FILTER,FILTER,24722,"65	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24764,integrability,Filter,Filtered,24764,":42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24806,integrability,filter,filtered,24806,"755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Numbe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24904,integrability,FILTER,FILTER,24904,"ASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24935,integrability,Filter,Filtered,24935,"53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>test_nist.b37_chr20_100kbp_at_10mb.vcf</summary>. . ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25657,integrability,filter,filter,25657,"t filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Numb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25709,integrability,filter,filtering,25709,"ng"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25896,integrability,filter,filtered,25896,". ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26054,integrability,filter,filtered,26054,"<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26450,integrability,filter,filtered,26450,"er=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##INFO=<ID=lowcov,Number=1,Type=String,Description=""List of callsets that had this call in a region with low coverage of high MQ reads."">. ##INFO=<ID=arbitrated,Number=1,Type=String,Description",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26606,integrability,filter,filtered,26606,"ll datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##INFO=<ID=lowcov,Number=1,Type=String,Description=""List of callsets that had this call in a region with low coverage of high MQ reads."">. ##INFO=<ID=arbitrated,Number=1,Type=String,Description=""TRUE if callsets had discordant calls so that arbitration was needed."">. ##contig=<ID=chr1,length=249250621,assembly=b37>. ##contig=<ID=chr2,length=243199",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26941,integrability,filter,filtered,26941,"r=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##INFO=<ID=lowcov,Number=1,Type=String,Description=""List of callsets that had this call in a region with low coverage of high MQ reads."">. ##INFO=<ID=arbitrated,Number=1,Type=String,Description=""TRUE if callsets had discordant calls so that arbitration was needed."">. ##contig=<ID=chr1,length=249250621,assembly=b37>. ##contig=<ID=chr2,length=243199373,assembly=b37>. ##contig=<ID=chr3,length=198022430,assembly=b37>. ##contig=<ID=chr4,length=191154276,assembly=b37>. ##contig=<ID=chr5,length=180915260,assembly=b37>. ##contig=<ID=chr6,length=171115067,assembly=b37>. ##contig=<ID=chr7,length=159138663,assembly=b37>. ##contig=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:27071,integrability,filter,filtered,27071,"INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##INFO=<ID=lowcov,Number=1,Type=String,Description=""List of callsets that had this call in a region with low coverage of high MQ reads."">. ##INFO=<ID=arbitrated,Number=1,Type=String,Description=""TRUE if callsets had discordant calls so that arbitration was needed."">. ##contig=<ID=chr1,length=249250621,assembly=b37>. ##contig=<ID=chr2,length=243199373,assembly=b37>. ##contig=<ID=chr3,length=198022430,assembly=b37>. ##contig=<ID=chr4,length=191154276,assembly=b37>. ##contig=<ID=chr5,length=180915260,assembly=b37>. ##contig=<ID=chr6,length=171115067,assembly=b37>. ##contig=<ID=chr7,length=159138663,assembly=b37>. ##contig=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:27248,integrability,filter,filtered,27248,"rence, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Type of variant"">. ##INFO=<ID=filt,Number=1,Type=String,Description=""List of callsets that had this call filtered."">. ##INFO=<ID=lowcov,Number=1,Type=String,Description=""List of callsets that had this call in a region with low coverage of high MQ reads."">. ##INFO=<ID=arbitrated,Number=1,Type=String,Description=""TRUE if callsets had discordant calls so that arbitration was needed."">. ##contig=<ID=chr1,length=249250621,assembly=b37>. ##contig=<ID=chr2,length=243199373,assembly=b37>. ##contig=<ID=chr3,length=198022430,assembly=b37>. ##contig=<ID=chr4,length=191154276,assembly=b37>. ##contig=<ID=chr5,length=180915260,assembly=b37>. ##contig=<ID=chr6,length=171115067,assembly=b37>. ##contig=<ID=chr7,length=159138663,assembly=b37>. ##contig=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28861,integrability,FILTER,FILTER,28861,"assembly=b37>. ##contig=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,integrability,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115302,integrability,Filter,Filter,115302,"=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 48 0 44 0 1 1 0,916667 1 . SNP ALL 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. SNP PASS 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. ```. Is it normal? Is `test_nist.b37_chr20_100kbp_at_10mb.vcf` outdated or it is made on latest deepvariant version?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115798,integrability,version,version,115798,"=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:800:841. chr20	10099565	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:827:1201. chr20	10099755	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:687:1028. chr20	10099832	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:723:1150. ```. . </details>. hap.py report:. ```. Type Filter TRUTH,TOTAL TRUTH,TP TRUTH,FN QUERY,TOTAL QUERY,FP QUERY,UNK FP,gt METRIC,Recall METRIC,Precision METRIC,Frac_NA METRIC,F1_Score TRUTH,TOTAL,TiTv_ratio. INDEL ALL 4 4 0 48 0 44 0 1 1 0,916667 1 . INDEL PASS 4 4 0 48 0 44 0 1 1 0,916667 1 . SNP ALL 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. SNP PASS 45 44 1 191 0 147 0 0,977778 1 0,769634 0,988764 1,142857143. ```. Is it normal? Is `test_nist.b37_chr20_100kbp_at_10mb.vcf` outdated or it is made on latest deepvariant version?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:578,interoperability,FORMAT,FORMAT,578,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:640,interoperability,FORMAT,FORMAT,640,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:723,interoperability,FORMAT,FORMAT,723,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:788,interoperability,FORMAT,FORMAT,788,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:889,interoperability,FORMAT,FORMAT,889,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:970,interoperability,FORMAT,FORMAT,970,"Different results on test data; Hello DeepVariant team. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1049,interoperability,FORMAT,FORMAT,1049,"am. We trying to implement your tool, it works, but we have different results on test data:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1242,interoperability,FORMAT,FORMAT,1242,"=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:36:0,36:1:45,50,0. chr20	10001617	.	C	A	30.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:31:43:23,20:0.465116:30,0,57. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25051,interoperability,FORMAT,FORMAT,25051," ```. ##fileformat=VCFv4.1. ##FILTER=<ID=GQlessthan70,Description=""Sum of GQ for datasets with this variant less than 70"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25170,interoperability,FORMAT,FORMAT,25170,"0"">. ##FILTER=<ID=allfilteredanddisagree,Description=""All callsets have this call filtered and they have discordant genotypes or variant calls"">. ##FILTER=<ID=allfilteredbutagree,Description=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads contain",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25350,interoperability,FORMAT,FORMAT,25350,"escription=""All callsets have this call filtered but they have the same genotype"">. ##FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Descri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25436,interoperability,FORMAT,FORMAT,25436,"FILTER=<ID=discordantunfiltered,Description=""Callsets with unfiltered calls have discordant genotypes or variant calls"">. ##FILTER=<ID=discordanthet,Description=""Filtered calls where a passing call is het and a high GQ but filtered call is hom var, since often the het is wrong"">. ##FILTER=<ID=questionableindel,Description=""Filtered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25760,interoperability,platform,platforms,25760,"iltered calls where some callsets have a filtered indel larger than 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at thi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25825,interoperability,platform,platforms,25825,"an 10bp and another dataset has an implied homozygous reference call"">. ##FILTER=<ID=cgonly,Description=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25926,interoperability,platform,platformnames,25926,"=""Filtered calls where only Complete Genomics had this call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25983,interoperability,platform,platforms,25983,"call and it was completely missing from any other callset"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Numb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26084,interoperability,platform,platformbias,26084,"cription=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:26140,interoperability,platform,platforms,26140,"excluding MQ0 reads"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Net Genotype quality across all datasets, defined as difference between most likely and next most likely genotype likelihoods"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Net Genotype across all datasets"">. ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phase set in which this variant falls"">. ##INFO=<ID=DPSum,Number=1,Type=Integer,Description=""Total read depth summed across all datasets, excluding MQ0 reads"">. ##INFO=<ID=filter,Number=1,Type=String,Description=""Reason for filtering this genotype as uncertain"">. ##INFO=<ID=platforms,Number=1,Type=Integer,Description=""Number of different platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformnames,Number=.,Type=String,Description=""Names of platforms for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=platformbias,Number=.,Type=String,Description=""Names of platforms that have reads containing a variant at this location, but the high-confidence call is homozygous reference, indicating that there is a potential bias."">. ##INFO=<ID=datasets,Number=1,Type=Integer,Description=""Number of different datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetnames,Number=.,Type=String,Description=""Names of datasets for which at least one callset called this genotype, whether filtered or not"">. ##INFO=<ID=datasetsmissingcall,Number=.,Type=Integer,Description=""Names of datasets that are missing a call or have an incorrect call at this location, and the high-confidence call is a variant"">. ##INFO=<ID=callsets,Number=1,Type=Integer,Description=""Number of different callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=callsetnames,Number=.,Type=String,Description=""Names of callsets that called this genotype, whether filtered or not"">. ##INFO=<ID=varType,Number=1,Type=String,Description=""Ty",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28873,interoperability,FORMAT,FORMAT,28873,">. ##contig=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28880,interoperability,INTEGR,INTEGRATION,28880,"g=<ID=chr8,length=146364022,assembly=b37>. ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28922,interoperability,platform,platforms,28922,". ##contig=<ID=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;dat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:28934,interoperability,platform,platformnames,28934,"=chr9,length=141213431,assembly=b37>. ##contig=<ID=chr10,length=135534747,assembly=b37>. ##contig=<ID=chr11,length=135006516,assembly=b37>. ##contig=<ID=chr12,length=133851895,assembly=b37>. ##contig=<ID=chr13,length=115169878,assembly=b37>. ##contig=<ID=chr14,length=107349540,assembly=b37>. ##contig=<ID=chr15,length=102531392,assembly=b37>. ##contig=<ID=chr16,length=90354753,assembly=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:29322,interoperability,platform,platforms,29322,"y=b37>. ##contig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:29334,interoperability,platform,platformnames,29334,"ig=<ID=chr17,length=81195210,assembly=b37>. ##contig=<ID=chr18,length=78077248,assembly=b37>. ##contig=<ID=chr19,length=59128983,assembly=b37>. ##contig=<ID=chr20,length=63025520,assembly=b37>. ##contig=<ID=chr21,length=48129895,assembly=b37>. ##contig=<ID=chr22,length=51304566,assembly=b37>. ##contig=<ID=chrX,length=155270560,assembly=b37>. ##contig=<ID=chrY,length=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:29703,interoperability,platform,platforms,29703,"h=59373566,assembly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasets",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:29715,interoperability,platform,platformnames,29715,"embly=b37>. ##contig=<ID=chrM,length=16569,assembly=b37>. ##fileDate=20160329. ##reference=human_g1k_v37.fasta. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	INTEGRATION. chr20	10000117	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:30125,interoperability,platform,platforms,30125,"onExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:30137,interoperability,platform,platformnames,30137,"E50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt	GT:PS:DP:GQ	0/1:.:706:878. chr20	10000211	.	C	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:30547,interoperability,platform,platforms,30547,"_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:30559,interoperability,platform,platformnames,30559,"idPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:984. chr20	10000439	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,Solid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:30918,interoperability,platform,platforms,30918,";datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:30930,interoperability,platform,platformnames,30930,"ngcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:754:366. chr20	10000598	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:31364,interoperability,platform,platforms,31364,"Exome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:31376,interoperability,platform,platformnames,31376,"S_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:747:499. chr20	10000694	.	G	A	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:31754,interoperability,platform,platforms,31754,"cov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebay",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:31766,interoperability,platform,platformnames,31766,"eTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:812:319. chr20	10000758	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:32181,interoperability,platform,platforms,32181,"TVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetname",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:32193,interoperability,platform,platformnames,32193,"SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:826:329. chr20	10001019	.	T	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:32616,interoperability,platform,platforms,32616,"CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:32628,interoperability,platform,platformnames,32628,"0GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:670:387. chr20	10001298	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:33048,interoperability,platform,platforms,33048,"C_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:33060,interoperability,platform,platformnames,33060,"lidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:763:420. chr20	10001436	.	A	AAGGCT	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:33471,interoperability,platform,platforms,33471,"SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:33483,interoperability,platform,platformnames,33483,"C_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:287. chr20	10001474	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:33893,interoperability,platform,platforms,33893,"lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:33905,interoperability,platform,platformnames,33905,"dSE75GATKHC_lowcov;filt=CS_HiSeqPE300xfreebayes_filt,CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:724:437. chr20	10001617	.	C	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:34315,interoperability,platform,platforms,34315,"lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonEx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:34327,interoperability,platform,platformnames,34327,"dPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:677:1030. chr20	10001628	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:34737,interoperability,platform,platforms,34737,"_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:34749,interoperability,platform,platformnames,34749,"idPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:679:715. chr20	10001661	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:35108,interoperability,platform,platforms,35108,";datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:35120,interoperability,platform,platformnames,35120,"ngcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:650:480. chr20	10001670	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:35479,interoperability,platform,platforms,35479,"00xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:35491,interoperability,platform,platformnames,35491,"al,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:642:481. chr20	10002058	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:35850,interoperability,platform,platforms,35850,"tnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:35862,interoperability,platform,platformnames,35862,"300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:654:320. chr20	10002099	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:36221,interoperability,platform,platforms,36221,"tnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:36233,interoperability,platform,platformnames,36233,"300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:665:924. chr20	10002138	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:36621,interoperability,platform,platforms,36621,"iSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:36633,interoperability,platform,platformnames,36633,",CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:563:336. chr20	10002142	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:37043,interoperability,platform,platforms,37043,"singcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:37055,interoperability,platform,platformnames,37055,"ome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1|1:.:555:312. chr20	10002625	.	G	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:37465,interoperability,platform,platforms,37465,"TVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:37477,interoperability,platform,platformnames,37477,"SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:644:382. chr20	10003021	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:37911,interoperability,platform,platforms,37911,"ATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE30",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:37923,interoperability,platform,platformnames,37923,"S_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:479:347. chr20	10003358	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:38357,interoperability,platform,platforms,38357,"5GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:38369,interoperability,platform,platformnames,38369,";filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:507:808. chr20	10003651	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:38779,interoperability,platform,platforms,38779,"5GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:38791,interoperability,platform,platformnames,38791,";filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:551:405. chr20	10003692	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:39128,interoperability,platform,platforms,39128,"atasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_Sol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:39140,interoperability,platform,platformnames,39140,"call=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:558:496. chr20	10003832	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:39477,interoperability,platform,platforms,39477,"5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:39489,interoperability,platform,platformnames,39489,"=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:633:383. chr20	10004094	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:39876,interoperability,platform,platforms,39876,"ames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:39888,interoperability,platform,platformnames,39888,"0xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:552:302. chr20	10004147	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:40271,interoperability,platform,platforms,40271,"rmal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:40283,interoperability,platform,platformnames,40283,"issingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:494:294. chr20	10004193	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;dataset",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:40674,interoperability,platform,platforms,40674,"SE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:40686,interoperability,platform,platformnames,40686,"CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:464:493. chr20	10004223	.	A	AA,AG	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=1;callsetnames=HiSeqPE300xfreebayes;datasetsmissingcall=HiSeqPE300x,CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:41096,interoperability,platform,platforms,41096,"SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:41108,interoperability,platform,platformnames,41108,"TKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_HiSeqPE300xGATK_filt,CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1|2:.:190:160. chr20	10004351	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:41467,interoperability,platform,platforms,41467,"gcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:41479,interoperability,platform,platformnames,41479,",SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:824:415. chr20	10004389	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:41867,interoperability,platform,platforms,41867,"GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:41879,interoperability,platform,platformnames,41879,"75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:774:355. chr20	10004610	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:42216,interoperability,platform,platforms,42216,"HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:42228,interoperability,platform,platformnames,42228,"ebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:794:404. chr20	10004725	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:42638,interoperability,platform,platforms,42638,",CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:42650,interoperability,platform,platformnames,42650,"dPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:733:994. chr20	10004769	.	TAAAACTATGC	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:43061,interoperability,platform,platforms,43061,"lidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:43073,interoperability,platform,platformnames,43073,"ov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:577:349. chr20	10004874	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:43483,interoperability,platform,platforms,43483,"lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:43495,interoperability,platform,platformnames,43495,"dPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:776:615. chr20	10004887	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:43905,interoperability,platform,platforms,43905,"lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:43917,interoperability,platform,platformnames,43917,"dPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	0/1:.:819:1208. chr20	10005010	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;data",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:44327,interoperability,platform,platforms,44327,"_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:44339,interoperability,platform,platformnames,44339,"idPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:817:414. chr20	10005427	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:44699,interoperability,platform,platforms,44699,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:44711,interoperability,platform,platformnames,44711,"gcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:792:415. chr20	10005499	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:45121,interoperability,platform,platforms,45121,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:45133,interoperability,platform,platformnames,45133,"gcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:779:386. chr20	10005587	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:45521,interoperability,platform,platforms,45521,"ingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:45533,interoperability,platform,platformnames,45533,"me,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:796:1062. chr20	10005723	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:45870,interoperability,platform,platforms,45870,",CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:45882,interoperability,platform,platformnames,45882,"dPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:736:417. chr20	10006291	.	G	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:46296,interoperability,platform,platforms,46296,"GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:46308,interoperability,platform,platformnames,46308,"smissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:736:960. chr20	10006404	.	A	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:46652,interoperability,platform,platforms,46652,"00xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:46664,interoperability,platform,platformnames,46664,"al;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:753:314. chr20	10006682	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:47079,interoperability,platform,platforms,47079,"GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:47091,interoperability,platform,platformnames,47091,"smissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:590:392. chr20	10006819	.	AAAAC	A	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:47506,interoperability,platform,platforms,47506,"_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GAT",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:47518,interoperability,platform,platformnames,47518,"ExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:490:152. chr20	10007150	.	G	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:47928,interoperability,platform,platforms,47928,"_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:47940,interoperability,platform,platformnames,47940,"idSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:604:851. chr20	10007175	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:48328,interoperability,platform,platforms,48328,"owcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:48340,interoperability,platform,platformnames,48340,"PE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt,CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:576:677. chr20	10007352	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExome",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:48722,interoperability,platform,platforms,48722,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasets",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:48734,interoperability,platform,platformnames,48734,"gcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:769:496. chr20	10007531	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:49098,interoperability,platform,platforms,49098,"dSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnorm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:49110,interoperability,platform,platformnames,49110,"tasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:770:426. chr20	10007980	.	A	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:49498,interoperability,platform,platforms,49498,"dSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasets",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:49510,interoperability,platform,platformnames,49510,"tasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:648:383. chr20	10008029	.	T	TA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=Io",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:49920,interoperability,platform,platforms,49920,"=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:49932,interoperability,platform,platformnames,49932,"C_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt;arbitrated=TRUE	GT:PS:DP:GQ	1/1:.:489:160. chr20	10008146	.	TA	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_Solid",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:50342,interoperability,platform,platforms,50342,"TVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:50354,interoperability,platform,platformnames,50354,"SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:575:309. chr20	10008221	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:50693,interoperability,platform,platforms,50693,"TKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:50705,interoperability,platform,platformnames,50705,"GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:568:393. chr20	10008458	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:51064,interoperability,platform,platforms,51064,"0xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:51076,interoperability,platform,platformnames,51076,"SeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:538:335. chr20	10008742	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:51467,interoperability,platform,platforms,51467,"SeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:51479,interoperability,platform,platformnames,51479,"CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:487:1181. chr20	10008921	.	C	CA	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,Sol",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:51867,interoperability,platform,platforms,51867,"me,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:51879,interoperability,platform,platformnames,51879,"0bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	0/1:.:333:261. chr20	10009227	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC;datasetsmissingcall=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:52267,interoperability,platform,platforms,52267,"call=IonExome,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_low",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:52279,interoperability,platform,platformnames,52279,"SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	0/1:.:695:784. chr20	10009246	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:52638,interoperability,platform,platforms,52638,"SE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExome",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:52650,interoperability,platform,platformnames,52650,"asetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:667:338. chr20	10009400	.	T	A	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:53038,interoperability,platform,platforms,53038,"SE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:53050,interoperability,platform,platformnames,53050,"asetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:700:352. chr20	10009512	.	C	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:53409,interoperability,platform,platforms,53409,"iSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:53421,interoperability,platform,platformnames,53421,",CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:691:397. chr20	10009719	.	A	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_So",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:53787,interoperability,platform,platforms,53787,"00xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:53799,interoperability,platform,platformnames,53799,"al,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidSE75GATKHC_filt	GT:PS:DP:GQ	1/1:.:576:327. chr20	10009795	.	A	G	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:54178,interoperability,platform,platforms,54178,"Gnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datase",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:54190,interoperability,platform,platformnames,54190,"tsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:496:309. chr20	10009871	.	A	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:54534,interoperability,platform,platforms,54534,"K;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:54546,interoperability,platform,platformnames,54546,"ingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1|0:.:333:160. chr20	10010393	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,Soli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:54956,interoperability,platform,platforms,54956,"TK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:54968,interoperability,platform,platformnames,54968,"lidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:850:951. chr20	10010536	.	G	GA	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;data",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:55378,interoperability,platform,platforms,55378,"S_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:55390,interoperability,platform,platformnames,55390,"cov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:683:160. chr20	10010766	.	T	G	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:55750,interoperability,platform,platforms,55750,"datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:55762,interoperability,platform,platformnames,55762,"gcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:865:464. chr20	10010832	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:56173,interoperability,platform,platforms,56173,"atasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:56185,interoperability,platform,platformnames,56185,"call=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:819:454. chr20	10011075	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=3;datasetnames=HiSeqPE300x,CGnormal,SolidSE75bp;callsets=4;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:56529,interoperability,platform,platforms,56529,"xGATK,CGnormal,SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:56541,interoperability,platform,platformnames,56541,",SolidSE75GATKHC;datasetsmissingcall=IonExome,SolidPE50x50bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:855:1010. chr20	10011309	.	T	C	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:56919,interoperability,platform,platforms,56919,"TK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExom",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:56931,interoperability,platform,platformnames,56931,"lidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:756:423. chr20	10011517	.	GA	G	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:57342,interoperability,platform,platforms,57342,"dPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:57354,interoperability,platform,platformnames,57354,"idSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	0/1:.:575:160. chr20	10011666	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:670:472. chr20	10011939	.	C	T	50	PASS	platforms=3;platformnames=Illumina,CG,Solid;datasets=4;datasetnames=HiSeqPE300x,CGnormal,SolidPE50x50bp,SolidSE75bp;callsets=5;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal,SolidPE50x50GATKHC,SolidSE75GATKHC;datasetsmissingcall=IonExome;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_SolidPE50x50GATKHC_filt	GT:PS:DP:GQ	1/1:.:718:455. chr20	10012021	.	CA	C	50	PASS	platforms=1;platformnames=Illumina;datasets=1;datasetnames=HiSeqPE300x;callsets=2;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK;datasetsmissingcall=CGnormal,IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_CGnormal_lowcov,CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov	GT:PS:DP:GQ	1/1:.:624:156. chr20	10012362	.	G	T	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov;filt=CS_CGnormal_filt	GT:PS:DP:GQ	1/1:.:538:202. chr20	10012384	.	T	C	50	PASS	platforms=2;platformnames=Illumina,CG;datasets=2;datasetnames=HiSeqPE300x,CGnormal;callsets=3;callsetnames=HiSeqPE300xfreebayes,HiSeqPE300xGATK,CGnormal;datasetsmissingcall=IonExome,SolidPE50x50bp,SolidSE75bp;lowcov=CS_IonExomeTVC_lowcov,CS_SolidPE50x50GATKHC_lowcov,CS_SolidSE75GATKHC_lowcov",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
