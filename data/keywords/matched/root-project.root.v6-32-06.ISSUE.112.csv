id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/16179:47,availability,operat,operators,47,[hist] Add some `const` keywords to arithmetic operators; Closes https://its.cern.ch/jira/browse/ROOT-9297.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16179
https://github.com/root-project/root/pull/16179:58,usability,Close,Closes,58,[hist] Add some `const` keywords to arithmetic operators; Closes https://its.cern.ch/jira/browse/ROOT-9297.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16179
https://github.com/root-project/root/pull/16180:42,deployability,API,API,42,[PyROOT] Add Sequence_Check to the public API; This PR fixes https://github.com/root-project/root/issues/15161. Applying the following commit from CPyCppyy upstream:. https://github.com/wlav/CPyCppyy/commit/a02ceeb. Adds a Sequence_Check which does not pass objects not supporting indexing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16180
https://github.com/root-project/root/pull/16180:35,integrability,pub,public,35,[PyROOT] Add Sequence_Check to the public API; This PR fixes https://github.com/root-project/root/issues/15161. Applying the following commit from CPyCppyy upstream:. https://github.com/wlav/CPyCppyy/commit/a02ceeb. Adds a Sequence_Check which does not pass objects not supporting indexing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16180
https://github.com/root-project/root/pull/16180:42,integrability,API,API,42,[PyROOT] Add Sequence_Check to the public API; This PR fixes https://github.com/root-project/root/issues/15161. Applying the following commit from CPyCppyy upstream:. https://github.com/wlav/CPyCppyy/commit/a02ceeb. Adds a Sequence_Check which does not pass objects not supporting indexing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16180
https://github.com/root-project/root/pull/16180:42,interoperability,API,API,42,[PyROOT] Add Sequence_Check to the public API; This PR fixes https://github.com/root-project/root/issues/15161. Applying the following commit from CPyCppyy upstream:. https://github.com/wlav/CPyCppyy/commit/a02ceeb. Adds a Sequence_Check which does not pass objects not supporting indexing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16180
https://github.com/root-project/root/pull/16180:244,reliability,doe,does,244,[PyROOT] Add Sequence_Check to the public API; This PR fixes https://github.com/root-project/root/issues/15161. Applying the following commit from CPyCppyy upstream:. https://github.com/wlav/CPyCppyy/commit/a02ceeb. Adds a Sequence_Check which does not pass objects not supporting indexing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16180
https://github.com/root-project/root/pull/16180:270,usability,support,supporting,270,[PyROOT] Add Sequence_Check to the public API; This PR fixes https://github.com/root-project/root/issues/15161. Applying the following commit from CPyCppyy upstream:. https://github.com/wlav/CPyCppyy/commit/a02ceeb. Adds a Sequence_Check which does not pass objects not supporting indexing.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16180
https://github.com/root-project/root/issues/16182:968,availability,Operat,Operating,968,missing include in root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The file . ```root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx```. is missing a. ```#include <iomanip>```. ### Reproducer. checkout out master on latest archlinux and attempt to compile with. ```. cmake ../src -DCMAKE_BUILD_TYPE=RelWithDebInfo -Droofit=on -Dmysql=off -Dpgsql=off -Droostats=on -Dfortran=off -Dhistfactory=on -Dtmva=on -Droottest=on -Droot7=on -Dtesting=on -Dbuiltin_llvm=on -Dbuiltin_tbb=off -Dbuiltin_nlohmannjson=on -DCMAKE_CXX_STANDARD=17 -DPYTHON_EXECUTABLE=$(which python) -Dfail-on-missing=on -Doracle=off -Dpythia6=off -Dpythia8=off -Dgfal=off -Dvdt=off -Ddavix=off -Droofit_hs3_yml=ON -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON -DxRooFit=on. #-DCMAKE_PREFIX_PATH=/home/cburgard/Physics/root/zmq . ```. ### ROOT version. master. ### Installation method. source. ### Operating system. archlinux. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16182
https://github.com/root-project/root/issues/16182:914,deployability,version,version,914,missing include in root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The file . ```root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx```. is missing a. ```#include <iomanip>```. ### Reproducer. checkout out master on latest archlinux and attempt to compile with. ```. cmake ../src -DCMAKE_BUILD_TYPE=RelWithDebInfo -Droofit=on -Dmysql=off -Dpgsql=off -Droostats=on -Dfortran=off -Dhistfactory=on -Dtmva=on -Droottest=on -Droot7=on -Dtesting=on -Dbuiltin_llvm=on -Dbuiltin_tbb=off -Dbuiltin_nlohmannjson=on -DCMAKE_CXX_STANDARD=17 -DPYTHON_EXECUTABLE=$(which python) -Dfail-on-missing=on -Doracle=off -Dpythia6=off -Dpythia8=off -Dgfal=off -Dvdt=off -Ddavix=off -Droofit_hs3_yml=ON -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON -DxRooFit=on. #-DCMAKE_PREFIX_PATH=/home/cburgard/Physics/root/zmq . ```. ### ROOT version. master. ### Installation method. source. ### Operating system. archlinux. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16182
https://github.com/root-project/root/issues/16182:935,deployability,Instal,Installation,935,missing include in root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The file . ```root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx```. is missing a. ```#include <iomanip>```. ### Reproducer. checkout out master on latest archlinux and attempt to compile with. ```. cmake ../src -DCMAKE_BUILD_TYPE=RelWithDebInfo -Droofit=on -Dmysql=off -Dpgsql=off -Droostats=on -Dfortran=off -Dhistfactory=on -Dtmva=on -Droottest=on -Droot7=on -Dtesting=on -Dbuiltin_llvm=on -Dbuiltin_tbb=off -Dbuiltin_nlohmannjson=on -DCMAKE_CXX_STANDARD=17 -DPYTHON_EXECUTABLE=$(which python) -Dfail-on-missing=on -Doracle=off -Dpythia6=off -Dpythia8=off -Dgfal=off -Dvdt=off -Ddavix=off -Droofit_hs3_yml=ON -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON -DxRooFit=on. #-DCMAKE_PREFIX_PATH=/home/cburgard/Physics/root/zmq . ```. ### ROOT version. master. ### Installation method. source. ### Operating system. archlinux. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16182
https://github.com/root-project/root/issues/16182:914,integrability,version,version,914,missing include in root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The file . ```root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx```. is missing a. ```#include <iomanip>```. ### Reproducer. checkout out master on latest archlinux and attempt to compile with. ```. cmake ../src -DCMAKE_BUILD_TYPE=RelWithDebInfo -Droofit=on -Dmysql=off -Dpgsql=off -Droostats=on -Dfortran=off -Dhistfactory=on -Dtmva=on -Droottest=on -Droot7=on -Dtesting=on -Dbuiltin_llvm=on -Dbuiltin_tbb=off -Dbuiltin_nlohmannjson=on -DCMAKE_CXX_STANDARD=17 -DPYTHON_EXECUTABLE=$(which python) -Dfail-on-missing=on -Doracle=off -Dpythia6=off -Dpythia8=off -Dgfal=off -Dvdt=off -Ddavix=off -Droofit_hs3_yml=ON -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON -DxRooFit=on. #-DCMAKE_PREFIX_PATH=/home/cburgard/Physics/root/zmq . ```. ### ROOT version. master. ### Installation method. source. ### Operating system. archlinux. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16182
https://github.com/root-project/root/issues/16182:914,modifiability,version,version,914,missing include in root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The file . ```root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx```. is missing a. ```#include <iomanip>```. ### Reproducer. checkout out master on latest archlinux and attempt to compile with. ```. cmake ../src -DCMAKE_BUILD_TYPE=RelWithDebInfo -Droofit=on -Dmysql=off -Dpgsql=off -Droostats=on -Dfortran=off -Dhistfactory=on -Dtmva=on -Droottest=on -Droot7=on -Dtesting=on -Dbuiltin_llvm=on -Dbuiltin_tbb=off -Dbuiltin_nlohmannjson=on -DCMAKE_CXX_STANDARD=17 -DPYTHON_EXECUTABLE=$(which python) -Dfail-on-missing=on -Doracle=off -Dpythia6=off -Dpythia8=off -Dgfal=off -Dvdt=off -Ddavix=off -Droofit_hs3_yml=ON -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON -DxRooFit=on. #-DCMAKE_PREFIX_PATH=/home/cburgard/Physics/root/zmq . ```. ### ROOT version. master. ### Installation method. source. ### Operating system. archlinux. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16182
https://github.com/root-project/root/issues/16182:1012,testability,context,context,1012,missing include in root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The file . ```root/roofitstats/vectorisedPDFs/VectorisedPDFTests.cxx```. is missing a. ```#include <iomanip>```. ### Reproducer. checkout out master on latest archlinux and attempt to compile with. ```. cmake ../src -DCMAKE_BUILD_TYPE=RelWithDebInfo -Droofit=on -Dmysql=off -Dpgsql=off -Droostats=on -Dfortran=off -Dhistfactory=on -Dtmva=on -Droottest=on -Droot7=on -Dtesting=on -Dbuiltin_llvm=on -Dbuiltin_tbb=off -Dbuiltin_nlohmannjson=on -DCMAKE_CXX_STANDARD=17 -DPYTHON_EXECUTABLE=$(which python) -Dfail-on-missing=on -Doracle=off -Dpythia6=off -Dpythia8=off -Dgfal=off -Dvdt=off -Ddavix=off -Droofit_hs3_yml=ON -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON -DxRooFit=on. #-DCMAKE_PREFIX_PATH=/home/cburgard/Physics/root/zmq . ```. ### ROOT version. master. ### Installation method. source. ### Operating system. archlinux. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16182
https://github.com/root-project/root/pull/16183:48,deployability,API,API,48,[v632][PyROOT] add Sequence_Check to the public API; Backporting fix from https://github.com/root-project/root/pull/16180. Applies the following commit from CPyCppyy upstream: wlav/CPyCppyy@a02ceeb. Closes #15161.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16183
https://github.com/root-project/root/pull/16183:41,integrability,pub,public,41,[v632][PyROOT] add Sequence_Check to the public API; Backporting fix from https://github.com/root-project/root/pull/16180. Applies the following commit from CPyCppyy upstream: wlav/CPyCppyy@a02ceeb. Closes #15161.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16183
https://github.com/root-project/root/pull/16183:48,integrability,API,API,48,[v632][PyROOT] add Sequence_Check to the public API; Backporting fix from https://github.com/root-project/root/pull/16180. Applies the following commit from CPyCppyy upstream: wlav/CPyCppyy@a02ceeb. Closes #15161.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16183
https://github.com/root-project/root/pull/16183:48,interoperability,API,API,48,[v632][PyROOT] add Sequence_Check to the public API; Backporting fix from https://github.com/root-project/root/pull/16180. Applies the following commit from CPyCppyy upstream: wlav/CPyCppyy@a02ceeb. Closes #15161.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16183
https://github.com/root-project/root/pull/16183:199,usability,Close,Closes,199,[v632][PyROOT] add Sequence_Check to the public API; Backporting fix from https://github.com/root-project/root/pull/16180. Applies the following commit from CPyCppyy upstream: wlav/CPyCppyy@a02ceeb. Closes #15161.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16183
https://github.com/root-project/root/issues/16184:1311,availability,Operat,Operating,1311,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:593,deployability,fail,fails,593,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1235,deployability,version,version,1235,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1272,deployability,Instal,Installation,1272,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:803,energy efficiency,load,loads,803,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1235,integrability,version,version,1235,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:393,interoperability,distribut,distributed,393,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1235,modifiability,version,version,1235,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:29,performance,I/O,I/O,29,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:803,performance,load,loads,803,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:593,reliability,fail,fails,593,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1351,testability,context,context,1351,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:990,usability,Statu,Status,990,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1007,usability,Statu,Status,1007,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1086,usability,Statu,Status,1086,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1103,usability,Statu,Status,1103,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1191,usability,Statu,Status,1191,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/issues/16184:1210,usability,Statu,Status,1210,"Serialisation (and therefore I/O) issues with TF1 and TFitResultPtr ; Original title: ""TF1 and TFitResultPtr do not serialise correctly pickle, and this is an issue with Python multiprocessing"". ### Check duplicate issues. - [X] Checked for duplicates. ### Description. TF1 and TFitResultPtr do not serialise correctly with pickle. This causes issues with multiprocessing in python as well as distributed execution, e.g. with DistRDF. ### Reproducer. One can see with the reproducer below that:. - The fit succeeds and the result pointer is sane if nothing is pickled and depickled. - The fit fails if the function is pickled and depickled. - The fit result pointer is not sane any more if pickled and then depickled. ```python. import ROOT. import pickle. def SerialiseDeserialise(obj):. return pickle.loads(pickle.dumps(obj)). h = ROOT.TH1F(""myHist"", ""myTitle"", 64, -4, 4). h.FillRandom(""gaus""). f1 = ROOT.TF1(""f1"", ""gaus""). f1_d = SerialiseDeserialise(f1). res = h.Fit(f1, ""S""). print (""Status is "", res.Status()). # Check fit with de-serialised TF1. res = h.Fit(f1_d, ""S""). print (""Status is "", res.Status()). # Check de-serialised result ptr. res_d = SerialiseDeserialise(res). print (""Status is "", res_d.Status()). ```. ### ROOT version. master (I suspect all). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16184
https://github.com/root-project/root/pull/16186:15,interoperability,format,format,15,[ntuple] clang-format some files; In preparation of some changes to those files.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16186
https://github.com/root-project/root/pull/16187:11,performance,I/O,I/O,11,"[hist] Fix I/O of TFormula nd TFitResultPtr; Fix the I/O of predefined functions (gaus, expo, etc..) where the data member fNumber was not saved in the file and could not be recomputed afterwards. . Fix also the I/O of the TFitResultPtr class . This PR fixes #16184.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16187
https://github.com/root-project/root/pull/16187:53,performance,I/O,I/O,53,"[hist] Fix I/O of TFormula nd TFitResultPtr; Fix the I/O of predefined functions (gaus, expo, etc..) where the data member fNumber was not saved in the file and could not be recomputed afterwards. . Fix also the I/O of the TFitResultPtr class . This PR fixes #16184.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16187
https://github.com/root-project/root/pull/16187:212,performance,I/O,I/O,212,"[hist] Fix I/O of TFormula nd TFitResultPtr; Fix the I/O of predefined functions (gaus, expo, etc..) where the data member fNumber was not saved in the file and could not be recomputed afterwards. . Fix also the I/O of the TFitResultPtr class . This PR fixes #16184.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16187
https://github.com/root-project/root/pull/16188:121,interoperability,platform,platforms,121,TMapFileTest: properly disable on Mac 12 and older.; The previous cmake boolean expression was disabling the test on all platforms except on Mac 13+. The issue is that in cmake `NOT MACOSX_VERSION VERSION_LESS 13.00` is false if MACOSX_VERSION is not defined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16188
https://github.com/root-project/root/pull/16188:109,safety,test,test,109,TMapFileTest: properly disable on Mac 12 and older.; The previous cmake boolean expression was disabling the test on all platforms except on Mac 13+. The issue is that in cmake `NOT MACOSX_VERSION VERSION_LESS 13.00` is false if MACOSX_VERSION is not defined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16188
https://github.com/root-project/root/pull/16188:131,safety,except,except,131,TMapFileTest: properly disable on Mac 12 and older.; The previous cmake boolean expression was disabling the test on all platforms except on Mac 13+. The issue is that in cmake `NOT MACOSX_VERSION VERSION_LESS 13.00` is false if MACOSX_VERSION is not defined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16188
https://github.com/root-project/root/pull/16188:109,testability,test,test,109,TMapFileTest: properly disable on Mac 12 and older.; The previous cmake boolean expression was disabling the test on all platforms except on Mac 13+. The issue is that in cmake `NOT MACOSX_VERSION VERSION_LESS 13.00` is false if MACOSX_VERSION is not defined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16188
https://github.com/root-project/root/issues/16189:2356,availability,Operat,Operating,2356,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:418,deployability,configurat,configuration,418,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1848,deployability,version,version,1848,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:2324,deployability,Instal,Installation,2324,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:418,integrability,configur,configuration,418,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1848,integrability,version,version,1848,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:359,interoperability,compatib,compatibility,359,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:418,modifiability,configur,configuration,418,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1848,modifiability,version,version,1848,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:32,reliability,doe,does,32,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:563,safety,Test,TestBit,563,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:668,safety,Test,TestBit,668,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:783,safety,Test,TestBit,783,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:897,safety,Test,TestBit,897,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1173,safety,Test,TestBit,1173,"Compatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1366,safety,Test,TestBit,1366,"ty mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating syst",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1558,safety,Test,TestBit,1558,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1753,safety,Test,TestBit,1753,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:418,security,configur,configuration,418,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:2003,security,Team,Team,2003,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:563,testability,Test,TestBit,563,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:668,testability,Test,TestBit,668,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:783,testability,Test,TestBit,783,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:897,testability,Test,TestBit,897,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1173,testability,Test,TestBit,1173,"Compatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1366,testability,Test,TestBit,1366,"ty mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating syst",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1558,testability,Test,TestBit,1558,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1753,testability,Test,TestBit,1753,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:2404,testability,context,context,2404,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:255,usability,behavi,behavior,255,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:611,usability,Close,Close,611,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:716,usability,Close,Close,716,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:832,usability,Close,Close,832,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:946,usability,Close,Close,946,"TFile::k630forwardCompatibility does not apply to new files correctly; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When setting `TFile.v630forwardCompatibility` to true in `/etc/root/system.rootrc`, there is still confusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1244,usability,Close,Close,1244,"nfusing behavior and new files can be written without compability. In particular, *new* files are not opened in compatibility mode (largely limiting the usefulness of the configuration flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1436,usability,Close,Close,1436,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1630,usability,Close,Close,1630,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:1825,usability,Close,Close,1825,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16189:2186,usability,help,help,2186,"ation flag). ### Reproducer. ```. gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). TFile file1 = TFile(""file1.root"",""CREATE""). file1.TestBit(TFile::k630forwardCompatibility). file1.Close(). TFile file2 = TFile(""file1.root"",""READ""). file2.TestBit(TFile::k630forwardCompatibility). file2.Close(). TFile* file3 = TFile::Open(""file3.root"",""CREATE""). file3->TestBit(TFile::k630forwardCompatibility). file3->Close(). TFile* file4 = TFile::Open(""file3.root"",""READ""). file4->TestBit(TFile::k630forwardCompatibility). file4->Close(). ```. produces. ```. $ root -l . root [0] gEnv->GetValue(""TFile.v630forwardCompatibility"", 0). (int) 1. root [1] . root [1] TFile file1 = TFile(""file1.root"",""CREATE""). (TFile &) Name: file1.root Title: . root [2] file1.TestBit(TFile::k630forwardCompatibility). (bool) false. root [3] file1.Close(). root [4] . root [4] TFile file2 = TFile(""file1.root"",""READ""). (TFile &) Name: file1.root Title: . root [5] file2.TestBit(TFile::k630forwardCompatibility). (bool) true. root [6] file2.Close(). root [7] . root [7] TFile* file3 = TFile::Open(""file3.root"",""CREATE""). (TFile *) 0x5650bd7edba0. root [8] file3->TestBit(TFile::k630forwardCompatibility). (bool) false. root [9] file3->Close(). root [10] . root [10] TFile* file4 = TFile::Open(""file3.root"",""READ""). (TFile *) 0x5650bd584570. root [11] file4->TestBit(TFile::k630forwardCompatibility). (bool) true. root [12] file4->Close(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.30/02 https://root.cern |. | (c) 1995-2023, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Aug 02 2024, 15:34:40 |. | From heads/master@tags/v6-30-02 |. | With g++ (Debian 12.2.0-14) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Spack. ### Operating system. Linux, debian. ### Additional context. Ref. #15006 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16189
https://github.com/root-project/root/issues/16190:2034,availability,Operat,Operating,2034,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:51,deployability,contain,contains,51,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:233,deployability,contain,contains,233,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:307,deployability,fail,fail,307,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:768,deployability,contain,contained,768,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1972,deployability,version,version,1972,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1994,deployability,Instal,Installation,1994,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:244,integrability,sub,subdirectory,244,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:290,integrability,sub,subdirectory,290,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1972,integrability,version,version,1972,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1391,modifiability,deco,deco,1391,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1442,modifiability,deco,deco,1442,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1972,modifiability,version,version,1972,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:307,reliability,fail,fail,307,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:382,testability,simpl,simple,382,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:2077,testability,context,context,2077,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:12,usability,behavi,behaviour,12,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:382,usability,simpl,simple,382,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:455,usability,help,helper,455,"TFileMerger behaviour when the directory structure contains repeated names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Instal",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1333,usability,Close,Close,1333,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/issues/16190:1623,usability,Close,Close,1623,"ues. - [X] Checked for duplicates. ### Description. For a ROOT file structured with top-level directories A and B, it seems that if B contains a subdirectory also named A the objects in that subdirectory may fail being properly merged when using **_hadd_**; instead the outcome is a simple copy of the object in the first source file... The getDirectory() helper in TFilerMerger::MergeOne() indeed apparently favours a lookup based on the directory name and not the full path, which may not always pick the intended directory:. https://github.com/root-project/root/blob/0aa2b6b8760b78dff2cffd873f955735fa1b0ef3/io/io/src/TFileMerger.cxx#L548. ### Reproducer. Save self-contained script below to mwe.cxx and execute with **_root -l -b -q mwe.cxx++_**. ```. #include ""TFileMerger.h"". #include ""TFile.h"". #include ""TH1D.h"". #include <iostream>. void createSrcFile(const char* name). {. TFile f(name, ""RECREATE"");. f.mkdir(""A"", """");. f.mkdir(""B/A"", """");. f.mkdir(""C/D/A"", """");. f.cd(""A"");. TH1D h1(""H1"", ""H1"", 1, 0., 1.);. h1.SetBinContent(1, 1);. h1.Write();. f.cd(""B/A"");. TH1D h2(""H2"", ""H2"", 1, 0., 1.);. h2.SetBinContent(1, 10);. h2.Write();. f.cd(""C/D/A"");. TH1D h3(""H3"", ""H3"", 1, 0., 1.);. h3.SetBinContent(1, 100);. h3.Write();. f.Close();. }. void check(const char* filename, const char* deco). {. TFile f(filename, ""READ"");. std::cout << deco. 	 << f.Get<TH1D>(""A/H1"")->GetBinContent(1). 	 << "" "". << f.Get<TH1D>(""B/A/H2"")->GetBinContent(1). 	 << "" "". 	 << f.Get<TH1D>(""C/D/A/H3"")->GetBinContent(1). 	 << std::endl;. f.Close();. }. void mwe(). {. createSrcFile(""src1.root"");. createSrcFile(""src2.root"");. TFileMerger mg;. mg.AddFile(""src1.root"", kFALSE);. mg.AddFile(""src2.root"", kFALSE);. mg.OutputFile(""dest.root"", kTRUE);. mg.Merge();. check(""src1.root"", "" "");. check(""src2.root"", ""+ "");. std::cout << ""------------\n"";. check(""dest.root"", ""= "");. }. ```. ### ROOT version. 6.32.02. ### Installation method. lxplus native. ### Operating system. RHEL 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16190
https://github.com/root-project/root/pull/16191:552,deployability,upgrad,upgrade,552,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16191:36,modifiability,extens,extensions,36,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16191:172,modifiability,extens,extensions,172,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16191:517,modifiability,extens,extensions,517,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16191:552,modifiability,upgrad,upgrade,552,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16191:320,security,control,controls,320,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16191:320,testability,control,controls,320,"[cling] Globally enable incremental extensions; We are relying on this since a while, for example for reemission of template symbols. At the moment, we get the incremental extensions because `Preprocessor::enableIncrementalProcessing()` turns them on internally, but this will change with LLVM 18 where this method only controls incremental processing of a single `Preprocessor` object. ---. This should mean no change in `master` with LLVM 16, but given that we already rely on this we should enable the incremental extensions properly outside of the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16191
https://github.com/root-project/root/pull/16192:763,deployability,updat,updated,763,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:164,modifiability,pac,packed,164,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:423,modifiability,variab,variable,423,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:556,performance,disk,disk,556,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:336,safety,valid,valid,336,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:733,safety,test,tested,733,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:763,safety,updat,updated,763,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:763,security,updat,updated,763,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:250,testability,simpl,simply,250,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:733,testability,test,tested,733,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:13,usability,support,support,13,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16192:250,usability,simpl,simply,250,"[ntuple] Add support for truncated single-precision float columns; # This Pull request:. adds a new ColumnType `Real32Trunc`, that stores a real value as a tightly-packed, IEEE-754 single precision float using less than 32 bits. The missing bits are simply truncated from the mantissa, causing the value to be rounded towards zero. The valid range of bit widths is `[10, 31]` inclusive. This is the first ColumnType with a variable bit width, therefore it requires some extra handling on the RColumnElement and RField side, but it uses a single type id on disk (`0x1D`) and a single enum value `EColumnType::kReal32Trunc`. The way to use it is by calling the new `SetTruncated(nBits)` method on `RField<float>`. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16192
https://github.com/root-project/root/pull/16194:0,deployability,Updat,Update,0,Update TProfile2D.cxx - copy all attributes of axis to projection histograms; these two lines will ensure any bin labels are propagated to projection histograms.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16194
https://github.com/root-project/root/pull/16194:0,safety,Updat,Update,0,Update TProfile2D.cxx - copy all attributes of axis to projection histograms; these two lines will ensure any bin labels are propagated to projection histograms.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16194
https://github.com/root-project/root/pull/16194:0,security,Updat,Update,0,Update TProfile2D.cxx - copy all attributes of axis to projection histograms; these two lines will ensure any bin labels are propagated to projection histograms.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16194
https://github.com/root-project/root/pull/16196:0,deployability,Updat,Update,0,"Update IncrementalCUDADeviceCompiler.cpp - change string comparison to exact match for ""-include""; Modified the loop to use exact string comparison `(s == ""-include"")` instead of checking if the string starts with ""-include"" `(s.find(""-include"") == 0)` to ensure only exact matches are considered. ### Explanation. - `(s.find(""-include"")`: Adds `s` to `argv` if `s` starts with `""-include""`. - `(s == ""-include"")`: Adds `s` to `argv` only if `s` is exactly `""-include""`. The first snippet is more inclusive, as it will match any string that begins with `""-include""`, such as `""-include-pch""` or something else starting with `""-include""`, while the second snippet will only match the exact string `""-include""`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16196
https://github.com/root-project/root/pull/16196:0,safety,Updat,Update,0,"Update IncrementalCUDADeviceCompiler.cpp - change string comparison to exact match for ""-include""; Modified the loop to use exact string comparison `(s == ""-include"")` instead of checking if the string starts with ""-include"" `(s.find(""-include"") == 0)` to ensure only exact matches are considered. ### Explanation. - `(s.find(""-include"")`: Adds `s` to `argv` if `s` starts with `""-include""`. - `(s == ""-include"")`: Adds `s` to `argv` only if `s` is exactly `""-include""`. The first snippet is more inclusive, as it will match any string that begins with `""-include""`, such as `""-include-pch""` or something else starting with `""-include""`, while the second snippet will only match the exact string `""-include""`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16196
https://github.com/root-project/root/pull/16196:0,security,Updat,Update,0,"Update IncrementalCUDADeviceCompiler.cpp - change string comparison to exact match for ""-include""; Modified the loop to use exact string comparison `(s == ""-include"")` instead of checking if the string starts with ""-include"" `(s.find(""-include"") == 0)` to ensure only exact matches are considered. ### Explanation. - `(s.find(""-include"")`: Adds `s` to `argv` if `s` starts with `""-include""`. - `(s == ""-include"")`: Adds `s` to `argv` only if `s` is exactly `""-include""`. The first snippet is more inclusive, as it will match any string that begins with `""-include""`, such as `""-include-pch""` or something else starting with `""-include""`, while the second snippet will only match the exact string `""-include""`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16196
https://github.com/root-project/root/pull/16196:99,security,Modif,Modified,99,"Update IncrementalCUDADeviceCompiler.cpp - change string comparison to exact match for ""-include""; Modified the loop to use exact string comparison `(s == ""-include"")` instead of checking if the string starts with ""-include"" `(s.find(""-include"") == 0)` to ensure only exact matches are considered. ### Explanation. - `(s.find(""-include"")`: Adds `s` to `argv` if `s` starts with `""-include""`. - `(s == ""-include"")`: Adds `s` to `argv` only if `s` is exactly `""-include""`. The first snippet is more inclusive, as it will match any string that begins with `""-include""`, such as `""-include-pch""` or something else starting with `""-include""`, while the second snippet will only match the exact string `""-include""`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16196
https://github.com/root-project/root/pull/16197:178,deployability,fail,failing,178,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:248,deployability,fail,failed,248,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:9,performance,Perform,Perform,9,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:178,reliability,fail,failing,178,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:248,reliability,fail,failed,248,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:137,safety,test,tested,137,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:137,testability,test,tested,137,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16197:9,usability,Perform,Perform,9,[PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16197
https://github.com/root-project/root/pull/16198:192,deployability,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:192,integrability,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:192,interoperability,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:192,modifiability,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:68,performance,memor,memory,68,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:192,reliability,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:59,safety,avoid,avoiding,59,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:192,security,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:192,testability,integr,integration,192,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:68,usability,memor,memory,68,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16198:167,usability,minim,minimally,167,[TTreeReader] Properly cleanup non-owned chains; therewith avoiding memory hogging because of the attached TTreeChaches. This code has been written by David Smith and minimally edited for its integration in root. See sister PR in roottest: https://github.com/root-project/roottest/pull/1161. This PR fixes [ROOT-6286](https://its.cern.ch/jira/browse/ROOT-6286).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16198
https://github.com/root-project/root/pull/16199:185,deployability,fail,failing,185,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:255,deployability,fail,failed,255,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:16,performance,Perform,Perform,16,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:185,reliability,fail,failing,185,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:255,reliability,fail,failed,255,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:144,safety,test,tested,144,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:144,testability,test,tested,144,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16199:16,usability,Perform,Perform,16,[v632] [PyROOT] Perform function-style casts when returning multi-keyword types; Fixes https://github.com/root-project/root/issues/15315. - [X] tested changes locally. This enables the failing example in the manual with `ROOT.Math.IMultiGenFunction` that failed due to an invalid zero initialization of an `unsigned int`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16199
https://github.com/root-project/root/pull/16200:93,deployability,releas,release,93,"[PyROOT] Avoid using deprecated `numpy._float`; The `np.float_` was removed in the NumPy 2.0 release. One should use `np.float64` instead, which is already in the same dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16200
https://github.com/root-project/root/pull/16200:9,safety,Avoid,Avoid,9,"[PyROOT] Avoid using deprecated `numpy._float`; The `np.float_` was removed in the NumPy 2.0 release. One should use `np.float64` instead, which is already in the same dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16200
https://github.com/root-project/root/issues/16201:622,availability,error,error-capturing,622,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:837,availability,error,errors,837,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:35,deployability,version,version,35,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:587,deployability,API,API,587,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:597,deployability,depend,depending,597,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:707,deployability,releas,release,707,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:899,deployability,instal,install,899,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:54,energy efficiency,current,currently,54,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1218,energy efficiency,current,current,1218,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:35,integrability,version,version,35,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:587,integrability,API,API,587,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:597,integrability,depend,depending,597,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:587,interoperability,API,API,587,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:35,modifiability,version,version,35,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:577,modifiability,extens,extension,577,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:597,modifiability,depend,depending,597,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:622,performance,error,error-capturing,622,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:837,performance,error,errors,837,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1179,reliability,doe,doesn,1179,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:248,safety,test,test,248,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:402,safety,Test,TestClasNumba,402,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:597,safety,depend,depending,597,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:622,safety,error,error-capturing,622,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:837,safety,error,errors,837,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:845,safety,Except,Exception,845,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1287,safety,test,test,1287,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:248,testability,test,test,248,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:402,testability,Test,TestClasNumba,402,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:597,testability,depend,depending,597,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1287,testability,test,test,1287,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:9,usability,Support,Support,9,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:70,usability,support,support,70,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:622,usability,error,error-capturing,622,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:837,usability,error,errors,837,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1125,usability,Support,Supporting,1125,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1187,usability,support,support,1187,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/issues/16201:1292,usability,support,support,1292,"[PyROOT] Support most recent numba version 0.60.0; We currently don't support numba 0.60.0 yet:. https://github.com/root-project/root/blob/master/requirements.txt#L17. One can see the problem when going into `roottest/python/numba` and running the test there:. ```bash. python PyROOT_numbatests.py. ```. Output with ROOT master and numba 0.59, where it's only a warning:. ```txt. PyROOT_numbatests.py::TestClasNumba::test03_inheritance. /home/rembserj/spaces/master/root/src/root/roottest/python/numba/PyROOT_numbatests.py:107: NumbaPendingDeprecationWarning: Code using Numba extension API maybe depending on 'old_style' error-capturing, which is deprecated and will be replaced by 'new_style' in a future release. See details at https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors. Exception origin:. File ""/home/rembserj/spaces/master/install/lib/root/cppyy/numba_ext.py"", line 349, in generic_resolve. f = typ._scope.__dict__[attr]. ~~~~~~~~~~~~~~~~~~~^^^^^^. return obj.get_one(). -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html. ```. Supporting numba 0.60.0 would be nice, because 0.59.0 doesn't support NumPy 2 yet. Thus, our current environment falls back to NumPy 1 and we are lacking NumPy 2 test support.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16201
https://github.com/root-project/root/pull/16202:20,safety,compl,complain,20,"TProtoClass: do not complain innards of transients.; In `GetRealData`, do not complain about missing information about data members that are directly or indirectly within a transient member of the top level class. This solves the underlying problem from https://github.com/root-project/root/pull/15733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16202
https://github.com/root-project/root/pull/16202:78,safety,compl,complain,78,"TProtoClass: do not complain innards of transients.; In `GetRealData`, do not complain about missing information about data members that are directly or indirectly within a transient member of the top level class. This solves the underlying problem from https://github.com/root-project/root/pull/15733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16202
https://github.com/root-project/root/pull/16202:20,security,compl,complain,20,"TProtoClass: do not complain innards of transients.; In `GetRealData`, do not complain about missing information about data members that are directly or indirectly within a transient member of the top level class. This solves the underlying problem from https://github.com/root-project/root/pull/15733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16202
https://github.com/root-project/root/pull/16202:78,security,compl,complain,78,"TProtoClass: do not complain innards of transients.; In `GetRealData`, do not complain about missing information about data members that are directly or indirectly within a transient member of the top level class. This solves the underlying problem from https://github.com/root-project/root/pull/15733.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16202
https://github.com/root-project/root/pull/16203:59,energy efficiency,reduc,reducing,59,"[RF] RooFit code improvements; Improve RooFit code, mostly reducing code duplication in concatenating lists of names with comma delimiter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16203
https://github.com/root-project/root/pull/16204:155,availability,Sli,Slice,155,"[RF] Remove `RooAbsReal::plotSliceOn()`; The `RooAbsReal::plotSliceOn()` function that was deprecated since at least ROOT 6 was removed. Use `plotOn(frame,Slice(...))` instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16204
https://github.com/root-project/root/pull/16204:155,reliability,Sli,Slice,155,"[RF] Remove `RooAbsReal::plotSliceOn()`; The `RooAbsReal::plotSliceOn()` function that was deprecated since at least ROOT 6 was removed. Use `plotOn(frame,Slice(...))` instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16204
https://github.com/root-project/root/pull/16205:363,availability,echo,echo,363,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:497,availability,down,downsides,497,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:660,deployability,updat,updated,660,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:1,energy efficiency,core,core,1,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:145,energy efficiency,Current,Currently,145,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:44,reliability,doe,does,44,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:563,safety,test,tests,563,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:630,safety,test,tested,630,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:660,safety,updat,updated,660,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:660,security,updat,updated,660,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:399,testability,simpl,simply,399,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:563,testability,test,tests,563,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:630,testability,test,tested,630,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:167,usability,behavi,behaviour,167,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:332,usability,help,help,332,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16205:399,usability,simpl,simply,399,"[core] Return 2 if root macro.C and macro.C does not exist as it is done for the Python interpreter; # This Pull request:. ## Changes or fixes:. Currently this is the behaviour. ```. ~> root -b -q -l NotExistingFile.C. Warning in <TApplication::GetOptions>: macro pippo.C not found. root: unrecognized option 'pippo.C'. Try 'root --help' for more information. ~> echo $? 0. ```. the root executable simply warns about the file not existing but returns 0, as everything went well. This has several downsides, including not protecting us from our typos when adding tests to the suite (see original JIRA issue). ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes [ROOT-9365](https://its.cern.ch/jira/browse/ROOT-9395).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16205
https://github.com/root-project/root/pull/16206:42,interoperability,compatib,compatibility,42,[v632] Backport RooFit bugfix and NumPy 2 compatibility fix; Backport RooFit bugfix and NumPy 2 compatibility fix.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16206
https://github.com/root-project/root/pull/16206:96,interoperability,compatib,compatibility,96,[v632] Backport RooFit bugfix and NumPy 2 compatibility fix; Backport RooFit bugfix and NumPy 2 compatibility fix.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16206
https://github.com/root-project/root/pull/16207:42,interoperability,compatib,compatibility,42,[v630] Backport RooFit bugfix and NumPy 2 compatibility fix; Backport RooFit bugfix and NumPy 2 compatibility fix.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16207
https://github.com/root-project/root/pull/16207:96,interoperability,compatib,compatibility,96,[v630] Backport RooFit bugfix and NumPy 2 compatibility fix; Backport RooFit bugfix and NumPy 2 compatibility fix.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16207
https://github.com/root-project/root/pull/16208:216,availability,error,errors,216,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:275,deployability,updat,updated,275,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:1,energy efficiency,Core,Core,1,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:216,performance,error,errors,216,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:216,safety,error,errors,216,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:245,safety,test,tested,245,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:275,safety,updat,updated,275,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:519,safety,test,test,519,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:275,security,updat,updated,275,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:245,testability,test,tested,245,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:519,testability,test,test,519,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:652,testability,simpl,simply,652,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:216,usability,error,errors,216,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16208:652,usability,simpl,simply,652,"[Core] ACLiC: set default verbosity level for rootcling; # This Pull request:. ## Changes or fixes:. Sets the verbosity level of rootcling in ACLiC to the default, therewith printing also warnings and not only fatal errors. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes [ROOT-10975](https://its.cern.ch/jira/browse/ROOT-10975). Linked roottest PR https://github.com/root-project/roottest/pull/1168 and https://github.com/root-project/roottest/pull/1169, that fixes a test which becomes broken once the verbosity is increased because some unused rules start to generate warnings. The rules are unused simply because the name of some template instantiations are not spelled correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16208
https://github.com/root-project/root/pull/16209:313,availability,error,error,313,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:46,deployability,version,version,46,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:58,deployability,upgrad,upgrades,58,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:157,deployability,version,versions,157,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:301,deployability,updat,updates,301,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:381,deployability,version,version,381,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:440,deployability,upgrad,upgrades,440,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:46,integrability,version,version,46,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:157,integrability,version,versions,157,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:381,integrability,version,version,381,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:359,interoperability,compatib,compatible,359,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:46,modifiability,version,version,46,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:58,modifiability,upgrad,upgrades,58,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:157,modifiability,version,versions,157,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:381,modifiability,version,version,381,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:440,modifiability,upgrad,upgrades,440,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:35,performance,lock,lock,35,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:313,performance,error,error,313,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:404,performance,lock,locked,404,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:461,performance,time,time,461,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:301,safety,updat,updates,301,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:313,safety,error,error,313,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:338,safety,test,test,338,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:427,safety,prevent,prevent,427,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:473,safety,test,tested,473,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:35,security,lock,lock,35,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:301,security,updat,updates,301,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:404,security,lock,locked,404,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:427,security,preven,prevent,427,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:338,testability,test,test,338,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:473,testability,test,tested,473,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:193,usability,support,support,193,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/pull/16209:313,usability,error,error,313,[ci] Revert Numba restrictions and lock NumPy version for upgrades; This reverts commit d6b623fff5a6d47ae66ec6db09dad26e987deb4e to no longer restrict numba versions to <0.6 which also unlocks support for numpy 2.0. The corresponding PR in rootest (https://github.com/root-project/roottest/pull/1162) updates the error style in the numba test to be backwards compatible. The numpy version is temporarily locked to below 2.0 to prevent both upgrades at the same time. - [X] tested changes locally. Fixes https://github.com/root-project/root/issues/16201,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16209
https://github.com/root-project/root/issues/16210:19,availability,down,downcasting,19,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:181,availability,down,downcasting,181,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:9,deployability,Automat,Automatic,9,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:171,deployability,automat,automatic,171,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:751,deployability,modul,module,751,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:146,integrability,interfac,interfaces,146,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:359,integrability,pub,public,359,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:409,integrability,pub,public,409,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:426,integrability,pub,public,426,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:146,interoperability,interfac,interfaces,146,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:146,modifiability,interfac,interfaces,146,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:751,modifiability,modul,module,751,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:87,performance,memor,memory,87,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:317,reliability,doe,doesn,317,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:94,safety,safe,safety,94,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:751,safety,modul,module,751,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:9,testability,Automat,Automatic,9,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:171,testability,automat,automatic,171,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:670,testability,Trace,Traceback,670,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:82,usability,help,help,82,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/issues/16210:87,usability,memor,memory,87,"[PyROOT] Automatic downcasting of smart pointers to actual type; It would greatly help memory safety if ROOT could use more smart pointers in its interfaces. However, the automatic downcasting of returned values is only working for raw pointers. It should work for smart pointers as well. For example, right now this doesn't work:. ```Python. class ClassA {. public:. ClassDef(ClassA, 0);. };. class ClassB : public ClassA {. public:. void helloB() {}. ClassDef(ClassB, 0);. };. ClassA *fooRawPtr() { return new ClassB{}; }. std::unique_ptr<ClassA> fooUniquePtr() { return std::make_unique<ClassB>(); }. ```. Output:. ```txt. <class cppyy.gbl.ClassB at 0x5e1ddf85ed20>. Traceback (most recent call last):. File ""/home/rembserj/repro.py"", line 30, in <module>. out_2.helloB(). ^^^^^^^^^^^^. AttributeError: 'ClassA' object has no attribute 'helloB'. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16210
https://github.com/root-project/root/pull/16211:5,deployability,modul,modulemap,5,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:103,deployability,modul,modulemap,103,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:161,deployability,modul,modulemap,161,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:194,deployability,modul,modulemaps,194,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:290,deployability,modul,modules,290,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:368,deployability,updat,updated,368,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:184,integrability,compon,component,184,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:45,interoperability,distribut,distributed,45,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:184,interoperability,compon,component,184,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:5,modifiability,modul,modulemap,5,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:103,modifiability,modul,modulemap,103,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:161,modifiability,modul,modulemap,161,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:184,modifiability,compon,component,184,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:194,modifiability,modul,modulemaps,194,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:235,modifiability,pac,packaging,235,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:290,modifiability,modul,modules,290,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:5,safety,modul,modulemap,5,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:103,safety,modul,modulemap,103,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:161,safety,modul,modulemap,161,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:194,safety,modul,modulemaps,194,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:290,safety,modul,modules,290,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:338,safety,test,tested,338,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:368,safety,updat,updated,368,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:368,security,updat,updated,368,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16211:338,testability,test,tested,338,"ROOT.modulemap changed from single file to a distributed file set; # This Pull request:. Converts ROOT.modulemap from a single file to a set of files where ROOT.modulemap includes per-component modulemaps, this will allow to implement packaging. ## Changes or fixes:. CMakeLists.txt, cmake/modules/RootMacros.cmake. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16211
https://github.com/root-project/root/pull/16212:33,deployability,patch,patches,33,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:90,deployability,fail,failing,90,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:90,reliability,fail,failing,90,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:33,safety,patch,patches,33,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:71,safety,test,tests,71,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:33,security,patch,patches,33,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:66,testability,unit,unit,66,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:71,testability,test,tests,71,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16212:101,testability,understand,understand,101,[PyROOT] Remove string converter patches to CPyCppyy; Check which unit tests are actually failing to understand the problem with the string converters in CPyCppyy master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16212
https://github.com/root-project/root/pull/16213:24,deployability,build,builds,24,[DO NOT MERGE] Triggers builds including test in roottest PR #1165; https://github.com/root-project/roottest/pull/1165. All this is done to fix [ROOT-5983](https://its.cern.ch/jira/browse/ROOT-5983),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16213
https://github.com/root-project/root/pull/16213:41,safety,test,test,41,[DO NOT MERGE] Triggers builds including test in roottest PR #1165; https://github.com/root-project/roottest/pull/1165. All this is done to fix [ROOT-5983](https://its.cern.ch/jira/browse/ROOT-5983),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16213
https://github.com/root-project/root/pull/16213:41,testability,test,test,41,[DO NOT MERGE] Triggers builds including test in roottest PR #1165; https://github.com/root-project/roottest/pull/1165. All this is done to fix [ROOT-5983](https://its.cern.ch/jira/browse/ROOT-5983),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16213
https://github.com/root-project/root/pull/16215:61,deployability,version,version,61,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:171,deployability,version,version,171,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:263,deployability,version,version,263,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:61,integrability,version,version,61,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:171,integrability,version,version,171,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:263,integrability,version,version,263,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:196,interoperability,distribut,distributed,196,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:61,modifiability,version,version,61,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:171,modifiability,version,version,171,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:263,modifiability,version,version,263,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:99,usability,support,support,99,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16215:246,usability,support,supported,246,"[ci] Enable numpy2.0; No longer set min numpy to 1.4 as this version is outdated. Unlocks numpy2.0 support. This also cleans up the requirements.txt file in terms of some version conditions(dask, distributed) that are no longer needed(as the min supported python version is 3.8). Also adds pandas and sets numba to latest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16215
https://github.com/root-project/root/pull/16216:224,integrability,translat,translation,224,"[ntuple] Fix item type names for STL map fields; With the addition of `RIntegralTypeMap` (PR https://github.com/root-project/root/pull/16039), most of the type. name deduction for type-erased fields was moved from the type. translation map to `RField`'s template specialization. Upon creation of. type-erased STL map(-like) types, originally only the type translation. map was used. This now can cause issues where the map's item types may. be non-normalized. By using the type names of the subfields of the. `std::pair` item field, we ensure the correct inner type names are used.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16216
https://github.com/root-project/root/pull/16216:356,integrability,translat,translation,356,"[ntuple] Fix item type names for STL map fields; With the addition of `RIntegralTypeMap` (PR https://github.com/root-project/root/pull/16039), most of the type. name deduction for type-erased fields was moved from the type. translation map to `RField`'s template specialization. Upon creation of. type-erased STL map(-like) types, originally only the type translation. map was used. This now can cause issues where the map's item types may. be non-normalized. By using the type names of the subfields of the. `std::pair` item field, we ensure the correct inner type names are used.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16216
https://github.com/root-project/root/pull/16216:491,integrability,sub,subfields,491,"[ntuple] Fix item type names for STL map fields; With the addition of `RIntegralTypeMap` (PR https://github.com/root-project/root/pull/16039), most of the type. name deduction for type-erased fields was moved from the type. translation map to `RField`'s template specialization. Upon creation of. type-erased STL map(-like) types, originally only the type translation. map was used. This now can cause issues where the map's item types may. be non-normalized. By using the type names of the subfields of the. `std::pair` item field, we ensure the correct inner type names are used.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16216
https://github.com/root-project/root/pull/16216:224,interoperability,translat,translation,224,"[ntuple] Fix item type names for STL map fields; With the addition of `RIntegralTypeMap` (PR https://github.com/root-project/root/pull/16039), most of the type. name deduction for type-erased fields was moved from the type. translation map to `RField`'s template specialization. Upon creation of. type-erased STL map(-like) types, originally only the type translation. map was used. This now can cause issues where the map's item types may. be non-normalized. By using the type names of the subfields of the. `std::pair` item field, we ensure the correct inner type names are used.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16216
https://github.com/root-project/root/pull/16216:356,interoperability,translat,translation,356,"[ntuple] Fix item type names for STL map fields; With the addition of `RIntegralTypeMap` (PR https://github.com/root-project/root/pull/16039), most of the type. name deduction for type-erased fields was moved from the type. translation map to `RField`'s template specialization. Upon creation of. type-erased STL map(-like) types, originally only the type translation. map was used. This now can cause issues where the map's item types may. be non-normalized. By using the type names of the subfields of the. `std::pair` item field, we ensure the correct inner type names are used.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16216
https://github.com/root-project/root/pull/16217:31,deployability,version,version,31,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:97,deployability,version,version,97,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:31,integrability,version,version,31,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:97,integrability,version,version,97,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:31,modifiability,version,version,31,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:97,modifiability,version,version,97,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:5,performance,Lock,Lock,5,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:5,security,Lock,Lock,5,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/pull/16217:83,usability,minim,minimum,83,"[ci] Lock max numpy, min numba version; Constrain requirements to numpy 1.26.4 and minimum numba version for py3.8.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16217
https://github.com/root-project/root/issues/16219:391,availability,Operat,Operating,391,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:0,deployability,Modul,Module,0,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:28,deployability,version,version,28,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:153,deployability,build,build,153,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:185,deployability,upgrad,upgrade,185,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:219,deployability,modul,module,219,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:248,deployability,Build,Building,248,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:288,deployability,version,version,288,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:352,deployability,Instal,Installation,352,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:129,energy efficiency,Current,Currently,129,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:28,integrability,version,version,28,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:288,integrability,version,version,288,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:0,modifiability,Modul,Module,0,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:28,modifiability,version,version,28,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:185,modifiability,upgrad,upgrade,185,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:219,modifiability,modul,module,219,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:288,modifiability,version,version,288,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:144,reliability,doe,does,144,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:0,safety,Modul,Module,0,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:219,safety,modul,module,219,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:431,testability,context,context,431,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/issues/16219:325,usability,support,support,325,"Module map on the new XCode version for macos15-beta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Currently ROOT does not build on macos15 beta due to an upgrade of XCode that changed the module maps. ### Reproducer. Building root on macos15 beta. ### ROOT version. master, 6.32 (the ones that support macos15 beta). ### Installation method. from sources. ### Operating system. MacOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16219
https://github.com/root-project/root/pull/16220:38,deployability,build,builds,38,[ci] Temporarily disable the mac-beta builds; until the issue with module maps #16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16220
https://github.com/root-project/root/pull/16220:67,deployability,modul,module,67,[ci] Temporarily disable the mac-beta builds; until the issue with module maps #16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16220
https://github.com/root-project/root/pull/16220:67,modifiability,modul,module,67,[ci] Temporarily disable the mac-beta builds; until the issue with module maps #16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16220
https://github.com/root-project/root/pull/16220:67,safety,modul,module,67,[ci] Temporarily disable the mac-beta builds; until the issue with module maps #16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16220
https://github.com/root-project/root/pull/16221:38,deployability,build,builds,38,[ci] Temporarily disable the mac-beta builds; Until the issue with module maps https://github.com/root-project/root/issues/16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16221
https://github.com/root-project/root/pull/16221:67,deployability,modul,module,67,[ci] Temporarily disable the mac-beta builds; Until the issue with module maps https://github.com/root-project/root/issues/16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16221
https://github.com/root-project/root/pull/16221:67,modifiability,modul,module,67,[ci] Temporarily disable the mac-beta builds; Until the issue with module maps https://github.com/root-project/root/issues/16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16221
https://github.com/root-project/root/pull/16221:67,safety,modul,module,67,[ci] Temporarily disable the mac-beta builds; Until the issue with module maps https://github.com/root-project/root/issues/16219 is fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16221
https://github.com/root-project/root/pull/16226:27,deployability,build,building,27,[cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16226
https://github.com/root-project/root/pull/16226:64,deployability,version,version,64,[cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16226
https://github.com/root-project/root/pull/16226:87,deployability,build,building,87,[cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16226
https://github.com/root-project/root/pull/16226:64,integrability,version,version,64,[cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16226
https://github.com/root-project/root/pull/16226:64,modifiability,version,version,64,[cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16226
https://github.com/root-project/root/pull/16226:8,safety,Avoid,Avoid,8,[cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16226
https://github.com/root-project/root/issues/16227:14,availability,recov,recover,14,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:112,availability,down,download,112,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:0,deployability,Build,Build,0,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:14,deployability,recov,recover,14,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:299,performance,time,time,299,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:14,reliability,recov,recover,14,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:65,reliability,doe,does,65,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:234,reliability,doe,does,234,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:14,safety,recov,recover,14,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:272,safety,reme,remember,272,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/issues/16227:14,security,recov,recover,14,Build can not recover from partial 'cleanup'; Is It 'just me' or does the master (intentionally ?) no longer re-download the tar files for the builtins. I.e.:. ```. cmake. ninja. rm -rf *-prefix builtins. ninja. ```. used to work and does not work anymore (and no I don't remember when was the last time I saw it worked).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16227
https://github.com/root-project/root/pull/16228:14,deployability,instal,install,14,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:305,deployability,contain,contains,305,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:371,deployability,contain,contains,371,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:388,deployability,version,version,388,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:531,deployability,updat,updated,531,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:388,integrability,version,version,388,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:29,interoperability,bind,binding,29,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:208,interoperability,bind,bindings,208,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:29,modifiability,bind,binding,29,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:208,modifiability,bind,bindings,208,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:388,modifiability,version,version,388,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:104,reliability,doe,doesn,104,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:454,reliability,doe,doesn,454,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:499,safety,test,tested,499,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:531,safety,updat,updated,531,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:531,security,updat,updated,531,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:112,testability,understand,understand,112,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/pull/16228:499,testability,test,tested,499,cmake: do not install python binding with SOVERSION; # This Pull request:. ## Changes or fixes:. Python doesn't understand soversions and they don't make sense here anyway since nothing is linked against the bindings. Thus `ROOT_LIBRARY_PROPERTIES` is split into `ROOT_LIBRARY_PROPERTIES_NOVER` that just contains the suffix and prefix and R`OOT_LIBRARY_PROPERTIES` that contains the (so)version if enabled. Additionally `IMPORT_PREFIX` is dropped which doesn't have an effect. ## Checklist:. - [x] tested changes locally. - ~~[ ] updated the docs (if necessary)~~.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16228
https://github.com/root-project/root/issues/16229:947,deployability,patch,patch,947,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1025,deployability,patch,patch,1025,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1172,deployability,patch,patch,1172,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:8,energy efficiency,load,loading,8,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:55,energy efficiency,Current,Currently,55,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:71,energy efficiency,load,loads,71,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:726,energy efficiency,current,current,726,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:519,integrability,interfac,interface,519,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:636,integrability,interfac,interface,636,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:739,integrability,interfac,interface,739,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:226,interoperability,distribut,distribution,226,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:519,interoperability,interfac,interface,519,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:636,interoperability,interfac,interface,636,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:739,interoperability,interfac,interface,739,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:148,modifiability,maintain,maintainer,148,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:239,modifiability,maintain,maintainer,239,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:519,modifiability,interfac,interface,519,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:636,modifiability,interfac,interface,636,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:656,modifiability,paramet,parameters,656,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:739,modifiability,interfac,interface,739,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:8,performance,load,loading,8,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:71,performance,load,loads,71,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:148,safety,maintain,maintainer,148,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:239,safety,maintain,maintainer,239,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:947,safety,patch,patch,947,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1025,safety,patch,patch,1025,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1172,safety,patch,patch,1172,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:947,security,patch,patch,947,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1025,security,patch,patch,1025,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1172,security,patch,patch,1172,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:172,testability,simpl,simply,172,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1325,testability,context,context,1325,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:172,usability,simpl,simply,172,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:369,usability,support,support,369,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/issues/16229:1229,usability,support,support,1229,"Improve loading system fonts; ### Feature description. Currently, ROOT loads fonts via the `Root.TTFontPath`. This makes a lot of sense from a ROOT maintainer perspective (simply ship all used fonts), but is a roadblock for a distribution maintainer (embedded files are usually not wished if not otherwise possible). Thus, it would be nice if ROOT would _additionally_ support [fontconfig](https://www.freedesktop.org/wiki/Software/fontconfig/), which is the default way to find fonts on Linux. In particular, the font interface should first look into `Root.TTFontPath` and then fallback to fontconfig. This means that the font-finding interface needs two parameters: the font file name and a fontconfig name as fallback. The current font interface is a bit all over the place. There is at least `graf2d/graf/src/TTF.cxx`, `graf3d/gl/src/TGLFontManager.cxx` and `graf3d/gl/src/TGLText.cxx` that handle font names, probably more. Fedora uses [this patch](https://src.fedoraproject.org/rpms/root/blob/rawhide/f/root-fontconfig.patch) from @ellert to get rid of the non-free MS fonts (see also https://github.com/root-project/root/issues/8357), which is a good start but the patch is not really feasible upstream due to Windows/OSX support. /cc @Axel-Naumann @dpiparo. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16229
https://github.com/root-project/root/pull/16230:309,interoperability,convers,conversion,309,"[ntuple] Convert count leaf names for `SetConvertDotsInBranchNames`; When `SetConvertDotsInBranchNames`, dot characters in field names are converted into underscores. This flag previously did not take into account count leafs, which in the RNTuple are represented as a projected fields. With this commit, the conversion is also done for these kinds of fields.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16230
https://github.com/root-project/root/pull/16231:34,deployability,build,building,34,[v6-32][cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16231
https://github.com/root-project/root/pull/16231:71,deployability,version,version,71,[v6-32][cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16231
https://github.com/root-project/root/pull/16231:94,deployability,build,building,94,[v6-32][cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16231
https://github.com/root-project/root/pull/16231:71,integrability,version,version,71,[v6-32][cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16231
https://github.com/root-project/root/pull/16231:71,modifiability,version,version,71,[v6-32][cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16231
https://github.com/root-project/root/pull/16231:15,safety,Avoid,Avoid,15,[v6-32][cmake] Avoid warning when building from tar file; Use the ROOT version from file when building from the source tar file. Fixes https://github.com/root-project/root/issues/15178.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16231
https://github.com/root-project/root/pull/16233:7,deployability,Updat,Update,7,[v632] Update release notes to include iterator fix(#15269); Include this issue that is fixed in 6.32.04 (#15269),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16233
https://github.com/root-project/root/pull/16233:14,deployability,releas,release,14,[v632] Update release notes to include iterator fix(#15269); Include this issue that is fixed in 6.32.04 (#15269),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16233
https://github.com/root-project/root/pull/16233:7,safety,Updat,Update,7,[v632] Update release notes to include iterator fix(#15269); Include this issue that is fixed in 6.32.04 (#15269),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16233
https://github.com/root-project/root/pull/16233:7,security,Updat,Update,7,[v632] Update release notes to include iterator fix(#15269); Include this issue that is fixed in 6.32.04 (#15269),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16233
https://github.com/root-project/root/pull/16234:89,integrability,coupl,couple,89,[net][graf3d] fix some warnings (vsprintf -> vsnprintf); # This Pull request:. changes a couple of usages of `vsprintf` to `vsnprintf` to fix some compiler warnings.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16234
https://github.com/root-project/root/pull/16234:89,modifiability,coupl,couple,89,[net][graf3d] fix some warnings (vsprintf -> vsnprintf); # This Pull request:. changes a couple of usages of `vsprintf` to `vsnprintf` to fix some compiler warnings.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16234
https://github.com/root-project/root/pull/16234:89,testability,coupl,couple,89,[net][graf3d] fix some warnings (vsprintf -> vsnprintf); # This Pull request:. changes a couple of usages of `vsprintf` to `vsnprintf` to fix some compiler warnings.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16234
https://github.com/root-project/root/pull/16235:21,deployability,build,build,21,[BP 632] [cling] Fix build with latest MacOSX15.0.sdk beta; BP of https://github.com/root-project/root/pull/16225.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16235
https://github.com/root-project/root/issues/16236:84,energy efficiency,current,currently,84,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:114,energy efficiency,model,model,114,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:393,energy efficiency,model,model,393,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:430,energy efficiency,model,model,430,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:461,energy efficiency,model,model,461,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:492,energy efficiency,model,model,492,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:571,energy efficiency,model,model,571,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:912,energy efficiency,model,model,912,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1082,energy efficiency,model,model,1082,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1377,energy efficiency,model,model,1377,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1422,energy efficiency,model,model,1422,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1464,energy efficiency,model,model,1464,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:105,interoperability,specif,specific,105,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:717,interoperability,Bind,BindRawPtr,717,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1483,interoperability,semant,semantic,1483,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:717,modifiability,Bind,BindRawPtr,717,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:39,performance,parallel,parallel,39,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:176,performance,parallel,parallel,176,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:129,safety,prevent,prevents,129,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:23,security,token,token,23,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:114,security,model,model,114,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:129,security,preven,prevents,129,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:393,security,model,model,393,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:430,security,model,model,430,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:461,security,model,model,461,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:484,security,token,token,484,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:492,security,model,model,492,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:571,security,model,model,571,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:728,security,token,token,728,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:851,security,token,token,851,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:892,security,token,token,892,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:912,security,model,model,912,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1082,security,model,model,1082,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1116,security,token,tokens,1116,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1251,security,token,token,1251,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1338,security,token,tokens,1338,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1377,security,model,model,1377,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1422,security,model,model,1422,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1464,security,model,model,1464,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:622,testability,context,context,622,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:675,testability,context,context,675,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1168,testability,context,context,1168,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/issues/16236:1221,testability,context,context,1221,"[ntuple] Improve field token usage for parallel writing; A `REntry::RFieldToken` is currently bound to a specific model id. This prevents the following usage from working with parallel writing, as I wanted to recommend it to @siliataider:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleParallelWriter.hxx>. using namespace ROOT::Experimental;. void parallel_writer() {. auto model = RNTupleModel::CreateBare();. model->MakeField<float>(""e"");. model->Freeze();. auto token = model->GetToken(""e"");. auto writer = RNTupleParallelWriter::Recreate(std::move(model), ""ntpl"", ""ntpl.root"");. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. float e;. entry->BindRawPtr(token, &e);. }. ```. ```. terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): invalid token for this entry, make sure to use a token from the same model as this entry. At:. void ROOT::Experimental::REntry::EnsureMatchingModel(RFieldToken) const. ```. This is because the `RNTupleParallelWriter` internally clones the model, so every thread has to get tokens from its entry:. ```c++. // per thread. auto context = writer->CreateFillContext();. auto entry = context->CreateEntry();. auto token = entry->GetToken(""e"");. ```. In principle, we could allow using a single set of tokens for all entries from any cloned model. This requires either not changing the model id when cloning, or having a second model id with that semantic.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16236
https://github.com/root-project/root/pull/16237:96,energy efficiency,reduc,reduce,96,[ntuple] clang-format pass; clang-format some files + add some typedefs to `ntuple_test.hxx` to reduce namespace noise in the tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16237
https://github.com/root-project/root/pull/16237:15,interoperability,format,format,15,[ntuple] clang-format pass; clang-format some files + add some typedefs to `ntuple_test.hxx` to reduce namespace noise in the tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16237
https://github.com/root-project/root/pull/16237:34,interoperability,format,format,34,[ntuple] clang-format pass; clang-format some files + add some typedefs to `ntuple_test.hxx` to reduce namespace noise in the tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16237
https://github.com/root-project/root/pull/16237:126,safety,test,tests,126,[ntuple] clang-format pass; clang-format some files + add some typedefs to `ntuple_test.hxx` to reduce namespace noise in the tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16237
https://github.com/root-project/root/pull/16237:126,testability,test,tests,126,[ntuple] clang-format pass; clang-format some files + add some typedefs to `ntuple_test.hxx` to reduce namespace noise in the tests,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16237
https://github.com/root-project/root/pull/16239:39,availability,error,error,39,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:86,availability,error,error,86,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:33,deployability,build,build,33,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:97,deployability,build,building,97,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:126,deployability,fail,failed,126,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:162,deployability,build,build,162,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:39,performance,error,error,39,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:86,performance,error,error,86,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:126,reliability,fail,failed,126,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:39,safety,error,error,39,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:86,safety,error,error,86,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:39,usability,error,error,39,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:86,usability,error,error,86,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16239:118,usability,Command,Command,118,[cmake][clad] Fix potential Clad build error; This should fix the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16239
https://github.com/root-project/root/pull/16240:18,safety,test,test,18,[meta] Thoroughly test TClingInfo property; This PR fixes [ROOT-6913 ](https://its.cern.ch/jira/browse/ROOT-6313).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16240
https://github.com/root-project/root/pull/16240:18,testability,test,test,18,[meta] Thoroughly test TClingInfo property; This PR fixes [ROOT-6913 ](https://its.cern.ch/jira/browse/ROOT-6313).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16240
https://github.com/root-project/root/issues/16241:27,availability,cluster,cluster,27,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:660,availability,cluster,cluster,660,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:27,deployability,cluster,cluster,27,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:660,deployability,cluster,cluster,660,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:63,integrability,buffer,buffers,63,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:545,integrability,buffer,buffers,545,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:590,integrability,sub,substantial,590,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:166,performance,synch,synchronization,166,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:218,performance,lock,locking,218,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:352,performance,lock,locking,352,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:722,performance,perform,perform,722,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:212,safety,avoid,avoid,212,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:218,security,lock,locking,218,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:352,security,lock,locking,352,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16241:722,usability,perform,perform,722,"[ntuple] Method to prepare cluster commit / flush column write buffers; With `RNTupleWriter::Append` / `RNTupleParallelWriter::Append`, the application must organize synchronization to the underlying `TFile`. To avoid locking for every `Fill`, https://github.com/root-project/root/pull/15239 introduced `FillNoCommit` and gives some guarantees so that locking is only necessary when calling `CommitCluster`. However that's still not ideal because `CommitCluster` will first call `CommitCluster` on every field, which will flush the column write buffers and trigger compression. This can be substantial for many fields or very large page sizes (compared to the cluster size). Ideally a `RNTupleFillContext` had a method to perform this work outside of the critical section, like `PrepareCommitCluster` or `FlushPageBuffers`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16241
https://github.com/root-project/root/issues/16242:7,availability,replic,replicate,7,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:376,availability,failur,failures,376,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:454,availability,failur,failures,454,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:718,availability,Failur,Failure,718,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:815,availability,failur,failures,815,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2381,availability,failur,failure,2381,"(Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3280,availability,operat,operator,3280,"eferences only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (mo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3329,availability,Error,Error,3329," sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3402,availability,error,error,3402,"ow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_req",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3759,availability,Error,Error,3759," Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3832,availability,error,error,3832,"hub/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3894,availability,ERROR,ERROR,3894,"ssification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5885,availability,uptim,uptime,5885,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6143,availability,failur,failure,6143,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6288,availability,Operat,Operating,6288,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:22,deployability,build,build,22,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:204,deployability,build,build,204,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:376,deployability,fail,failures,376,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:443,deployability,log,log,443,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:454,deployability,fail,failures,454,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:475,deployability,Contain,Container-LastTest,475,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:494,deployability,log,log,494,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:557,deployability,Contain,Container-LastTest,557,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:576,deployability,log,log,576,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:597,deployability,log,log,597,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:651,deployability,instal,installation,651,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:692,deployability,instal,installation,692,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:718,deployability,Fail,Failure,718,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:815,deployability,fail,failures,815,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:893,deployability,Contain,Container-LastTest,893,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:912,deployability,log,log,912,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:975,deployability,Contain,Container-LastTest,975,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:994,deployability,log,log,994,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1042,deployability,FAIL,FAILED,1042,"ing (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1092,deployability,Fail,Failed,1092,"(specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1138,deployability,Fail,Failed,1138,"used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1179,deployability,Fail,Failed,1179,"I for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1216,deployability,Fail,Failed,1216,"e](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-pyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1262,deployability,Fail,Failed,1262,"s/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1304,deployability,Fail,Failed,1304,"2#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1347,deployability,Fail,Failed,1347,"oducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1386,deployability,Fail,Failed,1386,"seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1425,deployability,Fail,Failed,1425,"low and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1487,deployability,Fail,Failed,1487,"est.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU mul",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1542,deployability,Fail,Failed,1542,"5802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CN",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1599,deployability,Fail,Failed,1599,"he problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1654,deployability,Fail,Failed,1654,"lation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1704,deployability,Fail,Failed,1704,"upyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't impor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1771,deployability,Fail,Failed,1771,"backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate Py",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1834,deployability,Fail,Failed,1834,"for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/githu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1877,deployability,Fail,Failed,1877," see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/genera",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1939,deployability,Fail,Failed,1939,"ttachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2005,deployability,Fail,Failed,2005,"details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2069,deployability,Fail,Failed,2069,"est-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2132,deployability,Fail,Failed,2132,"s (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/datafram",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2191,deployability,Fail,Failed,2191,"PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2250,deployability,Fail,Failed,2250,"ication (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2299,deployability,fail,failed,2299," (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_al",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2343,deployability,fail,fails,2343,"(Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2381,deployability,fail,failure,2381,"(Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2465,deployability,build,build,2465,"odelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2852,deployability,build,build,2852,"ial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2926,deployability,modul,module,2926,"notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not foun",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2949,deployability,Modul,ModuleNotFoundError,2949,"test-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2973,deployability,modul,module,2973,"OOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3183,deployability,modul,module,3183,"ook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3359,deployability,build,build,3359,"cceed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3556,deployability,modul,module,3556,"h nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu240",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3789,deployability,build,build,3789,"ceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4046,deployability,modul,module,4046," Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4561,deployability,build,buildready,4561,"OOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4695,deployability,artifact,artifacts,4695,":RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4745,deployability,build,build-artifacts,4745,"CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. whic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4916,deployability,artifact,artifacts,4916,"not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cm",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,deployability,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,deployability,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5770,deployability,version,version,5770,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5804,deployability,version,version,5804,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5851,deployability,releas,release,5851,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5980,deployability,build,build,5980,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6008,deployability,build,build,6008,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6036,deployability,build,build,6036,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6117,deployability,build,build,6117,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6143,deployability,fail,failure,6143,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6214,deployability,version,version,6214,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6235,deployability,Instal,Installation,6235,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2476,energy efficiency,GPU,GPU,2476,"PyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/h",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2483,energy efficiency,CPU,CPU,2483," (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2780,energy efficiency,model,model,2780,"5 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3022,integrability,event,event,3022,"test-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdif",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3391,integrability,messag,message,3391,"is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3821,integrability,messag,message,3821,"File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,integrability,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,integrability,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5770,integrability,version,version,5770,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5804,integrability,version,version,5804,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6214,integrability,version,version,6214,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:96,interoperability,specif,specifically,96,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2268,interoperability,specif,specific,2268,"90 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3391,interoperability,messag,message,3391,"is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3821,interoperability,messag,message,3821,"File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4333,interoperability,socket,socketserver,4333,"github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4525,interoperability,registr,registry,4525,"oPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/gi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,interoperability,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,interoperability,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6192,interoperability,xml,xml,6192,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2926,modifiability,modul,module,2926,"notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not foun",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2949,modifiability,Modul,ModuleNotFoundError,2949,"test-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2973,modifiability,modul,module,2973,"OOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3183,modifiability,modul,module,3183,"ook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3556,modifiability,modul,module,3556,"h nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu240",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4046,modifiability,modul,module,4046," Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,modifiability,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,modifiability,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5770,modifiability,version,version,5770,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5804,modifiability,version,version,5804,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6214,modifiability,version,version,6214,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:376,performance,failur,failures,376,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:454,performance,failur,failures,454,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:718,performance,Failur,Failure,718,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:815,performance,failur,failures,815,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2381,performance,failur,failure,2381,"(Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2476,performance,GPU,GPU,2476,"PyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/h",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2483,performance,CPU,CPU,2483," (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2487,performance,multi-thread,multi-thread,2487,"). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3329,performance,Error,Error,3329," sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3402,performance,error,error,3402,"ow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_req",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3759,performance,Error,Error,3759," Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3832,performance,error,error,3832,"hub/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3894,performance,ERROR,ERROR,3894,"ssification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6071,performance,parallel,parallel,6071,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6143,performance,failur,failure,6143,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6153,performance,parallel,parallel,6153,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:376,reliability,fail,failures,376,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:454,reliability,fail,failures,454,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:718,reliability,Fail,Failure,718,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:815,reliability,fail,failures,815,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1042,reliability,FAIL,FAILED,1042,"ing (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1092,reliability,Fail,Failed,1092,"(specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-p",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1138,reliability,Fail,Failed,1138,"used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1179,reliability,Fail,Failed,1179,"I for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1216,reliability,Fail,Failed,1216,"e](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-pyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1262,reliability,Fail,Failed,1262,"s/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1304,reliability,Fail,Failed,1304,"2#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1347,reliability,Fail,Failed,1347,"oducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1386,reliability,Fail,Failed,1386,"seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1425,reliability,Fail,Failed,1425,"low and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1487,reliability,Fail,Failed,1487,"est.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU mul",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1542,reliability,Fail,Failed,1542,"5802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CN",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1599,reliability,Fail,Failed,1599,"he problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1654,reliability,Fail,Failed,1654,"lation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1704,reliability,Fail,Failed,1704,"upyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't impor",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1771,reliability,Fail,Failed,1771,"backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate Py",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1834,reliability,Fail,Failed,1834,"for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/githu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1859,reliability,rca,rcanvas-,1859,"elevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1877,reliability,Fail,Failed,1877," see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/genera",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1939,reliability,Fail,Failed,1939,"ttachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2005,reliability,Fail,Failed,2005,"details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2069,reliability,Fail,Failed,2069,"est-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2132,reliability,Fail,Failed,2132,"s (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/datafram",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2191,reliability,Fail,Failed,2191,"PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2250,reliability,Fail,Failed,2250,"ication (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2299,reliability,fail,failed,2299," (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_al",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2343,reliability,fail,fails,2343,"(Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2381,reliability,fail,failure,2381,"(Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,reliability,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,reliability,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5885,reliability,uptim,uptime,5885,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6143,reliability,fail,failure,6143,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:443,safety,log,log,443,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:494,safety,log,log,494,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:576,safety,log,log,576,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:597,safety,log,log,597,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:912,safety,log,log,912,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:994,safety,log,log,994,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1036,safety,test,tests,1036,"t working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-Ju",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1457,safety,test,test-TestRModelParserPyTorch,1457,"tCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2321,safety,test,test,2321,"A-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2869,safety,test,test,2869,"4-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OU",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2926,safety,modul,module,2926,"notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not foun",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2949,safety,Modul,ModuleNotFoundError,2949,"test-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2973,safety,modul,module,2973,"OOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3183,safety,modul,module,3183,"ook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3329,safety,Error,Error,3329," sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3402,safety,error,error,3402,"ow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_req",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3556,safety,modul,module,3556,"h nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu240",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3759,safety,Error,Error,3759," Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3832,safety,error,error,3832,"hub/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3864,safety,TEST,TEST,3864,"va/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /gi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3889,safety,TEST,TEST,3889,"delClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3894,safety,ERROR,ERROR,3894,"ssification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4046,safety,modul,module,4046," Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4195,safety,Except,Exception,4195,"le(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git confi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6180,safety,Test,TestResults,6180,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:443,security,log,log,443,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:494,security,log,log,494,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:576,security,log,log,576,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:597,security,log,log,597,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:912,security,log,log,912,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:994,security,log,log,994,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2780,security,model,model,2780,"5 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/RO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4333,security,soc,socketserver,4333,"github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:4494,security,secur,security-opt,4494,"als/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,security,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,security,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:443,testability,log,log,443,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:494,testability,log,log,494,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:576,testability,log,log,576,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:597,testability,log,log,597,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:912,testability,log,log,912,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:994,testability,log,log,994,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1036,testability,test,tests,1036,"t working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-Ju",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1374,testability,Regress,Regression,1374,"lures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:1457,testability,test,test-TestRModelParserPyTorch,1457,"tCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2321,testability,test,test,2321,"A-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2789,testability,Trace,Traceback,2789,"l-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2869,testability,test,test,2869,"4-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OU",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3050,testability,Trace,Traceback,3050,"cal_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3427,testability,Trace,Traceback,3427,"CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_addres",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3864,testability,TEST,TEST,3864,"va/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /gi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3889,testability,TEST,TEST,3889,"delClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3932,testability,Trace,Traceback,3932,"port torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5270,testability,Integr,Integration,5270,"back (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5681,testability,Integr,Integration,5681,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6180,testability,Test,TestResults,6180,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:6337,testability,context,context,6337,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:518,usability,user,user-attachments,518,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:936,usability,user,user-attachments,936,"CI ""To replicate this build locally"" not working (for me); ### Description. On a Alma 9.4 node (specifically cmslpc-el9-heavy01.fnal.gov), I used verbatim the instructions from the CI for an arbitrary PR build (see [here](https://github.com/root-project/root/actions/runs/10343508810/job/28658232103?pr=16202#step:9:8064) and a copy/paste in the reproducer. However, I get 23 failures not seen on any of the CI runs (see list below and . full log of the failures at: [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log). Looking in the log the problem seem to include:. * Missing (py)Torch installation (PyMVA). * Missing ipython3 installation (Jupyter). * Failure to connect to a server (roottest-python-distrdf-backends-test_all ). * Some more unclear failures. * See below for an extraction of the relevant output. * see [RootCI-Container-LastTest.log](https://github.com/user-attachments/files/16615802/RootCI-Container-LastTest.log) for more details. ```. The following tests FAILED:. 385 - PyMVA-RandomForest-Classification (Failed). 386 - PyMVA-RandomForest-Multiclass (Failed). 387 - PyMVA-GTB-Classification (Failed). 388 - PyMVA-GTB-Multiclass (Failed). 389 - PyMVA-AdaBoost-Classification (Failed). 390 - PyMVA-AdaBoost-Multiclass (Failed). 391 - PyMVA-Torch-Classification (Failed). 392 - PyMVA-Torch-Regression (Failed). 393 - PyMVA-Torch-Multiclass (Failed). 394 - gtest-tmva-pymva-test-TestRModelParserPyTorch (Failed). 1068 - tutorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_noteb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2500,usability,support,support,2500,"utorial-tmva-TMVA_CNN_Classification (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:2530,usability,Learn,Learning,2530,"cation (Failed). 1069 - tutorial-tmva-TMVA_Higgs_Classification (Failed). 1070 - tutorial-tmva-TMVA_RNN_Classification (Failed). 1071 - tutorial-tmva-TMVA_SOFIE_PyTorch (Failed). 1203 - tutorial-dataframe-df102_NanoAODDimuonAnalysis-py (Failed). 1205 - tutorial-dataframe-df104_HiggsToTwoPhotons-py (Failed). 1261 - tutorial-rcanvas-df104-py (Failed). 1564 - roottest-python-JupyROOT-importROOT_notebook (Failed). 1565 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 1566 - roottest-python-JupyROOT-thread_local_notebook (Failed). 1567 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 1568 - roottest-python-JupyROOT-tpython_notebook (Failed). 1664 - roottest-python-distrdf-backends-test_all (Failed). ```. The specific run I references only failed the `TMapFile` test (which sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhot",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3329,usability,Error,Error,3329," sometimes fails, sometimes succeed). The set of failure types is as follow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3402,usability,error,error,3402,"ow:. ```. Warning in <TMVA_CNN_Classification>: TMVA is not build with GPU or CPU multi-thread support. Cannot use TMVA Deep Learning for CNN. Running with nthreads = 4. [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Setup TMVA... [37;41;1m<FATAL> : Can't import __main__[0m. ***> abort program execution. ```. ```. Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_req",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3759,usability,Error,Error,3759," Generate PyTorch model... Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/u",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3832,usability,error,error,3832,"hub/home/ROOT-CI/build/tmva/pymva/test/generatePyTorchModelClassification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:3894,usability,ERROR,ERROR,3894,"ssification.py"", line 1, in <module>. import torch. ModuleNotFoundError: No module named 'torch'. ```. ```. RDataFrame::Run: event loop was interrupted. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df102_NanoAODDimuonAnalysis.py"", line 50, in <module>. h.SetTitle(""""). ^^^^^^^^^^. cppyy.gbl.std.bad_alloc: TH1D& ROOT::RDF::RResultPtr<TH1D>::operator*() =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/src/tutorials/dataframe/df104_HiggsToTwoPhotons.py"", line 87, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. CMake Error at /github/home/ROOT-CI/build/RootTestDriver.cmake:232 (message):. error code: 1. ```. ```. -- END TEST OUTPUT --. -- BEGIN TEST ERROR --. sh: 1: ipython3: not found. Traceback (most recent call last):. File ""/github/home/ROOT-CI/roottest/python/JupyROOT/nbdiff.py"", line 197, in <module>. retCode = canReproduceNotebook(nbFileName, kernelName, needsCompare). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ```. ```. Exception occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /g",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5202,usability,user,user,5202," occurred during processing of request from ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5244,usability,user,user,5244,"m ('127.0.0.1', 53110). FTraceback (most recent call last):. File ""/usr/lib/python3.12/socketserver.py"", line 318, in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installatio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5613,usability,user,user,5613,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/issues/16242:5655,usability,user,user,5655,", in _handle_request_noblock. self.process_request(request, client_address). ```. ### Reproducer. Grab the image:. ```. $ docker run --security-opt label=disable -it registry.cern.ch/root-ci/ubuntu2404:buildready. ```. Then:. ``` . (. rm -rf /github/home/ROOT-CI. mkdir -p /github/home/ROOT-CI. ). (. curl --output /github/home/ROOT-CI/artifacts.tar.gz https://s3.cern.ch/swift/v1/ROOT-build-artifacts/ubuntu2404/master/RelWithDebInfo/3f796869dae3bde0bfafc4ef8051339eb5ca133c/2024-08-12.tar.gz. ). (. cd /github/home/ROOT-CI && tar -xf /github/home/ROOT-CI/artifacts.tar.gz. ). (. cd '/github/home/ROOT-CI/src'. git checkout master. git fetch. git reset --hard @{u}. ). (. cd '/github/home/ROOT-CI/src'. git fetch https://github.com/root-project/root 9fc748389d42ce698fe8654ac177f9cf9a542f5c. ). (. cd '/github/home/ROOT-CI/src'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch origin 7d45ab2957efacf7b6685f4ae126a9fed243494c:fix-15733. git checkout fix-15733. git rebase 531620f59e898e5ec809043135583d15b0d151a6. ). (. git clone --branch master --single-branch https://github.com/root-project/roottest.git ""/github/home/ROOT-CI/roottest"". ). (. cd '/github/home/ROOT-CI/roottest'. . git config user.email ""rootci@root.cern"". git config user.name 'ROOT Continous Integration'. . git fetch . git checkout . git rebase master. ). (. which cmake. cmake --version. which c++ || true. c++ --version || true. uname -a || true. cat /etc/os-release || true. sw_vers || true. uptime || true. df || true. ). (. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -N -L. ). (. cmake --build '/github/home/ROOT-CI/build' --config 'RelWithDebInfo' --parallel '16'. ). (. cd '/github/home/ROOT-CI/build'. ctest --output-on-failure --parallel 16 --output-junit TestResults.xml. ). ```. ### ROOT version. master. ### Installation method. docker copy/pasted from CI. ### Operating system. Alma9 + Ubuntu. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16242
https://github.com/root-project/root/pull/16243:257,availability,avail,available,257,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:320,availability,avail,available,320,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:188,integrability,configur,configured,188,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:188,modifiability,configur,configured,188,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:257,reliability,availab,available,257,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:320,reliability,availab,available,320,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:206,safety,test,testing,206,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:230,safety,Test,TestSupport,230,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:257,safety,avail,available,257,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:301,safety,Test,TestSupport,301,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:320,safety,avail,available,320,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:466,safety,Test,TestSupport,466,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:514,safety,test,tests,514,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:549,safety,Test,TestSupport,549,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:770,safety,Test,TestSupport,770,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:792,safety,test,tests,792,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:188,security,configur,configured,188,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:257,security,availab,available,257,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:320,security,availab,available,320,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:206,testability,test,testing,206,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:230,testability,Test,TestSupport,230,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:301,testability,Test,TestSupport,301,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:466,testability,Test,TestSupport,466,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:514,testability,test,tests,514,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:549,testability,Test,TestSupport,549,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:770,testability,Test,TestSupport,770,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:792,testability,test,tests,792,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/pull/16243:607,usability,user,user,607,"[CMake] Always link against gtest in ROOT_ADD_GTEST ; The comments in `ROOT_ADD_GTEST` suggest that the macro can also be used. in your own projects based on ROOT, only that when ROOT was configured. with `testing=OFF`, the ROOT::TestSupport library is not available. However, in the case where ROOT::TestSupport is not available, the. ROOT_ADD_GTEST macro is dysfunctional because the linkage against. `gtest` is missing. It is only indirectly picked up via. ROOT::TestSupport. This breaks the compilation of all tests, even if. they don't use the TestSupport library. To make this work again without. the user having to explicitly link against `gtest`, this PR suggests. to always link against `gtest` in the ROOT_ADD_GTEST macro. Also, make the linking against ROOT::TestSupport in RooFit tests explicit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16243
https://github.com/root-project/root/issues/16244:1208,availability,Operat,Operating,1208,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:1151,deployability,version,version,1151,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:1172,deployability,Instal,Installation,1172,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:11,energy efficiency,draw,drawing,11,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:158,energy efficiency,draw,drawing,158,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:743,energy efficiency,Draw,Draw,743,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:780,energy efficiency,Draw,Draw,780,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:796,energy efficiency,draw,drawing,796,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:862,energy efficiency,draw,drawn,862,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:1151,integrability,version,version,1151,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:1151,modifiability,version,version,1151,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:29,performance,content,content,29,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:201,performance,content,content,201,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:413,performance,content,content,413,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:475,performance,content,content,475,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:563,performance,content,content,563,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:1246,testability,context,context,1246,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:254,usability,behavi,behaviour,254,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:357,usability,tool,tooltip,357,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:960,usability,user,user-attachments,960,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/issues/16244:1079,usability,user,user-attachments,1079,"JSROOT not drawing bins with content=0 but entries > 0 in TProfile2D; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. JSROOT isn't drawing the bins of TProfile2D that have a content of 0 but non-zero entries. This is different behaviour to regular ROOT (see reproducer). I'll also perhaps remark here that it would be good if the tooltip for JSROOT over TProfile2D would show both the 'content' and 'entries' of the bin, at the moment it shows the content, but misleadingly shows it under entries, e.g. shows ""entries=X"" for a bin with content=X. . ### Reproducer. Here's a reproducer:. ```. %jsroot on. import ROOT. p2 = ROOT.TProfile2D(""p2"",""p2"",10,0,10,10,0,10). p2.Fill(4,4,-1);p2.Fill(6,6,0);p2.Fill(3,3,1). p2.Draw(""COL1Z""). ROOT.gPad.GetCanvas().Draw(). ```. vs drawing with jsroot off -- the bin that has a value of 0 in it is drawn in regular ROOT, but not in jsroot. ![Screenshot 2024-08-15 at 14 00 16](https://github.com/user-attachments/assets/6c6d717e-f779-4476-bdc3-43c4b842adf1). ![Screenshot 2024-08-15 at 14 00 23](https://github.com/user-attachments/assets/65c72733-fcc3-4d3c-aee5-18bbb3c4b468). ### ROOT version. latest. ### Installation method. pre-built. ### Operating system. all. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16244
https://github.com/root-project/root/pull/16245:24,deployability,build,build,24,"Move some files out of `build` to other directories; Partially closes #8031, only moving the part of the files where I think the new location is not controversial. Thanks @pcanal for the suggestions!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16245
https://github.com/root-project/root/pull/16245:63,usability,close,closes,63,"Move some files out of `build` to other directories; Partially closes #8031, only moving the part of the files where I think the new location is not controversial. Thanks @pcanal for the suggestions!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16245
https://github.com/root-project/root/pull/16246:1,energy efficiency,Core,Core,1,[Core][Cont] TRefArray: force the loading of the referenced branch when accessing by index; This PR fixes ROOT-3594. Sister PR in roottest: https://github.com/root-project/roottest/pull/1166. Thanks a lot to @ferdymercury for the initial stab https://github.com/root-project/root/pull/15932.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16246
https://github.com/root-project/root/pull/16246:34,energy efficiency,load,loading,34,[Core][Cont] TRefArray: force the loading of the referenced branch when accessing by index; This PR fixes ROOT-3594. Sister PR in roottest: https://github.com/root-project/roottest/pull/1166. Thanks a lot to @ferdymercury for the initial stab https://github.com/root-project/root/pull/15932.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16246
https://github.com/root-project/root/pull/16246:34,performance,load,loading,34,[Core][Cont] TRefArray: force the loading of the referenced branch when accessing by index; This PR fixes ROOT-3594. Sister PR in roottest: https://github.com/root-project/roottest/pull/1166. Thanks a lot to @ferdymercury for the initial stab https://github.com/root-project/root/pull/15932.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16246
https://github.com/root-project/root/pull/16246:72,security,access,accessing,72,[Core][Cont] TRefArray: force the loading of the referenced branch when accessing by index; This PR fixes ROOT-3594. Sister PR in roottest: https://github.com/root-project/roottest/pull/1166. Thanks a lot to @ferdymercury for the initial stab https://github.com/root-project/root/pull/15932.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16246
https://github.com/root-project/root/pull/16247:46,availability,error,error,46,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:83,availability,error,error,83,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:40,deployability,build,build,40,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:94,deployability,build,building,94,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:123,deployability,fail,failed,123,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:159,deployability,build,build,159,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:46,performance,error,error,46,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:83,performance,error,error,83,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:123,reliability,fail,failed,123,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:46,safety,error,error,46,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:83,safety,error,error,83,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:46,usability,error,error,46,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:83,usability,error,error,83,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16247:115,usability,Command,Command,115,[v6-32][cmake][clad] Fix potential Clad build error; Fixes the following potential error when building clad:. ```. Command failed: 2. /usr/local/bin/cmake build . config .. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16247
https://github.com/root-project/root/pull/16248:141,deployability,updat,updated,141,Numpybridge with resize stdcopy rchunkloader; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16248
https://github.com/root-project/root/pull/16248:111,safety,test,tested,111,Numpybridge with resize stdcopy rchunkloader; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16248
https://github.com/root-project/root/pull/16248:141,safety,updat,updated,141,Numpybridge with resize stdcopy rchunkloader; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16248
https://github.com/root-project/root/pull/16248:141,security,updat,updated,141,Numpybridge with resize stdcopy rchunkloader; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16248
https://github.com/root-project/root/pull/16248:111,testability,test,tested,111,Numpybridge with resize stdcopy rchunkloader; # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16248
https://github.com/root-project/root/issues/16249:816,availability,Operat,Operating,816,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16249:759,deployability,version,version,759,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16249:781,deployability,Instal,Installation,781,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16249:759,integrability,version,version,759,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16249:759,modifiability,version,version,759,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16249:27,reliability,doe,does,27,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16249:870,testability,context,context,870,"Iterating with a range for does one extra iteration; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. The following code:. ```. void foo() {. std::unique_ptr<TFile> digitfile(TFile::Open(""emcaldigits.root"", ""READ""));. auto treereader = std::make_unique<TTreeReader>(static_cast<TTree*>(digitfile->Get(""o2sim"")));. std::cout << treereader->GetEntries() << std::endl;. TTreeReaderValue<std::vector<o2::emcal::Digit>> digitbranch(*treereader, ""EMCALDigit"");. TTreeReaderValue<std::vector<o2::emcal::TriggerRecord>> triggerbranch(*treereader, ""EMCALDigitTRGR"");. for (auto &d : *treereader) {. std::cout << ""Foo"" << std::endl;. }. }. ```. iterates once on an empty tree (0 entries). Is that expected? ### Reproducer. See above. ### ROOT version. 6.30.0x. ### Installation method. aliBuild. ### Operating system. Linux on ARM, macOS. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16249
https://github.com/root-project/root/issues/16250:437,availability,error,error,437,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:13,deployability,build,build,13,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:202,deployability,depend,dependency,202,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:376,deployability,depend,dependency,376,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:390,deployability,build,build,390,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:450,deployability,configurat,configuration,450,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:488,deployability,build,build,488,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:202,integrability,depend,dependency,202,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:376,integrability,depend,dependency,376,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:450,integrability,configur,configuration,450,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:346,interoperability,plug,plugin,346,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:202,modifiability,depend,dependency,202,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:376,modifiability,depend,dependency,376,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:450,modifiability,configur,configuration,450,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:396,performance,time,time,396,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:437,performance,error,error,437,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:464,performance,time,time,464,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:5,reliability,doe,doesn,5,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:202,safety,depend,dependency,202,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:376,safety,depend,dependency,376,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:437,safety,error,error,437,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:450,security,configur,configuration,450,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:202,testability,depend,dependency,202,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:376,testability,depend,dependency,376,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16250:437,usability,error,error,437,"ROOT doesn't build anymore with `opengl=ON` and `asimage=OFF`; See also this discussion here:. https://github.com/root-project/root/pull/15812#issuecomment-2252107168. The PR #15812 introduced a direct dependency of `graf3d/gl` on TASImage, which is only built if `asimage=ON`. It would be better if the PNG export would be done via the `TImage` plugin system, so there is no dependency at build time. Or if this can't be done, at least error out at configuration time if one attempts to build with this combination of flags. Here is the culprit:. https://github.com/root-project/root/blob/master/graf3d/gl/src/TGLSdfFontMaker.cxx#L198. @osschar @linev . See also:. * https://root.cern.ch/doc/master/classTASImage.html. * https://root.cern/doc/master/imgconv_8C.html",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16250
https://github.com/root-project/root/issues/16252:77,availability,failur,failure,77,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:222,availability,down,down,222,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:303,availability,error,error,303,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:63,deployability,Fail,Failed,63,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:77,deployability,fail,failure,77,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:292,deployability,fail,fails,292,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:326,deployability,contain,contains,326,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:583,deployability,contain,contains,583,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:662,deployability,build,build,662,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:710,deployability,modul,module,710,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:149,energy efficiency,core,cores,149,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:193,energy efficiency,reduc,reducing,193,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:216,energy efficiency,core,cores,216,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:233,energy efficiency,core,cores,233,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:967,energy efficiency,core,cores,967,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:359,integrability,event,event,359,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:404,integrability,event,event,404,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:449,integrability,event,event,449,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:494,integrability,event,event,494,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:539,integrability,event,event,539,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:710,modifiability,modul,module,710,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:77,performance,failur,failure,77,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:107,performance,memor,memory,107,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:303,performance,error,error,303,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:9,reliability,rca,rcanvas-,9,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:45,reliability,rca,rcanvas-,45,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:63,reliability,Fail,Failed,63,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:77,reliability,fail,failure,77,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:292,reliability,fail,fails,292,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:678,reliability,rca,rcanvas,678,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:248,safety,test,test,248,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:273,safety,compl,complete,273,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:303,safety,error,error,303,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:710,safety,modul,module,710,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:273,security,compl,complete,273,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:248,testability,test,test,248,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:599,testability,Trace,Traceback,599,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:107,usability,memor,memory,107,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/issues/16252:303,usability,error,error,303,"tutorial-rcanvas-df104-py; > 1261 - tutorial-rcanvas-df104-py (Failed). This failure seems to be linked to memory limitation. On my node there is 48 cores but the `ulimit` is set to 16Gb. When reducing the number of cores down to 35 cores then the test starts to sometimes complete sometimes fails. The error output sometimes contains:. ```. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. RDataFrame::Run: event loop was interrupted. ```. and always contains:. ```. Traceback (most recent call last):. File ""/github/home/ROOT-CI/build/tutorials/rcanvas/df104.py"", line 89, in <module>. ROOT.RDF.RunGraphs([hists[s] for s in [""ggH"", ""VBF"", ""data""]]). cppyy.gbl.std.bad_alloc: unsigned int ROOT::RDF::RunGraphs(vector<ROOT::RDF::RResultHandle>) =>. bad_alloc: std::bad_alloc. ```. **And indeed, the process easily reaches 16Gb. With 32 cores, the peak is 15Gb.**.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16252
https://github.com/root-project/root/pull/16253:33,availability,error,error,33,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:71,availability,error,errors,71,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:27,deployability,build,build,27,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:99,deployability,build,builds,99,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:33,performance,error,error,33,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:71,performance,error,errors,71,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:33,safety,error,error,33,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:71,safety,error,errors,71,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:33,usability,error,error,33,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16253:71,usability,error,errors,71,[cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16253
https://github.com/root-project/root/pull/16254:40,availability,error,error,40,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:78,availability,error,errors,78,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:34,deployability,build,build,34,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:106,deployability,build,builds,106,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:40,performance,error,error,40,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:78,performance,error,errors,78,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:40,safety,error,error,40,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:78,safety,error,errors,78,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:40,usability,error,error,40,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16254:78,usability,error,errors,78,[v6-32][cmake][win] Fix potential build error of cfitsio; This should fix the errors we see in the nighly builds on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16254
https://github.com/root-project/root/pull/16255:197,deployability,build,build,197,[CMake] Avoid duplicate linking against gtest; Following up on 1bd63965cf1 to avoid warnings like these on macOS:. ```. ld: warning: ignoring duplicate libraries: 'googletest-prefix/src/googletest-build/lib//libgtest.a'. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16255
https://github.com/root-project/root/pull/16255:8,safety,Avoid,Avoid,8,[CMake] Avoid duplicate linking against gtest; Following up on 1bd63965cf1 to avoid warnings like these on macOS:. ```. ld: warning: ignoring duplicate libraries: 'googletest-prefix/src/googletest-build/lib//libgtest.a'. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16255
https://github.com/root-project/root/pull/16255:78,safety,avoid,avoid,78,[CMake] Avoid duplicate linking against gtest; Following up on 1bd63965cf1 to avoid warnings like these on macOS:. ```. ld: warning: ignoring duplicate libraries: 'googletest-prefix/src/googletest-build/lib//libgtest.a'. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16255
https://github.com/root-project/root/issues/16256:1296,availability,Operat,Operating,1296,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:786,deployability,version,version,786,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:1258,deployability,Instal,Installation,1258,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:786,integrability,version,version,786,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:298,interoperability,xml,xml,298,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:786,modifiability,version,version,786,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:390,performance,memor,memory,390,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:373,safety,avoid,avoids,373,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:941,security,Team,Team,941,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:1343,testability,context,context,1343,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:390,usability,memor,memory,390,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/issues/16256:1120,usability,help,help,1120,"Allow multiple calls to REFLEX_GENERATE_DICTIONARY; ### Explain what you would like to see improved and how. The CMake function `REFLEX_GENERATE_DICTIONARY` can only be called once for each CMake target as it generates a file based on the target name. . In CMS code, we allow multiple classes_def*.xml files for each library being created. This has sped up compilation and avoids excessing memory use by the compiler. Because of the restriction in `REFLEX_GENERATE_DICTIONARY` , my experiments to use CMake to generate some CMSSW code was unable to use that function. It appears that if `REFLEX_GENERATE_DICTIONARY` used part of the name of the `SELECTION` argument for the generate class name it could be possible to have multiple calls to the function for the same target. . ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.33.01 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jul 22 2024, 08:52:38 |. | From heads/master@tags/v6-33-01 |. | With g++ (GCC) 12.3.1 20230527 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. from source. ### Operating system. Linux alma 8. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16256
https://github.com/root-project/root/pull/16259:594,deployability,updat,updated,594,"[geom] TGeoTessellated: fix facet surface calculation; # This Pull request:. ## Changes or fixes:. Fixes an issue in the facet surface area calculation which was mixing vertex indexing at the facet level and at the shape level, resulting in spurious surface area warnings. `surfaceArea += 0.5 * Vertex_t::Cross(e1, e2).Mag()` works when `e1` and `e2` are chords within the same facet. That is only guaranteed when using the direction provided by `facet = fFacets[ifacet]` and `fVertices[facet[i + 1]]`, not by using `GetVertex(i+1)` directly. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16259
https://github.com/root-project/root/pull/16259:564,safety,test,tested,564,"[geom] TGeoTessellated: fix facet surface calculation; # This Pull request:. ## Changes or fixes:. Fixes an issue in the facet surface area calculation which was mixing vertex indexing at the facet level and at the shape level, resulting in spurious surface area warnings. `surfaceArea += 0.5 * Vertex_t::Cross(e1, e2).Mag()` works when `e1` and `e2` are chords within the same facet. That is only guaranteed when using the direction provided by `facet = fFacets[ifacet]` and `fVertices[facet[i + 1]]`, not by using `GetVertex(i+1)` directly. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16259
https://github.com/root-project/root/pull/16259:594,safety,updat,updated,594,"[geom] TGeoTessellated: fix facet surface calculation; # This Pull request:. ## Changes or fixes:. Fixes an issue in the facet surface area calculation which was mixing vertex indexing at the facet level and at the shape level, resulting in spurious surface area warnings. `surfaceArea += 0.5 * Vertex_t::Cross(e1, e2).Mag()` works when `e1` and `e2` are chords within the same facet. That is only guaranteed when using the direction provided by `facet = fFacets[ifacet]` and `fVertices[facet[i + 1]]`, not by using `GetVertex(i+1)` directly. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16259
https://github.com/root-project/root/pull/16259:594,security,updat,updated,594,"[geom] TGeoTessellated: fix facet surface calculation; # This Pull request:. ## Changes or fixes:. Fixes an issue in the facet surface area calculation which was mixing vertex indexing at the facet level and at the shape level, resulting in spurious surface area warnings. `surfaceArea += 0.5 * Vertex_t::Cross(e1, e2).Mag()` works when `e1` and `e2` are chords within the same facet. That is only guaranteed when using the direction provided by `facet = fFacets[ifacet]` and `fVertices[facet[i + 1]]`, not by using `GetVertex(i+1)` directly. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16259
https://github.com/root-project/root/pull/16259:564,testability,test,tested,564,"[geom] TGeoTessellated: fix facet surface calculation; # This Pull request:. ## Changes or fixes:. Fixes an issue in the facet surface area calculation which was mixing vertex indexing at the facet level and at the shape level, resulting in spurious surface area warnings. `surfaceArea += 0.5 * Vertex_t::Cross(e1, e2).Mag()` works when `e1` and `e2` are chords within the same facet. That is only guaranteed when using the direction provided by `facet = fFacets[ifacet]` and `fVertices[facet[i + 1]]`, not by using `GetVertex(i+1)` directly. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16259
https://github.com/root-project/root/pull/16260:13,deployability,Updat,Update,13,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:115,deployability,build,build,115,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:139,deployability,Updat,Update,139,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:184,deployability,version,version,184,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:247,deployability,build,build,247,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:184,integrability,version,version,184,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:128,interoperability,platform,platforms,128,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:184,modifiability,version,version,184,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:13,safety,Updat,Update,13,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:139,safety,Updat,Update,139,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:200,safety,detect,detect,200,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:13,security,Updat,Update,13,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:139,security,Updat,Update,139,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16260:200,security,detect,detect,200,"[afterimage] Update to latest config.guess; Now that `builtin_afterimage` is deprecated and always `ON`, it has to build on all platforms. Update `config.guess` to the latest upstream version to auto-detect `riscv64-unknown-linux-gnu` and fix the build.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16260
https://github.com/root-project/root/pull/16261:51,safety,Avoid,Avoids,51,[ntuple] Add virtual destructor of RPageAllocator; Avoids the following compiler warning by Clang:. ```. delete called on non-final 'ROOT::Experimental::Internal::RPageAllocatorHeap' that has virtual functions but non-virtual destructor. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16261
https://github.com/root-project/root/pull/16262:182,deployability,updat,updated,182,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:140,energy efficiency,core,core,140,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:67,performance,memor,memory,67,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:129,performance,memor,memory,129,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:51,safety,avoid,avoid,51,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:152,safety,test,tested,152,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:182,safety,updat,updated,182,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:182,security,updat,updated,182,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:152,testability,test,tested,152,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:67,usability,memor,memory,67,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16262:129,usability,memor,memory,129,"[Tutorials] Fix Thread Pool size for tutorials; to avoid excessive memory usage, which can lead to issues on machines with a low memory per core. - [v] tested changes locally. - [v] updated the docs (if necessary). Fixes #16252.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16262
https://github.com/root-project/root/pull/16263:36,availability,replic,replicate,36,[ci] Improve instructions on how to replicate builds locally; Fixes #16242.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16263
https://github.com/root-project/root/pull/16263:46,deployability,build,builds,46,[ci] Improve instructions on how to replicate builds locally; Fixes #16242.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16263
https://github.com/root-project/root/pull/16264:45,usability,document,documentation,45,[doc] Remove all non-legacy links to the old documentation url; Fixes #15962.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16264
https://github.com/root-project/root/pull/16265:1,reliability,rca,rcanvas,1,[rcanvas] Adjust df104.py tutorial; Disable stats for background. Adjust axis title offsets.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16265
https://github.com/root-project/root/pull/16267:12,deployability,build,build,12,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:94,deployability,build,build,94,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:136,deployability,build,building,136,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:227,deployability,build,build,227,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:365,deployability,updat,updated,365,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:335,safety,test,tested,335,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:365,safety,updat,updated,365,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:365,security,updat,updated,365,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16267:335,testability,test,tested,335,"[cmake] add build option for html, disabled by default; # This Pull request:. adds the `html` build options to allow enabling/disabling building of THtml-related code. . Setting the flag to **OFF** by default (meaning we won't build html anymore by default), since we intend to deprecate THtml in the near future. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16267
https://github.com/root-project/root/pull/16268:62,availability,Restor,Restore,62,"[cling] Fix `DelegateGenerator` on macOS; Commit 785c9df34d (""Restore symbol lookup in child interpreters"") added a `DefinitionGenerator` to allow symbol lookup in the parent `IncrementalJIT` after the upgrade to LLVM 13. It appears that instead of the unmangled name, we need to lookup already linker mangled names. This fixes the tests `CodeUnloading/AtExit.C` and `MultipleInterpreters/MultipleInterpreters.C` on macOS, which adds an underscore during linker mangling. No change on Linux because there is no additional linker name mangling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16268
https://github.com/root-project/root/pull/16268:202,deployability,upgrad,upgrade,202,"[cling] Fix `DelegateGenerator` on macOS; Commit 785c9df34d (""Restore symbol lookup in child interpreters"") added a `DefinitionGenerator` to allow symbol lookup in the parent `IncrementalJIT` after the upgrade to LLVM 13. It appears that instead of the unmangled name, we need to lookup already linker mangled names. This fixes the tests `CodeUnloading/AtExit.C` and `MultipleInterpreters/MultipleInterpreters.C` on macOS, which adds an underscore during linker mangling. No change on Linux because there is no additional linker name mangling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16268
https://github.com/root-project/root/pull/16268:202,modifiability,upgrad,upgrade,202,"[cling] Fix `DelegateGenerator` on macOS; Commit 785c9df34d (""Restore symbol lookup in child interpreters"") added a `DefinitionGenerator` to allow symbol lookup in the parent `IncrementalJIT` after the upgrade to LLVM 13. It appears that instead of the unmangled name, we need to lookup already linker mangled names. This fixes the tests `CodeUnloading/AtExit.C` and `MultipleInterpreters/MultipleInterpreters.C` on macOS, which adds an underscore during linker mangling. No change on Linux because there is no additional linker name mangling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16268
https://github.com/root-project/root/pull/16268:62,reliability,Restor,Restore,62,"[cling] Fix `DelegateGenerator` on macOS; Commit 785c9df34d (""Restore symbol lookup in child interpreters"") added a `DefinitionGenerator` to allow symbol lookup in the parent `IncrementalJIT` after the upgrade to LLVM 13. It appears that instead of the unmangled name, we need to lookup already linker mangled names. This fixes the tests `CodeUnloading/AtExit.C` and `MultipleInterpreters/MultipleInterpreters.C` on macOS, which adds an underscore during linker mangling. No change on Linux because there is no additional linker name mangling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16268
https://github.com/root-project/root/pull/16268:332,safety,test,tests,332,"[cling] Fix `DelegateGenerator` on macOS; Commit 785c9df34d (""Restore symbol lookup in child interpreters"") added a `DefinitionGenerator` to allow symbol lookup in the parent `IncrementalJIT` after the upgrade to LLVM 13. It appears that instead of the unmangled name, we need to lookup already linker mangled names. This fixes the tests `CodeUnloading/AtExit.C` and `MultipleInterpreters/MultipleInterpreters.C` on macOS, which adds an underscore during linker mangling. No change on Linux because there is no additional linker name mangling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16268
https://github.com/root-project/root/pull/16268:332,testability,test,tests,332,"[cling] Fix `DelegateGenerator` on macOS; Commit 785c9df34d (""Restore symbol lookup in child interpreters"") added a `DefinitionGenerator` to allow symbol lookup in the parent `IncrementalJIT` after the upgrade to LLVM 13. It appears that instead of the unmangled name, we need to lookup already linker mangled names. This fixes the tests `CodeUnloading/AtExit.C` and `MultipleInterpreters/MultipleInterpreters.C` on macOS, which adds an underscore during linker mangling. No change on Linux because there is no additional linker name mangling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16268
https://github.com/root-project/root/issues/16269:805,availability,Operat,Operating,805,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:345,deployability,instal,install,345,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:744,deployability,version,version,744,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:767,deployability,Instal,Installation,767,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:744,integrability,version,version,744,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:186,interoperability,platform,platforms,186,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:744,modifiability,version,version,744,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:456,safety,test,test,456,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:462,safety,test,test,462,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:456,testability,test,test,456,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:462,testability,test,test,462,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16269:863,testability,context,context,863,"Problems using `std::filesystem` in standalone `cling`; ### Description. `libstdc++` provides `std::filesystem` symbols in a static archive `libstdc++fs.a`. This causes problems on some platforms because the linker might strip the symbols. See https://github.com/root-project/root/issues/11601 and the note on `devtoolset`s in https://root.cern/install/build_from_source/#caveats for instances of similar problems. If a proper solution is found, the Cling test `test/Prompt/ValuePrinter/FileSystemPath.C` should be re-enabled (it was disabled in https://github.com/root-project/root/pull/16258). ### Reproducer. Try to run in standalone `cling`:. ```. #include <filesystem>. auto p = std::filesystem::path(""/some/path/foo.cpp"");. ```. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux, with `libstdc++`. ### Additional context. It seems to work in ROOT itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16269
https://github.com/root-project/root/issues/16270:305,integrability,event,eventually,305,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:203,interoperability,platform,platform,203,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:49,safety,test,tests,49,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:162,safety,test,tests,162,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:268,safety,test,tests,268,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:49,testability,test,tests,49,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:162,testability,test,tests,162,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/issues/16270:268,testability,test,tests,268,"[cling] Problems with many DynamicLibraryManager tests on macOS; https://github.com/root-project/root/pull/16258 proposes to disable many `DynamicLibraryManager` tests on macOS that never worked on that platform since their introduction (they pass fine on Linux). The tests should be debugged, fixed, and eventually re-enabled.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16270
https://github.com/root-project/root/pull/16271:23,deployability,build,build,23,Move all files out of `build/win`; The header files in `build/win` were moved to `cmake/win`. The new directory was chosen to be `cmake/win` because these files are referred to exclusively in the CMake modules. The remaining files were moved to `misc/win`. This is another step towards closing #8031.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271
https://github.com/root-project/root/pull/16271:56,deployability,build,build,56,Move all files out of `build/win`; The header files in `build/win` were moved to `cmake/win`. The new directory was chosen to be `cmake/win` because these files are referred to exclusively in the CMake modules. The remaining files were moved to `misc/win`. This is another step towards closing #8031.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271
https://github.com/root-project/root/pull/16271:202,deployability,modul,modules,202,Move all files out of `build/win`; The header files in `build/win` were moved to `cmake/win`. The new directory was chosen to be `cmake/win` because these files are referred to exclusively in the CMake modules. The remaining files were moved to `misc/win`. This is another step towards closing #8031.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271
https://github.com/root-project/root/pull/16271:202,modifiability,modul,modules,202,Move all files out of `build/win`; The header files in `build/win` were moved to `cmake/win`. The new directory was chosen to be `cmake/win` because these files are referred to exclusively in the CMake modules. The remaining files were moved to `misc/win`. This is another step towards closing #8031.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271
https://github.com/root-project/root/pull/16271:202,safety,modul,modules,202,Move all files out of `build/win`; The header files in `build/win` were moved to `cmake/win`. The new directory was chosen to be `cmake/win` because these files are referred to exclusively in the CMake modules. The remaining files were moved to `misc/win`. This is another step towards closing #8031.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16271
https://github.com/root-project/root/pull/16272:10,usability,support,support,10,[webgeom] support TGeoTrack creation; For some reason implemented in painter and not in TGeoManager itself. Fixes https://github.com/root-project/root/issues/16167.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16272
https://github.com/root-project/root/pull/16273:76,availability,failur,failures,76,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:18,deployability,build,building,18,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:76,deployability,fail,failures,76,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:76,performance,failur,failures,76,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:76,reliability,fail,failures,76,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:13,safety,test,test,13,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:114,safety,test,tests,114,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:13,testability,test,test,13,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16273:114,testability,test,tests,114,[cmake] Make test building serial on Windows; Should decrease the number of failures and retries when running the tests on Windows.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16273
https://github.com/root-project/root/pull/16274:172,deployability,version,versions,172,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:196,deployability,depend,dependencies,196,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:522,deployability,manag,manager,522,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:688,deployability,manag,manager,688,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:699,deployability,manag,manage,699,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:706,deployability,depend,dependencies,706,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:522,energy efficiency,manag,manager,522,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:688,energy efficiency,manag,manager,688,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:699,energy efficiency,manag,manage,699,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:172,integrability,version,versions,172,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:196,integrability,depend,dependencies,196,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:706,integrability,depend,dependencies,706,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:486,interoperability,compatib,compatible,486,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:172,modifiability,version,versions,172,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:196,modifiability,depend,dependencies,196,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:514,modifiability,pac,package,514,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:680,modifiability,pac,package,680,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:706,modifiability,depend,dependencies,706,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:144,reliability,doe,doesn,144,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:196,safety,depend,dependencies,196,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:448,safety,avoid,avoid,448,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:522,safety,manag,manager,522,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:556,safety,compl,completely,556,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:688,safety,manag,manager,688,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:699,safety,manag,manage,699,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:706,safety,depend,dependencies,706,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:64,security,modif,modifies,64,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:224,security,hack,hacky,224,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:459,security,hack,hack,459,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:544,security,hack,hack,544,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:556,security,compl,completely,556,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:196,testability,depend,dependencies,196,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:706,testability,depend,dependencies,706,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16274:408,usability,close,closes,408,"[CMake] Only replace `find_package` if required; Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16274
https://github.com/root-project/root/pull/16275:199,modifiability,refact,refactor,199,"[CMake] Forward common CMake flags to builtin TBB; This is already done the same way for many other external projects, like. Clad, etc. Closes https://github.com/root-project/root/issues/8815. Also, refactor some CMake code to avoid code duplication.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16275
https://github.com/root-project/root/pull/16275:199,performance,refactor,refactor,199,"[CMake] Forward common CMake flags to builtin TBB; This is already done the same way for many other external projects, like. Clad, etc. Closes https://github.com/root-project/root/issues/8815. Also, refactor some CMake code to avoid code duplication.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16275
https://github.com/root-project/root/pull/16275:227,safety,avoid,avoid,227,"[CMake] Forward common CMake flags to builtin TBB; This is already done the same way for many other external projects, like. Clad, etc. Closes https://github.com/root-project/root/issues/8815. Also, refactor some CMake code to avoid code duplication.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16275
https://github.com/root-project/root/pull/16275:136,usability,Close,Closes,136,"[CMake] Forward common CMake flags to builtin TBB; This is already done the same way for many other external projects, like. Clad, etc. Closes https://github.com/root-project/root/issues/8815. Also, refactor some CMake code to avoid code duplication.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16275
https://github.com/root-project/root/pull/16278:101,availability,failur,failures,101,"Revert ""[CMake] Only replace `find_package` if required""; This reverts commit 2a265a3a, which caused failures in the nightlies even though the CI in #16274 was green.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16278
https://github.com/root-project/root/pull/16278:101,deployability,fail,failures,101,"Revert ""[CMake] Only replace `find_package` if required""; This reverts commit 2a265a3a, which caused failures in the nightlies even though the CI in #16274 was green.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16278
https://github.com/root-project/root/pull/16278:160,energy efficiency,green,green,160,"Revert ""[CMake] Only replace `find_package` if required""; This reverts commit 2a265a3a, which caused failures in the nightlies even though the CI in #16274 was green.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16278
https://github.com/root-project/root/pull/16278:101,performance,failur,failures,101,"Revert ""[CMake] Only replace `find_package` if required""; This reverts commit 2a265a3a, which caused failures in the nightlies even though the CI in #16274 was green.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16278
https://github.com/root-project/root/pull/16278:101,reliability,fail,failures,101,"Revert ""[CMake] Only replace `find_package` if required""; This reverts commit 2a265a3a, which caused failures in the nightlies even though the CI in #16274 was green.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16278
https://github.com/root-project/root/pull/16279:36,deployability,build,builds,36,[v632][CMake] Fix ROOT_ADD_GTEST in builds with `testing=OFF`; Backport two PRs to fix the usage of the `ROOT_ADD_GTEST` macro in builds with `testing=OFF`. * https://github.com/root-project/root/pull/16243. * https://github.com/root-project/root/pull/16255.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16279
https://github.com/root-project/root/pull/16279:130,deployability,build,builds,130,[v632][CMake] Fix ROOT_ADD_GTEST in builds with `testing=OFF`; Backport two PRs to fix the usage of the `ROOT_ADD_GTEST` macro in builds with `testing=OFF`. * https://github.com/root-project/root/pull/16243. * https://github.com/root-project/root/pull/16255.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16279
https://github.com/root-project/root/pull/16279:49,safety,test,testing,49,[v632][CMake] Fix ROOT_ADD_GTEST in builds with `testing=OFF`; Backport two PRs to fix the usage of the `ROOT_ADD_GTEST` macro in builds with `testing=OFF`. * https://github.com/root-project/root/pull/16243. * https://github.com/root-project/root/pull/16255.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16279
https://github.com/root-project/root/pull/16279:143,safety,test,testing,143,[v632][CMake] Fix ROOT_ADD_GTEST in builds with `testing=OFF`; Backport two PRs to fix the usage of the `ROOT_ADD_GTEST` macro in builds with `testing=OFF`. * https://github.com/root-project/root/pull/16243. * https://github.com/root-project/root/pull/16255.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16279
https://github.com/root-project/root/pull/16279:49,testability,test,testing,49,[v632][CMake] Fix ROOT_ADD_GTEST in builds with `testing=OFF`; Backport two PRs to fix the usage of the `ROOT_ADD_GTEST` macro in builds with `testing=OFF`. * https://github.com/root-project/root/pull/16243. * https://github.com/root-project/root/pull/16255.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16279
https://github.com/root-project/root/pull/16279:143,testability,test,testing,143,[v632][CMake] Fix ROOT_ADD_GTEST in builds with `testing=OFF`; Backport two PRs to fix the usage of the `ROOT_ADD_GTEST` macro in builds with `testing=OFF`. * https://github.com/root-project/root/pull/16243. * https://github.com/root-project/root/pull/16255.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16279
https://github.com/root-project/root/pull/16280:33,deployability,version,version,33,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16280:111,deployability,version,version,111,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16280:1,energy efficiency,core,core,1,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16280:33,integrability,version,version,33,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16280:111,integrability,version,version,111,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16280:33,modifiability,version,version,33,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16280:111,modifiability,version,version,111,[core] Increment MemInfo_t class version; PR #14695 changed the class layout but forgot to increment the class version.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16280
https://github.com/root-project/root/pull/16281:17,availability,error,error,17,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:81,availability,error,error,81,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:326,availability,avail,available,326,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:941,availability,avail,available,941,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1421,availability,error,errors,1421,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:111,deployability,build,build,111,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:491,deployability,modul,module,491,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:570,deployability,instal,install,570,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1105,deployability,modul,module,1105,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1184,deployability,instal,install,1184,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1431,deployability,Fail,Failed,1431,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:783,energy efficiency,load,load,783,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:87,integrability,messag,message,87,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:87,interoperability,messag,message,87,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:491,modifiability,modul,module,491,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1105,modifiability,modul,module,1105,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:17,performance,error,error,17,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:81,performance,error,error,81,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:783,performance,load,load,783,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1421,performance,error,errors,1421,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:163,reliability,doe,doesn,163,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:326,reliability,availab,available,326,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:941,reliability,availab,available,941,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1431,reliability,Fail,Failed,1431,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:17,safety,error,error,17,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:81,safety,error,error,81,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:326,safety,avail,available,326,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:491,safety,modul,module,491,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:941,safety,avail,available,941,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1105,safety,modul,module,1105,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1421,safety,error,errors,1421,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:326,security,availab,available,326,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:941,security,availab,available,941,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:376,testability,Trace,Traceback,376,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:991,testability,Trace,Traceback,991,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:17,usability,error,error,17,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:81,usability,error,error,81,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:438,usability,support,support,438,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1053,usability,support,support,1053,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1421,usability,error,errors,1421,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16281:1484,usability,Close,Closes,1484,"[PyROOT] Improve error handling for AsNumpy with unreadable objects; Improve the error message when you try to build NumPy arrays with types. that the interpreter doesn't know about. Running the reproducer from the JIRA ticket, one now gets this output:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 13, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 243, in RDataFrameAsNumpy. raise RuntimeError(. RuntimeError: The column named ""foo"" is of type ""Foo"", which is not known to the ROOT interpreter. Please load the corresponding header files or dictionaries. ```. This was the output before:. ```txt. TClass::Init:0: RuntimeWarning: no dictionary for class Foo is available. { ""a"", ""b"", ""foo"", ""foo.a"", ""foo.b"" }. Traceback (most recent call last):. File ""/home/rembserj/root-support/jira/ROOT-10930/reproducer.py"", line 5, in <module>. print(df.AsNumpy()). ^^^^^^^^^^^^. File ""/home/rembserj/spaces/master/install/lib/root/ROOT/_pythonization/_rdataframe.py"", line 236, in RDataFrameAsNumpy. result_ptrs[column] = df.Take[column_type](column). ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TypeError: Could not find ""Take<Foo>"" (set cppyy.set_debug() for C++ errors):. Failed to instantiate ""Take<Foo>(std::string)"". ```. Closes the following Jira issue:. https://its.cern.ch/jira/browse/ROOT-10930",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16281
https://github.com/root-project/root/pull/16282:151,availability,Operat,Operator,151,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:419,availability,Operat,Operators,419,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:14,deployability,Updat,Updating,14,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:102,deployability,Updat,Updates,102,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:275,deployability,scale,scale,275,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:477,deployability,Updat,Updated,477,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:627,deployability,updat,updated,627,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:275,energy efficiency,scale,scale,275,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:23,integrability,Batch,BatchNormalization,23,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:132,integrability,Batch,BatchNormalization,132,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:432,integrability,Batch,BatchNormalization,432,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:188,modifiability,paramet,parametric,188,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:275,modifiability,scal,scale,275,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:557,modifiability,paramet,parametric,557,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:23,performance,Batch,BatchNormalization,23,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:132,performance,Batch,BatchNormalization,132,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:275,performance,scale,scale,275,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:432,performance,Batch,BatchNormalization,432,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:14,safety,Updat,Updating,14,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:66,safety,input,input,66,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:102,safety,Updat,Updates,102,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:169,safety,input,input,169,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:213,safety,input,input,213,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:477,safety,Updat,Updated,477,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:597,safety,test,tested,597,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:627,safety,updat,updated,627,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:14,security,Updat,Updating,14,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:102,security,Updat,Updates,102,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:477,security,Updat,Updated,477,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:627,security,updat,updated,627,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:597,testability,test,tested,597,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:66,usability,input,input,66,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:169,usability,input,input,169,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:213,usability,input,input,213,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16282:360,usability,Document,Documentation,360,"[tmva][sofie] Updating BatchNormalization Op to handle paramteric input tensor; # This Pull request:. Updates the implementation of BatchNormalization Operator to parse input tensors with parametric shapes. - `x` input tensor can have shapes of form `{dim1, dim2, dim3}`. - `scale`, `B`, `input_mean`, `input_var` tensors need to be initialized tensors. [ONNX Documentation](https://github.com/onnx/onnx/blob/main/docs/Operators.md#BatchNormalization). ## Changes or fixes:. - Updated implementation in the `ROperator_BatchNormalization.hxx` file to handle parametric shapes. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16282
https://github.com/root-project/root/pull/16284:529,availability,down,down,529,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:17,deployability,automat,automatic,17,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:318,deployability,automat,automatically,318,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:372,deployability,automat,automatic,372,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:122,performance,memor,memory,122,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:534,performance,memor,memory,534,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:9,safety,Prevent,Prevent,9,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:358,safety,prevent,prevents,358,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:9,security,Preven,Prevent,9,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:160,security,sign,significantly,160,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:358,security,preven,prevents,358,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:17,testability,automat,automatic,17,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:318,testability,automat,automatically,318,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:372,testability,automat,automatic,372,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:72,usability,help,helpers,72,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:122,usability,memor,memory,122,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16284:534,usability,memor,memory,534,"[ntuple] Prevent automatic instantiation of `RSimpleField<T>`; With the helpers for column creation introduced by #16116, memory consumption during compilation significantly increases (from ~200MB to ~600MB using clang) due to the fact that templated field types, and therefore all possible column representations are automatically instantiated. This commit prevents this automatic instantiation from happening by `extern`-alizing all `RSimpleField` template specializations and only instantiating them in `RField.cxx`, bringing down memory consumption to ~230MB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16284
https://github.com/root-project/root/pull/16285:156,availability,error,error,156,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:94,deployability,build,build,94,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:150,deployability,build,build,150,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:172,deployability,observ,observed,172,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:329,deployability,version,versions,329,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:353,deployability,depend,dependencies,353,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:679,deployability,manag,manager,679,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:845,deployability,manag,manager,845,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:856,deployability,manag,manage,856,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:863,deployability,depend,dependencies,863,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:679,energy efficiency,manag,manager,679,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:845,energy efficiency,manag,manager,845,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:856,energy efficiency,manag,manage,856,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:329,integrability,version,versions,329,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:353,integrability,depend,dependencies,353,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:863,integrability,depend,dependencies,863,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:643,interoperability,compatib,compatible,643,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:329,modifiability,version,versions,329,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:353,modifiability,depend,dependencies,353,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:671,modifiability,pac,package,671,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:837,modifiability,pac,package,837,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:863,modifiability,depend,dependencies,863,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:156,performance,error,error,156,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:301,reliability,doe,doesn,301,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:156,safety,error,error,156,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:353,safety,depend,dependencies,353,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:605,safety,avoid,avoid,605,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:679,safety,manag,manager,679,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:713,safety,compl,completely,713,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:845,safety,manag,manager,845,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:856,safety,manag,manage,856,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:863,safety,depend,dependencies,863,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:221,security,modif,modifies,221,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:381,security,hack,hacky,381,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:616,security,hack,hack,616,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:701,security,hack,hack,701,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:713,security,compl,completely,713,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:172,testability,observ,observed,172,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:353,testability,depend,dependencies,353,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:863,testability,depend,dependencies,863,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:88,usability,clear,clear,88,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:156,usability,error,error,156,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16285:565,usability,close,closes,565,"[CMake] Only replace `find_package` if required; **This is a replay of #16274 with the ""clear build"" label for the CI, to see if we can reproduce the build error that were observed after merging said PR**. Our CMake code modifies `find_package` to ignore any ROOT builtins, such that the builtin LLVM doesn't find and use system versions of the builtin dependencies. This is a bit hacky, but fortunately this needs to be done only when builtins are used. Therefore, this commit suggests to only do this redefinition of `find_package` if any builtins are used. This closes #8633, where it was requested to avoid this hack for the sake of being compatible with the `vcpkg` package manager. Although the hack is not completely removed, it is removed for the case where not builtins are used, which is probably what is done when using a C++ package manager to manage dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16285
https://github.com/root-project/root/pull/16286:30,usability,Close,Closes,30,[ci] Enable clad on mac beta; Closes #15912.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16286
https://github.com/root-project/root/pull/16287:21,performance,memor,memory,21,[tree] fix potential memory leak in TFriendElement constructor; Return value of `Compress()` function must be always deleted.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16287
https://github.com/root-project/root/pull/16287:21,usability,memor,memory,21,[tree] fix potential memory leak in TFriendElement constructor; Return value of `Compress()` function must be always deleted.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16287
https://github.com/root-project/root/pull/16289:6,deployability,build,build,6,"Move `build/unix` to `cmake/unix`; As most of the files in `build/unix` were referenced by the `CMakeLists.txt`, moving the `unix` directory to `cmake` is a reasonable choice. There are scripts like `makereleasenotes.sh` and `pandoc-jira.sh` that are not related to CMake, but there were not related to the build process either (and also not unix either, for that matter). A better place for these scripts could be found in a followup commit if desired. Closes #8031.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16289
https://github.com/root-project/root/pull/16289:60,deployability,build,build,60,"Move `build/unix` to `cmake/unix`; As most of the files in `build/unix` were referenced by the `CMakeLists.txt`, moving the `unix` directory to `cmake` is a reasonable choice. There are scripts like `makereleasenotes.sh` and `pandoc-jira.sh` that are not related to CMake, but there were not related to the build process either (and also not unix either, for that matter). A better place for these scripts could be found in a followup commit if desired. Closes #8031.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16289
https://github.com/root-project/root/pull/16289:307,deployability,build,build,307,"Move `build/unix` to `cmake/unix`; As most of the files in `build/unix` were referenced by the `CMakeLists.txt`, moving the `unix` directory to `cmake` is a reasonable choice. There are scripts like `makereleasenotes.sh` and `pandoc-jira.sh` that are not related to CMake, but there were not related to the build process either (and also not unix either, for that matter). A better place for these scripts could be found in a followup commit if desired. Closes #8031.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16289
https://github.com/root-project/root/pull/16289:454,usability,Close,Closes,454,"Move `build/unix` to `cmake/unix`; As most of the files in `build/unix` were referenced by the `CMakeLists.txt`, moving the `unix` directory to `cmake` is a reasonable choice. There are scripts like `makereleasenotes.sh` and `pandoc-jira.sh` that are not related to CMake, but there were not related to the build process either (and also not unix either, for that matter). A better place for these scripts could be found in a followup commit if desired. Closes #8031.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16289
https://github.com/root-project/root/issues/16290:140,deployability,API,APIs,140,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:822,energy efficiency,reduc,reduce,822,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:140,integrability,API,APIs,140,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:140,interoperability,API,APIs,140,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:625,interoperability,Bind,BindRawPtr,625,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:625,modifiability,Bind,BindRawPtr,625,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:291,performance,parallel,parallel,291,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:481,performance,parallel,parallel,481,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/issues/16290:833,performance,time,time,833,"[ntuple] Provide tutorial for (envisioned) framework usage; It would be good to provide a tutorial how we (RNTuple developers) envision the APIs to be used by experiment frameworks. Relevant classes and methods that come to mind:. * Creation of (bare) `RNTupleModel` and `RFieldToken`s (for parallel writing, see also https://github.com/root-project/root/issues/16236). * Creation of (multiple) `RNTupleWriter` / `RNTupleParallelWriter` when `Append`ing to a single `TFile`. * For parallel writing, creation of `RNTupleFillContext` per thread or another granularity. * Creation of (potentially multiple) `REntry`s and using `BindRawPtr()` to fill objects. * Using `FillNoFlush()`, `RNTupleFillStatus::ShouldFlushCluster()`, `FlushColumns()` (see https://github.com/root-project/root/issues/16241) and `CommitCluster()` to reduce the time in critical sections",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16290
https://github.com/root-project/root/pull/16292:30,deployability,depend,dependency,30,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:57,deployability,depend,dependencies,57,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:30,integrability,depend,dependency,30,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:57,integrability,depend,dependencies,57,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:30,modifiability,depend,dependency,30,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:57,modifiability,depend,dependencies,57,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:25,safety,test,test,25,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:30,safety,depend,dependency,30,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:57,safety,depend,dependencies,57,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:150,safety,test,test,150,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:25,testability,test,test,25,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:30,testability,depend,dependency,30,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:57,testability,depend,dependencies,57,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:145,testability,unit,unit,145,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16292:150,testability,test,test,150,[ntuple] Remove outdated test dependency on RDF; The RDF dependencies were cleaned up in commit 8d7fa5f87c and commit f215692b3d removed the RDF unit test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16292
https://github.com/root-project/root/pull/16293:142,deployability,Updat,Updated,142,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16293:46,modifiability,Pac,Pack,46,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16293:95,modifiability,Pac,Pack,95,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16293:142,safety,Updat,Updated,142,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16293:130,security,modif,modifiable,130,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16293:142,security,Updat,Updated,142,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16293:154,security,sign,signatures,154,[ntuple] make src argument of RColumnElement::Pack/Unpack const; The `src` of `RColumnElement::Pack/Unpack` is not intended to be modifiable. Updated the signatures to reflect that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16293
https://github.com/root-project/root/pull/16294:18,modifiability,variab,variable,18,[hist] fix unused variable warnings; `Int_t nbin` is only used in debug - marked as [[maybe_unused]]. `sumSquare` is unused - removed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16294
https://github.com/root-project/root/pull/16295:1,energy efficiency,core,core,1,[core] remove deprecated ATOMIC_VAR_INIT from TUrl.cxx; `ATOMIC_VAR_INIT` is not useful anymore and deprecated in c++20.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16295
https://github.com/root-project/root/pull/16296:165,availability,down,downstream,165,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:238,availability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:89,deployability,API,API,89,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:153,deployability,API,API,153,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:238,deployability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:359,deployability,patch,patches,359,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:89,integrability,API,API,89,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:153,integrability,API,API,153,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:238,integrability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:89,interoperability,API,API,89,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:134,interoperability,compatib,compatibe,134,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:153,interoperability,API,API,153,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:238,modifiability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:359,safety,patch,patches,359,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:81,security,expos,exposes,81,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:359,security,patch,patches,359,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:293,testability,simpl,simplify,293,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:157,usability,support,support,157,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:176,usability,tool,tools,176,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:195,usability,interact,interactive,195,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:288,usability,help,help,288,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16296:293,usability,simpl,simplify,293,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM. @aaronj0, you can take it from here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16296
https://github.com/root-project/root/pull/16297:443,availability,state,state,443,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:24,deployability,build,build,24,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:350,deployability,patch,patches,350,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:374,deployability,releas,release,374,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:468,deployability,upgrad,upgrade,468,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:366,energy efficiency,current,current,366,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:443,integrability,state,state,443,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:468,modifiability,upgrad,upgrade,468,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:52,safety,test,tests,52,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:259,safety,test,tests,259,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:350,safety,patch,patches,350,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:350,security,patch,patches,350,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:52,testability,test,tests,52,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/pull/16297:259,testability,test,tests,259,"[cling] Fix `clingtest` build and disable or remove tests [v6.32]; Backport of. * https://github.com/root-project/root/pull/16258 (partial, the change in `CIFactory.cpp` is not needed). * https://github.com/root-project/root/pull/16268 (which fixes two Cling tests on macOS and is not exercised by ROOT). The reason I propose these is that `v6-32-00-patches` is the current release with LLVM 16, which would be good to have in a fully working state before merging the upgrade to LLVM 18.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16297
https://github.com/root-project/root/issues/16298:806,availability,Operat,Operating,806,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:721,deployability,version,version,721,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:760,deployability,instal,install,760,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:773,deployability,Instal,Installation,773,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:417,integrability,Event,Events,417,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:695,integrability,pub,public,695,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:721,integrability,version,version,721,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:9,interoperability,Convers,Conversion,9,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:721,modifiability,version,version,721,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:244,safety,input,inputfile,244,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:392,safety,input,inputtree,392,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:402,safety,input,inputfile,402,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:452,safety,input,inputtree,452,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:667,security,ssh,ssh,667,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:847,testability,context,context,847,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:244,usability,input,inputfile,244,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:392,usability,input,inputtree,392,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:402,usability,input,inputfile,402,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/issues/16298:452,usability,input,inputtree,452,"[PyROOT] Conversion from `std::string` to `std::string_view` broken in 6.32; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The following code crashes in ROOT >= 6.32, it was ok in ROOT 6.30. ```python. import ROOT. inputfile = ROOT.TFile.Open(""root://eospublic.cern.ch//eos/opendata/cms/derived-data/AOD2NanoAODOutreachTool/Run2012BC_DoubleMuParked_Muons.root""). inputtree=inputfile.Get(""Events""). tmprdf = ROOT.RDataFrame(inputtree). cols=tmprdf.GetColumnNames(). #THIS CRASHES. for col in cols:. print(col). print( tmprdf.GetColumnType(col) ). # THIS WORKS:. #print(cols[0]). #print(tmprdf.GetColumnType(cols[0])). ```. ### Reproducer. ssh lxplus. python3 ~arizzi/public/repro.py. ### ROOT version. ROOT 6.32.02 . lxplus default install. ### Installation method. lxplus. ### Operating system. lxplus. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16298
https://github.com/root-project/root/pull/16299:1864,deployability,updat,updated,1864,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:306,energy efficiency,reduc,reducing,306,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:163,integrability,interfac,interface,163,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:339,integrability,translat,translation,339,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:163,interoperability,interfac,interface,163,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:339,interoperability,translat,translation,339,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:665,interoperability,prox,proxy,665,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1383,interoperability,mismatch,mismatching,1383,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:163,modifiability,interfac,interface,163,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:327,performance,time,time,327,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:523,performance,time,time,523,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1635,performance,memor,memory,1635,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1165,safety,avoid,avoid,1165,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1219,safety,test,test,1219,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1315,safety,test,test,1315,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1354,safety,test,test,1354,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1834,safety,test,tested,1834,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1864,safety,updat,updated,1864,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:132,security,expos,exposing,132,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:395,security,sign,significantly,395,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:556,security,control,control,556,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1864,security,updat,updated,1864,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:351,testability,unit,unit,351,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:556,testability,control,control,556,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1041,testability,simul,simulate,1041,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1219,testability,test,test,1219,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1315,testability,test,test,1315,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1354,testability,test,test,1354,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1834,testability,test,tested,1834,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16299:1635,usability,memor,memory,1635,"[ntuple] Move RColumnElement concrete definitions out of the header file; # This Pull request:. by @hahnjo suggestion, since we are exposing a type-erased virtual interface for `RColumnElement` through `RColumnElementBase`, we can hide all the concrete definitions into a cxx file. This has the benefit of reducing the compile time of any translation unit that includes `RColumnElementBase.hxx` significantly, as the compiler won't have to instantiate all the combination matrix of `RColumnElement<CppT, ColumnType>` every time. It also let us have better control on exactly which types of `RColumnElement` we allow to instantiate by explicitly listing them into a proxy enum. ## Changes or fixes:. - renamed `RColumnElement.hxx` to `RColumnElementBase.hxx`. - moved all concrete definitions from `RColumnElementBase.hxx` to `src/RColumnElement.hxx`. This is a private header file that is included by `RColumnElement.cxx` and by `ntuple_endian.cxx`. The reason to separate this from `RColumnElement.cxx` is that `ntuple_endian.cxx` needs to simulate a big-endian machine by defining `R__LITTLE_ENDIAN 0`, which changes the definitions of some `RColumnElement`s. To avoid including the whole `RColumnElement.cxx` in the test, we decided to split the definitions into a file that can be included independently by the test. It's not a perfect solution (the test executable ends up with mismatching instantiations of RColumnElement since it links to libROOTNTuple.so) but it's technically not worse than before. We still might want to think of alternative solutions. - introduces an enum `EColumnCppType` that lists all the allowed c++ in-memory types for RColumnElement. This is used internally to map the templated `RColumnElementBase::Generate` to a non-templated function that can be implemented in the cxx file. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16299
https://github.com/root-project/root/pull/16300:28,deployability,fail,fail,28,[CMake] Tutorials as tests: fail if function not found; Fixes [ROOT-9420](https://its.cern.ch/jira/browse/ROOT-9420).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16300
https://github.com/root-project/root/pull/16300:28,reliability,fail,fail,28,[CMake] Tutorials as tests: fail if function not found; Fixes [ROOT-9420](https://its.cern.ch/jira/browse/ROOT-9420).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16300
https://github.com/root-project/root/pull/16300:21,safety,test,tests,21,[CMake] Tutorials as tests: fail if function not found; Fixes [ROOT-9420](https://its.cern.ch/jira/browse/ROOT-9420).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16300
https://github.com/root-project/root/pull/16300:21,testability,test,tests,21,[CMake] Tutorials as tests: fail if function not found; Fixes [ROOT-9420](https://its.cern.ch/jira/browse/ROOT-9420).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16300
https://github.com/root-project/root/pull/16301:1,energy efficiency,Core,Core,1,[Core] Add the .libraries command at the prompt; fixes [ROOT-5843](https://its.cern.ch/jira/browse/ROOT-5843). See https://github.com/root-project/roottest/pull/1175.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16301
https://github.com/root-project/root/pull/16301:26,usability,command,command,26,[Core] Add the .libraries command at the prompt; fixes [ROOT-5843](https://its.cern.ch/jira/browse/ROOT-5843). See https://github.com/root-project/roottest/pull/1175.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16301
https://github.com/root-project/root/pull/16306:26,deployability,build,building,26,"Revert ""[cmake] Make test building serial on Windows""; This reverts commit d13fd4aaeeb5b52be492337eab8137b277a8c5a3. As per agreement with @bellenot .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16306
https://github.com/root-project/root/pull/16306:21,safety,test,test,21,"Revert ""[cmake] Make test building serial on Windows""; This reverts commit d13fd4aaeeb5b52be492337eab8137b277a8c5a3. As per agreement with @bellenot .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16306
https://github.com/root-project/root/pull/16306:21,testability,test,test,21,"Revert ""[cmake] Make test building serial on Windows""; This reverts commit d13fd4aaeeb5b52be492337eab8137b277a8c5a3. As per agreement with @bellenot .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16306
https://github.com/root-project/root/pull/16307:23,safety,test,test,23,[ntuple] speed up HTTP test; Read only one column from the remote file to speed up the test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16307
https://github.com/root-project/root/pull/16307:87,safety,test,test,87,[ntuple] speed up HTTP test; Read only one column from the remote file to speed up the test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16307
https://github.com/root-project/root/pull/16307:23,testability,test,test,23,[ntuple] speed up HTTP test; Read only one column from the remote file to speed up the test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16307
https://github.com/root-project/root/pull/16307:87,testability,test,test,87,[ntuple] speed up HTTP test; Read only one column from the remote file to speed up the test.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16307
https://github.com/root-project/root/pull/16309:236,availability,error,error,236,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:18,integrability,interfac,interface,18,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:18,interoperability,interfac,interface,18,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:139,interoperability,distribut,distributed,139,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:18,modifiability,interfac,interface,18,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:236,performance,error,error,236,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:236,safety,error,error,236,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:443,safety,test,tests,443,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:443,testability,test,tests,443,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:13,usability,user,user,13,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:95,usability,user,user,95,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:100,usability,interact,interacts,100,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:214,usability,clear,clear,214,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/pull/16309:236,usability,error,error,236,"[df] Improve user interface in DistrRDF ; Add a number of functions that could replace the way user interacts with the C++ elements of the distributed, fully pythonic RDF analysis, so that this is more natural and clear as well as less error prone compared to the previous method. . The new functions are: . - DeclareHeaders. - DeclareSharedLibs . - DeclareFiles . - DeclareCppCode. The functions work with both Spark and Dask backends. . The tests are introduced in roottest PR: https://github.com/root-project/roottest/pull/1177.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16309
https://github.com/root-project/root/issues/16310:346,availability,Operat,Operating,346,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:298,deployability,version,version,298,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:316,deployability,Instal,Installation,316,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:168,energy efficiency,Measur,Measure,168,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:298,integrability,version,version,298,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:112,interoperability,standard,standard,112,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:298,modifiability,version,version,298,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:187,performance,time,time,187,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:193,performance,memor,memory,193,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:384,testability,context,context,384,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/issues/16310:193,usability,memor,memory,193,"[ntuple] Compare RNTuple to ORC; ### Explain what you would like to see improved and how. Implement the RNTuple standard benchmarks using ORC: https://orc.apache.org/. Measure read/write time, memory consumption, and final file size. Moved from https://its.cern.ch/jira/browse/ROOT-10264. ### ROOT version. n/a. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16310
https://github.com/root-project/root/pull/16311:240,availability,cluster,cluster,240,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:608,availability,cluster,cluster,608,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:687,availability,cluster,clusters,687,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:733,availability,cluster,clusters,733,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1269,availability,sli,slightly,1269,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:240,deployability,cluster,cluster,240,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:608,deployability,cluster,cluster,608,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:687,deployability,cluster,clusters,687,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:733,deployability,cluster,clusters,733,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:9,energy efficiency,Adapt,Adaptive,9,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:70,energy efficiency,adapt,adaptive,70,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:278,energy efficiency,reduc,reduce,278,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:329,energy efficiency,current,currently,329,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:528,energy efficiency,current,current,528,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:557,energy efficiency,adapt,adaptive,557,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:852,energy efficiency,adapt,adaptive,852,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:9,integrability,Adapt,Adaptive,9,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:70,integrability,adapt,adaptive,70,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:557,integrability,adapt,adaptive,557,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:852,integrability,adapt,adaptive,852,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:9,interoperability,Adapt,Adaptive,9,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:70,interoperability,adapt,adaptive,70,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:557,interoperability,adapt,adaptive,557,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:852,interoperability,adapt,adaptive,852,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:9,modifiability,Adapt,Adaptive,9,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:70,modifiability,adapt,adaptive,70,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:557,modifiability,adapt,adaptive,557,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:852,modifiability,adapt,adaptive,852,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:542,performance,perform,performance,542,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1247,performance,memor,memory,1247,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1442,performance,memor,memory,1442,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1269,reliability,sli,slightly,1269,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:897,safety,test,test,897,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1052,safety,avoid,avoids,1052,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:897,testability,test,test,897,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1007,testability,simpl,simplifies,1007,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:180,usability,document,document,180,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:542,usability,perform,performance,542,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1007,usability,simpl,simplifies,1007,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1247,usability,memor,memory,1247,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/pull/16311:1442,usability,memor,memory,1442,"[ntuple] Adaptive page sizes; Moves from fixed page sizes on write to adaptive page sizes, following the original idea of @hahnjo . The new mechanism is explained in the tuning.md document in the PR. The PR also bumps the target compressed cluster size to 150MB. We may want to reduce that still. Evaluation of the new method is currently ongoing and the PR description will be amended with the results. EDIT: [Comparison](https://docs.google.com/spreadsheets/d/1maJhgvgVU8RkX7QXd7B3QiTBfKuYbTbvgkoHzBUOurY/edit?usp=sharing) of current write performance vs adaptive page sizes with 50MB, 100MB, 150MB target cluster size. To me it seems that there is not a good argument to go to 150 MB clusters. There may be an argument for 100 MB clusters. For the moment, I'll remove the commit that changes the default settings from the PR. An additional flavor, `adaptive / exp`, is included in the table to test the effect of flushing _foreign columns_. In the experimental mode, columns only flush themselves, which simplifies the `RWritePageMemoryManager` and avoids the upcall from the sink to the column. There is a small positive effect of foreign flushes on the file size in the nanoAOD sample. The effect is more visible for the number of pages. The memory consumption is slightly smaller without foreign column flushes. I'll see if I can construct an example that shows better the advantage of foreign column flushes (or not). As expected, the memory savings become visible for large EDMs (e.g., nanoAOD in this set of samples).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16311
https://github.com/root-project/root/issues/16312:652,availability,fault,fault,652,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:4675,availability,operat,operator,4675,"y 0xF36E7A0: TBufferFile::ReadFastArray(int*, int) (TBufferFile.cxx:1327). [1965517:tpc-tracker]: ==1965517== by 0xF3E580B: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1183). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreamerInfoReadBuffer.cxx:1297). [1965517:tpc-tracker]: ==1965517== by 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: operator() (TStreamerInfoActions.h:131). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*, void*) (TBufferFile.cxx:3736). [1965517:tpc-tracker]: ==1965517== by 0xF482A0F: TStreamerInfoActions::ReadSTLMemberWiseSameClass(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*, short) (TStreamerInfoActions.cxx:1155). [1965517:tpc-tracker]: ==1965517== by 0xF482C4F: int TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:5405,availability,operat,operator,5405," 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: operator() (TStreamerInfoActions.h:131). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*, void*) (TBufferFile.cxx:3736). [1965517:tpc-tracker]: ==1965517== by 0xF482A0F: TStreamerInfoActions::ReadSTLMemberWiseSameClass(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*, short) (TStreamerInfoActions.cxx:1155). [1965517:tpc-tracker]: ==1965517== by 0xF482C4F: int TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_all",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6288,availability,operat,operator,6288,"ctions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:7832,availability,operat,operator,7832,"r<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreamerInfoReadBuffer.cxx:1297). [1965517:tpc-tracker]: ==1965517== by 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: operator() (TStreamerInfoActions.h:131). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*, void*) (TBufferFile.cxx:3736). [1965517:tpc-tracker]: ==1965517== by 0xF482A0F: TStreamerInfoActions::ReadSTLMemberWiseSameClass(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*, short) (TStreamerInfoActions.cxx:1155). [1965517:tpc-tracker]: ==1965517== by 0xF482C4F: int TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:8562,availability,operat,operator,8562," 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: operator() (TStreamerInfoActions.h:131). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*, void*) (TBufferFile.cxx:3736). [1965517:tpc-tracker]: ==1965517== by 0xF482A0F: TStreamerInfoActions::ReadSTLMemberWiseSameClass(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*, short) (TStreamerInfoActions.cxx:1155). [1965517:tpc-tracker]: ==1965517== by 0xF482C4F: int TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517==. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7AC: frombuf (Bytes.h:314). [1965517:tpc-tracker]: ==1965517== by 0xF36E7AC: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7AC: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7AC: TBufferFile::ReadFastArray(int*, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:10516,availability,operat,operator,10516,"y 0xF36E7AC: TBufferFile::ReadFastArray(int*, int) (TBufferFile.cxx:1327). [1965517:tpc-tracker]: ==1965517== by 0xF3E580B: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1183). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreamerInfoReadBuffer.cxx:1297). [1965517:tpc-tracker]: ==1965517== by 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: operator() (TStreamerInfoActions.h:131). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*, void*) (TBufferFile.cxx:3736). [1965517:tpc-tracker]: ==1965517== by 0xF482A0F: TStreamerInfoActions::ReadSTLMemberWiseSameClass(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*, short) (TStreamerInfoActions.cxx:1155). [1965517:tpc-tracker]: ==1965517== by 0xF482C4F: int TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:11246,availability,operat,operator,11246," 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: operator() (TStreamerInfoActions.h:131). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*, void*) (TBufferFile.cxx:3736). [1965517:tpc-tracker]: ==1965517== by 0xF482A0F: TStreamerInfoActions::ReadSTLMemberWiseSameClass(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*, short) (TStreamerInfoActions.cxx:1155). [1965517:tpc-tracker]: ==1965517== by 0xF482C4F: int TStreamerInfoActions::ReadSTL<&TStreamerInfoActions::ReadSTLMemberWiseSameClass, &TStreamerInfoActions::ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_all",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12129,availability,operat,operator,12129,"ctions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13168,availability,Operat,Operating,13168,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:956,deployability,version,version,956,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1060,deployability,version,version,1060,"an int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> >",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1179,deployability,version,version,1179,"hich we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1868,deployability,version,version,1868,"cker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2576,deployability,version,version,2576," offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: =",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2697,deployability,version,version,2697,"er]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13111,deployability,version,version,13111,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13133,deployability,Instal,Installation,13133,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:652,energy efficiency,fault,fault,652,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:756,energy efficiency,optim,optimized,756,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:3340,energy efficiency,optim,optimized,3340,"fset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFile::ReadFastArray(int*, int) (TBufferFile.cxx:1327). [1965517:tpc-tracker]: ==1965517== by 0xF3E580B: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1183). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreame",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6230,energy efficiency,alloc,alloc,6230,"ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastA",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6392,energy efficiency,alloc,allocate,6392,"F36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6473,energy efficiency,alloc,allocate,6473,"7== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6483,energy efficiency,alloc,allocator,6483,"6DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6550,energy efficiency,alloc,allocate,6550,": ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreamerInfoReadBuffer.cxx:1297). [1965517:tpc-tracker]: ==",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:6828,energy efficiency,alloc,allocator,6828,":tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb80 is 0 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreamerInfoReadBuffer.cxx:1297). [1965517:tpc-tracker]: ==1965517== by 0xF45B81F: TStreamerInfoActions::VectorLooper::GenericRead(TBuffer&, void*, void const*, TStreamerInfoActions::TLoopConfiguration const*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1883). [1965517:tpc-tracker]: ==1965517== by 0xF36DAAB: o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12071,energy efficiency,alloc,alloc,12071,"ReadSTLObjectWiseFastArray>(TBuffer&, void*, TStreamerInfoActions::TConfiguration const*) (TStreamerInfoActions.cxx:1405). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12233,energy efficiency,alloc,allocate,12233,"F36DE4B: operator() (TStreamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additiona",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12314,energy efficiency,alloc,allocate,12314,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12324,energy efficiency,alloc,allocator,12324,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12391,energy efficiency,alloc,allocate,12391,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:12669,energy efficiency,alloc,allocator,12669,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:956,integrability,version,version,956,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1060,integrability,version,version,1060,"an int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> >",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1179,integrability,version,version,1179,"hich we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1516,integrability,sub,subset,1516,": char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStrea",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1868,integrability,version,version,1868,"cker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2205,integrability,sub,subset,2205,"3. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2576,integrability,version,version,2576," offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: =",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2697,integrability,version,version,2697,"er]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2988,integrability,Sub,Subset,2988,"ect. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFile::ReadFastArray(int*, int) (TBufferFile.cxx:1327). [1965517:tpc-tracker]: ==1965517== by 0xF3E580B: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1183). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:3082,integrability,sub,subset,3082,"e=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFile::ReadFastArray(int*, int) (TBufferFile.cxx:1327). [1965517:tpc-tracker]: ==1965517== by 0xF3E580B: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1183). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13111,integrability,version,version,13111,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:291,interoperability,platform,platform,291,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:337,interoperability,specif,specifier,337,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:423,interoperability,standard,standard,423,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:956,modifiability,version,version,956,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1060,modifiability,version,version,1060,"an int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> >",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1179,modifiability,version,version,1179,"hich we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1868,modifiability,version,version,1868,"cker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2576,modifiability,version,version,2576," offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: =",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2697,modifiability,version,version,2697,"er]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13111,modifiability,version,version,13111,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:652,performance,fault,fault,652,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:756,performance,optimiz,optimized,756,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:3340,performance,optimiz,optimized,3340,"fset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFile::ReadFastArray(int*, int) (TBufferFile.cxx:1327). [1965517:tpc-tracker]: ==1965517== by 0xF3E580B: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1183). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: TBufferFile::ReadFastArray(void*, TClass const*, int, TMemberStreamer*, TClass const*) (TBufferFile.cxx:1616). [1965517:tpc-tracker]: ==1965517== by 0xF58C84B: int TStreamerInfo::ReadBuffer<char**>(TBuffer&, char** const&, TStreamerInfo::TCompInfo* const*, int, int, int, int, int) (TStreame",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:652,reliability,fault,fault,652,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13048,reliability,doe,does,13048,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:652,safety,fault,fault,652,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:369,security,sign,signed,369,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:382,security,sign,sign-ess,382,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1190,security,checksum,checksum,1190,"e when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:1879,security,checksum,checksum,1879,">Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:2708,security,checksum,checksum,2708,"mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalArray<o2::tpc::PadFlags>, version=1, checksum=0xb03d18c2. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365,. [1965517:tpc-tracker]: vector<o2::tpc::PadFlags> mData offset= 32 type=300 ,stl=1, ctype=3, calibration data. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Subset type. [1965517:tpc-tracker]: int mPadSubsetNumber offset= 60 type= 3 Number of the pad subset, e.g. ROC 0 is IROC A00. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. [1965517:tpc-tracker]: ==1965517== Invalid write of size 1. [1965517:tpc-tracker]: ==1965517== at 0xF36E7A0: frombuf (Bytes.h:313). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: frombuf (Bytes.h:442). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: ReadFastArray (TBufferFile.cxx:1338). [1965517:tpc-tracker]: ==1965517== by 0xF36E7A0: TBufferFile::ReadFas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:162,testability,understand,understand,162,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:13239,testability,context,context,13239,"reamerInfoActions.h:123). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: ApplySequence (TBufferFile.cxx:3670). [1965517:tpc-tracker]: ==1965517== by 0xF36DE4B: TBufferFile::ApplySequence(TStreamerInfoActions::TActionSequence const&, void*) (TBufferFile.cxx:3661). [1965517:tpc-tracker]: ==1965517== by 0xF376CEB: TBufferFile::ReadClassBuffer(TClass const*, void*, TClass const*) (TBufferFile.cxx:3598). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: Streamer (TClass.h:614). [1965517:tpc-tracker]: ==1965517== by 0xF3F4633: TKey::ReadObjectAny(TClass const*) (TKey.cxx:1120). [1965517:tpc-tracker]: ==1965517== by 0xF3B82E3: TDirectoryFile::GetObjectChecked(char const*, TClass const*) (TDirectoryFile.cxx:1111). [1965517:tpc-tracker]: ==1965517== Address 0x153fbb81 is 1 bytes after a block of size 1,440 alloc'd. [1965517:tpc-tracker]: ==1965517== at 0x4868908: operator new(unsigned long) (vg_replace_malloc.c:483). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (new_allocator.h:137). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (allocator.h:188). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: allocate (alloc_traits.h:464). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:378). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: _M_allocate (stl_vector.h:375). [1965517:tpc-tracker]: ==1965517== by 0x60E5D1F: std::vector<o2::tpc::PadFlags, std::allocator<o2::tpc::PadFlags> >::_M_default_append(unsigned long) (vector.tcc:650). [1965517:tpc-tracker]: ==1965517== by 0xF3E5797: void TGenCollectionStreamer::ReadBufferVectorPrimitives<int>(TBuffer&, void*, TClass const*) (TGenCollectionStreamer.cxx:1176). [1965517:tpc-tracker]: ==1965517== by 0xF36EC7B: Streamer (TClass.h:614). ```. ### Reproducer. I do not have one which does not involve running ALICE reconstruction on ARM. ### ROOT version. 6.32.02. ### Installation method. aliBuild. ### Operating system. ALMA Linux 9 on ARM64 (Ampere Altra). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/issues/16312:154,usability,help,help,154,"Broken streaming of vector of enum with underlying type other than int; ### Check duplicate issues. - [x] Checked for duplicates. ### Description. I need help to understand an issue which we have when running on Linux on ARM when reading a file which was serialised on x86. Notice that this platform is peculiar, because `char` (without specifier) is unsigned, and not signed (char sign-ess is implementation detail in the standard). This is important because `mPadSubset` that you will see below is an `enum PadSubset : char`. Running in valgrind, the issue appears as dumped below. What puzzles me and what I think is the culprit of the segmentation fault is the line:. ```. [1965517:tpc-tracker]: i= 2, mPadSubset type= 23, offset= 56, len=2, method=0 [optimized]. ```. as I would have expected it to be len=1. Can you explain me what is going on? ```. [1965517:tpc-tracker]: ====>Rebuilding TStreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 1. [1965517:tpc-tracker]: Creating StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version: 2. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=2, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [1965517:tpc-tracker]: vector<o2::tpc::CalArray<o2::tpc::PadFlags> > mData offset= 32 type=300 ,stl=1, ctype=61, internal CalArrays. [1965517:tpc-tracker]: o2::tpc::PadSubset mPadSubset offset= 56 type= 3 Pad subset granularity. [1965517:tpc-tracker]: i= 0, mName type=300, offset= 0, len=1, method=0. [1965517:tpc-tracker]: i= 1, mData type=300, offset= 32, len=1, method=0. [1965517:tpc-tracker]: i= 2, mPadSubset type= 3, offset= 56, len=1, method=0. [1965517:tpc-tracker]:. [1965517:tpc-tracker]: StreamerInfo for class: o2::tpc::CalDet<o2::tpc::PadFlags>, version=1, checksum=0x93700773. [1965517:tpc-tracker]: string mName offset= 0 type=300 ,stl=365, ctype=365, name of the object. [196",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16312
https://github.com/root-project/root/pull/16313:22,availability,operat,operators,22,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:152,availability,operat,operators,152,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:168,availability,operat,operator,168,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:328,availability,operat,operators,328,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:105,deployability,log,logs,105,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:193,integrability,sub,subgraphs,193,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:246,integrability,sub,subgraphs,246,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:105,safety,log,logs,105,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:105,security,log,logs,105,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:105,testability,log,logs,105,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:181,usability,support,support,181,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:280,usability,support,support,280,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16313:310,usability,Support,Support,310,"[tmva][sofie] Add new operators and several improvements in SOFIE; # This Pull request adds (see commits logs for more details). - TopK, Tile and Split operators. - If operator and support for subgraphs by parsing them from ONNX and dealing with subgraphs in RModel. - Add MatMul support for dim=1 tensors . - Support output of operators as constant tensors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16313
https://github.com/root-project/root/pull/16314:71,availability,avail,available,71,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:392,availability,down,down,392,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:278,deployability,upgrad,upgrade,278,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:469,deployability,upgrad,upgrade,469,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:867,deployability,patch,patched,867,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:278,modifiability,upgrad,upgrade,278,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:316,modifiability,variab,variables,316,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:469,modifiability,upgrad,upgrade,469,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:762,modifiability,Exten,Extend,762,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:71,reliability,availab,available,71,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:409,reliability,pra,practice,409,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:71,safety,avail,available,71,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:517,safety,test,tests,517,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:679,safety,Prevent,Prevent,679,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:867,safety,patch,patched,867,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:71,security,availab,available,71,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:679,security,Preven,Prevent,679,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:867,security,patch,patched,867,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16314:517,testability,test,tests,517,"[cling] Fix lifetime of `ClingMMapper`; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16314
https://github.com/root-project/root/pull/16315:412,availability,error,error,412,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:116,deployability,modul,modules,116,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:224,deployability,modul,modules,224,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:341,deployability,build,building,341,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:476,deployability,modul,modules,476,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:528,deployability,build,building,528,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:569,deployability,build,building,569,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:592,deployability,modul,module,592,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:432,energy efficiency,model,model,432,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:541,energy efficiency,Core,Core,541,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:98,interoperability,specif,specify,98,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:153,interoperability,specif,specify,153,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:513,interoperability,specif,specify,513,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:116,modifiability,modul,modules,116,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:224,modifiability,modul,modules,224,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:476,modifiability,modul,modules,476,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:592,modifiability,modul,module,592,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:412,performance,error,error,412,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:116,safety,modul,modules,116,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:224,safety,modul,modules,224,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:254,safety,accid,accident,254,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:412,safety,error,error,412,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:476,safety,modul,modules,476,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:592,safety,modul,module,592,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:432,security,model,model,432,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:89,usability,user,users,89,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16315:412,usability,error,error,412,"[rootcling] Add option to allow system byproducts; Commit 4ee93a229f (""[rootcling] Allow users to specify byproduct modules."") added explicit options to specify expected byproducts, but removed the implicit check for system modules. This worked a bit by accident because the interpreter includes `<new>` upon startup which already triggered building of `std.pcm` and `libc.pcm` before `rootcling` registered its error handler. This model breaks now with Apple splitting their modules, so add a new option that we specify during building of `Core.pcm` to allow implicit building of any system module. ---. This revives https://github.com/root-project/root/pull/14903",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16315
https://github.com/root-project/root/pull/16316:263,deployability,updat,updated,263,"[RF] RooDataHist arraySize getter; # This Pull request:. Add a getter for the ""arraySize"" memeber function RooDataHist. The weightArray getters are way more useful when actually being able to loop over the list. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16316
https://github.com/root-project/root/pull/16316:233,safety,test,tested,233,"[RF] RooDataHist arraySize getter; # This Pull request:. Add a getter for the ""arraySize"" memeber function RooDataHist. The weightArray getters are way more useful when actually being able to loop over the list. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16316
https://github.com/root-project/root/pull/16316:263,safety,updat,updated,263,"[RF] RooDataHist arraySize getter; # This Pull request:. Add a getter for the ""arraySize"" memeber function RooDataHist. The weightArray getters are way more useful when actually being able to loop over the list. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16316
https://github.com/root-project/root/pull/16316:263,security,updat,updated,263,"[RF] RooDataHist arraySize getter; # This Pull request:. Add a getter for the ""arraySize"" memeber function RooDataHist. The weightArray getters are way more useful when actually being able to loop over the list. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16316
https://github.com/root-project/root/pull/16316:233,testability,test,tested,233,"[RF] RooDataHist arraySize getter; # This Pull request:. Add a getter for the ""arraySize"" memeber function RooDataHist. The weightArray getters are way more useful when actually being able to loop over the list. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16316
https://github.com/root-project/root/pull/16317:246,deployability,updat,updated,246,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:108,modifiability,extens,extensions,108,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:216,safety,test,tested,216,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:246,safety,updat,updated,246,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:246,security,updat,updated,246,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:216,testability,test,tested,216,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:19,usability,document,documentation,19,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16317:126,usability,document,documentation,126,"[RF][HS3] improved documentation of RooJSONFactoryWSTool; # This Pull request:. ## Changes or fixes:. Small extensions on the documentation of RooJSONFactoryWSTool, adding a C++ example as well. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16317
https://github.com/root-project/root/pull/16318:79,availability,avail,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:400,availability,down,down,400,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:286,deployability,upgrad,upgrade,286,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:477,deployability,upgrad,upgrade,477,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:875,deployability,patch,patched,875,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:286,modifiability,upgrad,upgrade,286,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:324,modifiability,variab,variables,324,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:477,modifiability,upgrad,upgrade,477,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:770,modifiability,Exten,Extend,770,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:79,reliability,availab,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:417,reliability,pra,practice,417,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:79,safety,avail,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:525,safety,test,tests,525,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:687,safety,Prevent,Prevent,687,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:875,safety,patch,patched,875,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:79,security,availab,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:687,security,Preven,Prevent,687,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:875,security,patch,patched,875,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16318:525,testability,test,tests,525,"[cling] Fix lifetime of `ClingMMapper` [v6.32]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. (cherry picked from commit fd97311519a5d64f0110686db46e0d912503751c, backport of https://github.com/root-project/root/pull/16314)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16318
https://github.com/root-project/root/pull/16319:79,availability,avail,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:400,availability,down,down,400,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:286,deployability,upgrad,upgrade,286,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:477,deployability,upgrad,upgrade,477,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:875,deployability,patch,patched,875,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:286,modifiability,upgrad,upgrade,286,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:324,modifiability,variab,variables,324,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:477,modifiability,upgrad,upgrade,477,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:770,modifiability,Exten,Extend,770,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:79,reliability,availab,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:417,reliability,pra,practice,417,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:993,reliability,doe,doesn,993,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:79,safety,avail,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:525,safety,test,tests,525,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:687,safety,Prevent,Prevent,687,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:875,safety,patch,patched,875,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:1132,safety,compl,complicated,1132,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:79,security,availab,available,79,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:687,security,Preven,Prevent,687,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:875,security,patch,patched,875,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:1132,security,compl,complicated,1132,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:525,testability,test,tests,525,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16319:1001,usability,support,support,1001,"[cling] Fix lifetime of `ClingMMapper` [v6.30]; The `ClingMMapper` must remain available until all `ClingMemoryManager`s are destructed, which is typically during shutdown of `IncrementalJIT`. This was not the case for the global object `MMapperInstance` that was introduced during the upgrade to LLVM 13 because `libCling` variables are destructed before running `TROOT` `atexit` handlers that shut down the JIT. In practice, it happened to work but this will change with the upgrade to LLVM 18 where we see crashes in some tests, potentially because of upstream commit https://github.com/llvm/llvm-project/commit/47f5c54f997a59bb2c65abe6b8b811f6e7553456. See also commits e0f6c04660 (""Prevent static destruction from ending DefaultMMapper too early"") and 80c14bb948 (""Extend lifetime of SectionMemoryManager::DefaultMMapper, again"") for the same problem that we previously patched in our copy of LLVM. This differs from commit fd97311519a5d64f0110686db46e0d912503751c in master because LLVM doesn't support passing move-only lambdas. ---. This aims to backport https://github.com/root-project/root/pull/16314, but it's a bit more complicated with LLVM 13. We need to decide if we want this or just leave v6.30 and v6.28 alone.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16319
https://github.com/root-project/root/pull/16320:213,deployability,version,versions,213,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:28,energy efficiency,schedul,scheduled,28,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:104,energy efficiency,schedul,scheduled,104,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:213,integrability,version,versions,213,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:213,modifiability,version,versions,213,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:28,performance,schedul,scheduled,28,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:104,performance,schedul,scheduled,104,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:145,performance,memor,memory,145,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/pull/16320:145,usability,memor,memory,145,[RF] Remove deprecaded code scheduled for removal in 6.34 and other cleanups; 1. Remove deprecaded code scheduled for removal in 6.34. 2. Remove memory pool related code. 3. Remove checks for unsupported compiler versions. More details in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16320
https://github.com/root-project/root/issues/16321:322,availability,Operat,Operating,322,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:271,deployability,version,version,271,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:292,deployability,Instal,Installation,292,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:271,integrability,version,version,271,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:271,modifiability,version,version,271,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:360,testability,context,context,360,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:203,usability,user,user,203,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/issues/16321:226,usability,clear,clear,226,"[ntuple] Split RNTupleView<T, bool> in two classes; ### Explain what you would like to see improved and how. The boolean template in `RNTupleView<T, bool>` steers whether or not the view is owned by the user. It would be more clear to use two different classes. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16321
https://github.com/root-project/root/pull/16322:166,deployability,instal,installation,166,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:296,deployability,Instal,Install,296,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:423,deployability,updat,updated,423,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:264,interoperability,platform,platforms,264,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:19,safety,Test,Testing,19,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:124,safety,test,tests,124,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:142,safety,test,test,142,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:247,safety,test,tests,247,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:274,safety,except,except,274,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:378,safety,test,tests,378,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:423,safety,updat,updated,423,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:560,safety,test,test,560,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:598,safety,test,tests,598,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:423,security,updat,updated,423,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:19,testability,Test,Testing,19,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:124,testability,test,tests,124,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:142,testability,test,test,142,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:247,testability,test,tests,247,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:378,testability,test,tests,378,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:560,testability,test,test,560,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16322:598,testability,test,tests,598,"Full Chain Graphic Testing with Headless Chrome Browser; # This Pull request:. ## Changes or fixes:. DO NOT MERGE!! This PR tests the graphic test suite and includes installation of chrome in ROOT CI. ## Checklist:. - [x] Make old svg, pdf, json, tests run on all platforms except windows. - [x] Install headless chrome browser in ROOT CI (Done for linux). - [x] Enable new svg tests in roottest (Enabled for linux). - [x] updated the references files for new svg (if necessary). - [ ] Deal with hanging web chrome browser (only problem on linux, works for 18 test, maybe try to increase number of tests).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16322
https://github.com/root-project/root/pull/16323:9,deployability,Updat,Update,9,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:146,deployability,build,build,146,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:152,energy efficiency,model,models,152,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:202,energy efficiency,model,models,202,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:257,performance,perform,performed,257,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:9,safety,Updat,Update,9,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:9,security,Updat,Update,9,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:152,security,model,models,152,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:202,security,model,models,202,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/pull/16323:257,usability,perform,performed,257,"[RF][HF] Update `hf001_example` tutorial with example fit and plot; Changes to HistFactory ROOT tutorial. Since people usually use HistFactory to build models and then fit it, it is better to show, how models can be fitted in the same tutorial. Changes are performed both for python and c++ tutorials.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16323
https://github.com/root-project/root/issues/16324:332,availability,Operat,Operating,332,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:281,deployability,version,version,281,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:302,deployability,Instal,Installation,302,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:33,energy efficiency,model,model,33,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:115,energy efficiency,Current,Currently,115,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:183,energy efficiency,model,model,183,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:251,energy efficiency,model,model,251,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:281,integrability,version,version,281,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:281,modifiability,version,version,281,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:47,performance,disk,disk,47,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:33,security,model,model,33,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:183,security,model,model,183,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:251,security,model,model,251,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:370,testability,context,context,370,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16324:260,usability,prefer,preferable,260,"[ntuple] Allow for creating bare model from on-disk info; ### Explain what you would like to see improved and how. Currently, `RNTupleDescriptor::CreateModel()` always creates a full model with a default entry. There can be situations in which a bare model is preferable. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16324
https://github.com/root-project/root/issues/16325:224,availability,cluster,clusters,224,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:358,availability,Operat,Operating,358,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:224,deployability,cluster,clusters,224,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:307,deployability,version,version,307,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:328,deployability,Instal,Installation,328,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:307,integrability,version,version,307,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:281,interoperability,specif,specific,281,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:307,modifiability,version,version,307,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:180,performance,memor,memory,180,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:396,testability,context,context,396,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:16,usability,custom,customization,16,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:180,usability,memor,memory,180,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16325:256,usability,user,users,256,[ntuple] Better customization options for RClusterPool (read-ahead); ### Explain what you would like to see improved and how. The RClusterPool should be improved. - to work with a memory budget rather than a fixed number of clusters to read-ahead. - allow users to exclude/include specific fields. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16325
https://github.com/root-project/root/issues/16326:27,availability,cluster,cluster,27,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:204,availability,cluster,clusters,204,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:335,availability,cluster,clusters,335,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:519,availability,Operat,Operating,519,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:27,deployability,cluster,cluster,27,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:187,deployability,log,logical,187,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:204,deployability,cluster,clusters,204,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:335,deployability,cluster,clusters,335,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:444,deployability,log,logical,444,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:468,deployability,version,version,468,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:489,deployability,Instal,Installation,489,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:468,integrability,version,version,468,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:158,modifiability,exten,extended,158,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:468,modifiability,version,version,468,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:48,performance,parallel,parallel,48,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:224,performance,disk,disk,224,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:263,performance,parallel,parallel,263,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:321,performance,disk,disk,321,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:359,performance,parallel,parallel,359,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:187,safety,log,logical,187,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:444,safety,log,logical,444,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:16,security,control,control,16,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:187,security,log,logical,187,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:444,security,log,logical,444,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:16,testability,control,control,16,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:187,testability,log,logical,187,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:444,testability,log,logical,444,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16326:557,testability,context,context,557,"[ntuple] Better control of cluster ordering for parallel writes; ### Explain what you would like to see improved and how. The RNTupleParallelWriter should be extended to allow to fix the logical order of clusters written to disk. This would allow to better align parallel writing with, e.g., lumi blocks. The physical on-disk order of clusters written by the parallel writer will still be arbitrary, but the meta-data can link them to another, logical order. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16326
https://github.com/root-project/root/issues/16327:750,availability,Operat,Operating,750,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:184,deployability,automat,automatically,184,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:585,deployability,build,build,585,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:667,deployability,releas,releases,667,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:699,deployability,version,version,699,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:720,deployability,Instal,Installation,720,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:355,energy efficiency,core,core,355,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:514,energy efficiency,core,core,514,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:20,integrability,encapsulat,encapsulation,20,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:159,integrability,compon,component,159,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:207,integrability,wrap,wrapping,207,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:699,integrability,version,version,699,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:159,interoperability,compon,component,159,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:20,modifiability,encapsul,encapsulation,20,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:159,modifiability,compon,component,159,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:699,modifiability,version,version,699,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:184,testability,automat,automatically,184,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/issues/16327:788,testability,context,context,788,"Improve header file encapsulation; ### Explain what you would like to see improved and how. We should move all headers from $ROOTSYS/include to $ROOTSYS/ROOT/{component} and we should automatically generate wrapping headers that `#include` the relevant ROOT/ header with a deprecation warning. Eg. ```bash. mv ROOTSYS/include/TLish.h ROOTSYS/include/ROOT/core/TLish.h. cat ROOTSYS/include/TLish.h. ```. ```cpp. #warn ""This forwarding header will go away in X please include \""ROOT/Base/TLish.h\"" "". #include ""ROOT/core/TLish.h"". ```. The trampoline header file can be generated by our build system by adding a -DROOT_COMPATIBILITY switch that's on by default for few releases and then off. ### ROOT version. master. ### Installation method. N/A. ### Operating system. N/A. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16327
https://github.com/root-project/root/pull/16328:183,deployability,updat,updated,183,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16328:45,safety,test,tests,45,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16328:153,safety,test,tested,153,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16328:183,safety,updat,updated,183,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16328:183,security,updat,updated,183,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16328:45,testability,test,tests,45,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16328:153,testability,test,tested,153,"[cmake] Introduce the needs_network flag for tests; and assign it to the dataframe/df027_SQliteDependencyOverVersion.C, as a start. ## Checklist:. - [v] tested changes locally. - [v] updated the docs (if necessary). This PR fixes. - [ROOT-9705](https://its.cern.ch/jira/browse/ROOT-9705). - [ROOT-10539](https://its.cern.ch/jira/browse/ROOT-10539).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16328
https://github.com/root-project/root/pull/16329:7,modifiability,Exten,Extend,7,[Tree] Extend testing of TTreeReader; Fixes [ROOT-9354](https://its.cern.ch/jira/browse/ROOT-9354).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16329
https://github.com/root-project/root/pull/16329:14,safety,test,testing,14,[Tree] Extend testing of TTreeReader; Fixes [ROOT-9354](https://its.cern.ch/jira/browse/ROOT-9354).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16329
https://github.com/root-project/root/pull/16329:14,testability,test,testing,14,[Tree] Extend testing of TTreeReader; Fixes [ROOT-9354](https://its.cern.ch/jira/browse/ROOT-9354).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16329
https://github.com/root-project/root/pull/16330:373,deployability,updat,updated,373,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:140,performance,disk,disk,140,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:343,safety,test,tested,343,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:373,safety,updat,updated,373,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:373,security,updat,updated,373,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:343,testability,test,tested,343,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:13,usability,support,support,13,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16330:67,usability,support,support,67,"[ntuple] Add support for `std::(unordered)_multiset`; This PR adds support for `std::multiset` and `std::unordered_multiset` fields. The on-disk representation is exactly the same as `std::(unordered)_set`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16330
https://github.com/root-project/root/pull/16331:380,deployability,updat,updated,380,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:147,performance,disk,disk,147,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:350,safety,test,tested,350,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:380,safety,updat,updated,380,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:380,security,updat,updated,380,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:350,testability,test,tested,350,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:13,usability,support,support,13,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16331:74,usability,support,support,74,"[ntuple] Add support for `std::(unordered)_multimap` fields; This PR adds support for `std::multimap` and `std::unordered_multimap` fields. The on-disk representation is exactly the same as `std::(unordered)_map`, so the only addition is the type name resolution for type-erased fields and the `RField` template specializations. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16331
https://github.com/root-project/root/pull/16332:168,availability,avail,available,168,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16332:120,performance,disk,disk,120,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16332:168,reliability,availab,available,168,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16332:168,safety,avail,available,168,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16332:168,security,availab,available,168,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16332:13,usability,support,support,13,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16332:231,usability,support,support,231,"[ntuple] Add support for ""large locators"", drop string locator; - Adds a locator type that can reference blocks >4GB on disk. - The new locator replaces the previously available but unused string locator. - Makes that DAOS locator support >4GB blocks. - Adds some fixes for pages >2GB",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16332
https://github.com/root-project/root/pull/16333:142,deployability,automat,automatically,142,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:287,integrability,configur,configuring,287,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:334,integrability,translat,translated,334,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:334,interoperability,translat,translated,334,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:287,modifiability,configur,configuring,287,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:287,security,configur,configuring,287,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:142,testability,automat,automatically,142,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16333:214,usability,command,command,214,[RF][PyROOT] Pythonize RooStats SPlot constructor and AddSWeights; Adds pythonizations for the `RooStats::SPlot` class. The constructor(which automatically calls `AddSWeight()`) and the `AddSWeight` method follows command argument pythonization ( `**kwargs` -> `RooCmdArgs`) which makes configuring options more pythonic. Also adds a translated RooStats tutorial which uses the added pythonisations,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16333
https://github.com/root-project/root/pull/16334:14,availability,Markov,MarkovChain,14,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:66,availability,Markov,MarkovChain,66,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:155,availability,markov,markov,155,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:268,availability,Markov,MarkovChain,268,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:304,deployability,Updat,Updates,304,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:147,energy efficiency,reduc,reduced,147,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:201,energy efficiency,reduc,reduce,201,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:317,energy efficiency,reduc,reduce,317,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:330,energy efficiency,reduc,reduceEng,330,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:27,integrability,interfac,interfaces,27,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:78,integrability,interfac,interfaces,78,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:27,interoperability,interfac,interfaces,27,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:78,interoperability,interfac,interfaces,78,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
https://github.com/root-project/root/pull/16334:27,modifiability,interfac,interfaces,27,[RF] Improve `MarkovChain` interfaces and `MCMCInterval`; Removes MarkovChain interfaces that are one-time used in `MCMCInterval` . Now obtain the reduced markov chain data (also as Hist ) by calling `reduce` on the RooDataSet (which can be directly accessed through `MarkovChain::GetAsConstDataSet`). . Updates all `reduce` and `reduceEng`methods to const across `RooAbsData` and other RooFit classes with overrides.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16334
